<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Cyrille Rossant - misc</title><link href="https://cyrille.rossant.net/" rel="alternate"></link><link href="https://cyrille.rossant.net/feeds/misc.atom.xml" rel="self"></link><id>https://cyrille.rossant.net/</id><updated>2021-02-16T00:00:00+01:00</updated><entry><title>Datoviz: ultra-fast GPU scientific visualization with Vulkan</title><link href="https://cyrille.rossant.net/datoviz/" rel="alternate"></link><published>2021-02-16T00:00:00+01:00</published><updated>2021-02-16T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2021-02-16:/datoviz/</id><summary type="html">&lt;p&gt;I'm excited to present the project I've been working on at the &lt;a href="http://internationalbrainlab.org/"&gt;International Brain Laboratory (IBL)&lt;/a&gt;. &lt;a href="https://datoviz.org"&gt;&lt;strong&gt;Datoviz&lt;/strong&gt;&lt;/a&gt; is an early-stage open-source &lt;strong&gt;high-performance GPU scientific visualization library based on &lt;a href="https://www.khronos.org/vulkan/"&gt;Vulkan&lt;/a&gt;&lt;/strong&gt;, the Khronos cross-platform low-level graphics API, which is 5 years old today!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://datoviz.org"&gt;&lt;img alt="Datoviz screenshots" src="https://raw.githubusercontent.com/datoviz/data/master/screenshots/datoviz.jpg" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Datoviz aims at providing a &lt;strong&gt;unified, language-agnostic platform for …&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm excited to present the project I've been working on at the &lt;a href="http://internationalbrainlab.org/"&gt;International Brain Laboratory (IBL)&lt;/a&gt;. &lt;a href="https://datoviz.org"&gt;&lt;strong&gt;Datoviz&lt;/strong&gt;&lt;/a&gt; is an early-stage open-source &lt;strong&gt;high-performance GPU scientific visualization library based on &lt;a href="https://www.khronos.org/vulkan/"&gt;Vulkan&lt;/a&gt;&lt;/strong&gt;, the Khronos cross-platform low-level graphics API, which is 5 years old today!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://datoviz.org"&gt;&lt;img alt="Datoviz screenshots" src="https://raw.githubusercontent.com/datoviz/data/master/screenshots/datoviz.jpg" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Datoviz aims at providing a &lt;strong&gt;unified, language-agnostic platform for interactive visualization&lt;/strong&gt; in both 2D and 3D, with support for GUIs and general-purpose GPU compute.&lt;/p&gt;


&lt;p&gt;The main novelties compared to existing open source visualization solutions are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;performance&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;portability&lt;/strong&gt; across languages (not just Python or another specific language),&lt;/li&gt;
&lt;li&gt;ability to support simultaneously &lt;strong&gt;2D, 3D, GUIs and general-purpose GPU computing&lt;/strong&gt; in the same interface.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This new technology allows for &lt;strong&gt;a level of performance probably unprecedented in scientific 2D/3D visualization applications&lt;/strong&gt;. For example, on a 2019 high-end NVIDIA GPU:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a simple scatter plot with &lt;strong&gt;10 million points&lt;/strong&gt; renders at &lt;strong&gt;250 FPS&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;a high-resolution 3D mesh with &lt;strong&gt;10 million triangles&lt;/strong&gt; renders at &lt;strong&gt;400 FPS&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;one thousand signals&lt;/strong&gt; with &lt;strong&gt;30,000 points each&lt;/strong&gt; (30M vertices) renders at &lt;strong&gt;200 FPS&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We're starting to use Datoviz at IBL for graphical exploration of the large amounts of data we're acquiring: high-density electrophysiological data, neural activity in the 3D brain volume, and much more to come.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Datoviz is entirely written in C&lt;/strong&gt; on top of the Vulkan C API. There are preliminary light Python bindings (Cython). There are no external dependencies for the GUIs, everything is already bundled into the library (&lt;a href="https://github.com/datoviz/imgui"&gt;Dear ImGui&lt;/a&gt;).&lt;/p&gt;
&lt;h2&gt;A short history of the project&lt;/h2&gt;
&lt;p&gt;This project is the culmination of &lt;strong&gt;a decade of personal interests, research, and development in this field&lt;/strong&gt;. Frustrated by the poor performance of existing visualization libraries, I started to investigate using the GPU for fast 2D visualization in 2011. I released the experimental Galry project in 2012.&lt;/p&gt;
&lt;p&gt;The next year, I was approached by other Python developers who each had created their own library. We decided to &lt;strong&gt;join forces to create a single library, &lt;a href="http://vispy.org/"&gt;VisPy&lt;/a&gt;&lt;/strong&gt;, in 2013. Today, VisPy is maintained by David Hoese and others. It got recent funding from the &lt;a href="https://chanzuckerberg.com/eoss/proposals/rebuilding-the-community-behind-vispys-fast-interactive-visualizations/"&gt;Chan Zuckerberg Initiative&lt;/a&gt;. VisPy underlies &lt;a href="https://napari.org/"&gt;napari&lt;/a&gt;, a popular imaging software developed by Nicholas Sofroniew et al.&lt;/p&gt;
&lt;p&gt;Based on Python and OpenGL, VisPy is a very complex piece of software, in large part because of the quirks and limitations of OpenGL (especially when it's used from Python). I felt we had reached the limits of this technology but then, OpenGL's successor was announced: &lt;strong&gt;Vulkan&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I was very excited by this announcement and thought it could be a perfect technology for the next generation of GPU visualization software. In 2015, before the API was even released, &lt;a href="https://cyrille.rossant.net/compiler-data-visualization/"&gt;I wrote a blog post with a few ideas&lt;/a&gt; in this respect. It took me more nearly four years after the release of Vulkan in 2016 to find the time to experiment with it.&lt;/p&gt;
&lt;h2&gt;Vulkan for scientific visualization&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Vulkan is a great technology for modern scientific visualization&lt;/strong&gt;. Of course, that conclusion probably applies to other low-level graphics APIs like Metal, DirectX 12, WebGPU which all share a lot of principles (I have no experience with those — but WebGPU looks so promising). It's worth nothing that Khronos and the industry are starting to work in this direction too with &lt;a href="https://www.khronos.org/anari"&gt;the ANARI project&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The complexity of Vulkan is probably well beyond what about any scientist might want to deal with&lt;/strong&gt;. In the last few years, I regularly tried to read tutorials and specifications but it seemed daunting and impenetrable. Eventually, I started to connect the dots.&lt;/p&gt;
&lt;p&gt;The point of a library like Datoviz is precisely to hide most of that complexity away to scientist end-users. It's &lt;strong&gt;like a game engine, but for scientific visualization&lt;/strong&gt;. The top-level API deals with &lt;strong&gt;visual elements&lt;/strong&gt; rather than &lt;strong&gt;GPU objects and abstractions&lt;/strong&gt; (which nevertheless remain accessible to advanced users).&lt;/p&gt;
&lt;p&gt;Conceptually, most interactive scientific visualization use-cases are rather simple: define a subplot layout, choose a set of predefined visual elements (markers, paths, images, text, meshes...), interactivity models (2D pan/zoom, 3D arcball, first-person camera, etc.), and upload your data (positions, colors, colormaps, sizes...) in the coordinate system of your choice. More advanced use-cases essentially boil down to updating visuals and data as a response to events (mouse, keyboard, timers...).&lt;/p&gt;
&lt;p&gt;The hard part is obviously in the underlying implementation that should efficiently leverage the GPU, and even more so in the richness of the built-in visuals. Relatively basic visual elements are provided right now, more will come soon.&lt;/p&gt;
&lt;h2&gt;Implementation&lt;/h2&gt;
&lt;p&gt;Datoviz already sustained several development cycles with extensive internal refactoring and rewrites as I was being more and more accustomed to the technology. The low-level foundations are now relatively solid. Implementing everything from the ground up in Datoviz allowed for more control of the entire visualization stack, making it more amenable to scientific applications, less reliant on third-party projects, and less prone to the various bugs in the OpenGL drivers that we were used to in VisPy.&lt;/p&gt;
&lt;p&gt;The choice of C as a programming language results from pragmatic rather than ideological reasons. Given the requirements of the project (performance, portability, wrapping by other languages), the most serious contenders were C++ and Rust. I actually started using C++, but I realized that my knowledge of &lt;em&gt;modern&lt;/em&gt; C++ was lacking and would have required significant learning efforts. I felt that writing good, production-quality C++ code required a lot of experience. I had even less experience with Rust, and learning both Vulkan and a new programming language at the same time required a bandwidth I didn't have. Since the Vulkan API is a C API, I ended up just using C. It is not impossible that some parts of the library end up being rewritten in another, less ancient language. Yet, in this project, I feel that C gets the job done quite nicely. The hard parts actually lie in the GLSL shaders (which is itself a dialect of C), and in the Vulkan wrapper which is now pretty stable.&lt;/p&gt;
&lt;h2&gt;Prior work&lt;/h2&gt;
&lt;p&gt;When developing Datoviz, &lt;strong&gt;I relied extensively on prior work&lt;/strong&gt;. The experience we gained in developing VisPy was instrumental. A lot of ideas elaborated when creating VisPy made their way into Datoviz.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.labri.fr/perso/nrougier/"&gt;Nicolas Rougier&lt;/a&gt;, the creator of &lt;a href="https://glumpy.github.io/"&gt;Glumpy&lt;/a&gt;, one of the initial core VisPy cofounders, and a well-known contributor to the matplotlib knowledge base (articles, tutorials, videos, books), has published papers in computer graphics journals about displaying high-quality 2D graphics on the GPU. I reused a lot of his GLSL code (originally implemented in Glumpy) in the shaders provided in Datoviz. He ported to the GPU algorithms initially implemented by the late Maxim Shemanarev, creator of the antigrain geometry C++ library.&lt;/p&gt;
&lt;p&gt;Other dependencies (some of them are bundled into the library) non-exhaustively include &lt;a href="https://www.glfw.org/"&gt;GLFW&lt;/a&gt;, &lt;a href="https://github.com/ocornut/imgui"&gt;Dear ImGUI&lt;/a&gt; for GUIs, &lt;a href="https://ffmpeg.org/"&gt;ffmpeg&lt;/a&gt; for making live screencasts, &lt;a href="https://github.com/mapbox/earcut"&gt;earcut&lt;/a&gt; for polygon triangulation, &lt;a href="https://www.cs.cmu.edu/~quake/triangle.html"&gt;triangle&lt;/a&gt; for Delaunay triangulations, &lt;a href="https://github.com/Chlumsky/msdfgen"&gt;msdfgen&lt;/a&gt; for multi-channel signed distance field, used by the text visual.&lt;/p&gt;
&lt;h2&gt;Current status&lt;/h2&gt;
&lt;p&gt;My main goals now are to gather user feedback, fix bugs, improve the testing suite and continuous integration system, test the library on more hardware, work on packages, add a few more features until the first public release. Many more features are planned afterwards, which will mostly depend on our internal needs at the IBL. In the meantime, feel free to try the library if you feel adventurous.&lt;/p&gt;</content><category term="misc"></category><category term="dataviz"></category><category term="gpu"></category></entry><entry><title>Joining the International Brain Laboratory</title><link href="https://cyrille.rossant.net/ibl/" rel="alternate"></link><published>2018-09-17T00:00:00+02:00</published><updated>2018-09-17T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2018-09-17:/ibl/</id><summary type="html">&lt;p&gt;&lt;a href="https://www.internationalbrainlab.com/"&gt;&lt;img src="/images/ibl.png" alt="International Brain Laboratory" align="left" style="width: 280px" /&gt;&lt;/a&gt; I have joined the &lt;a href="https://www.internationalbrainlab.com/"&gt;&lt;strong&gt;International Brain Laboratory&lt;/strong&gt;&lt;/a&gt;, a virtual laboratory gathering 21 neuroscience teams around the world. Half of the researchers are experimentalists, collecting data in the same experimental conditions, while the other half are theoreticians, analyzing the data. I'm working on the data architecture group allowing experimenters to organize …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://www.internationalbrainlab.com/"&gt;&lt;img src="/images/ibl.png" alt="International Brain Laboratory" align="left" style="width: 280px" /&gt;&lt;/a&gt; I have joined the &lt;a href="https://www.internationalbrainlab.com/"&gt;&lt;strong&gt;International Brain Laboratory&lt;/strong&gt;&lt;/a&gt;, a virtual laboratory gathering 21 neuroscience teams around the world. Half of the researchers are experimentalists, collecting data in the same experimental conditions, while the other half are theoreticians, analyzing the data. I'm working on the data architecture group allowing experimenters to organize and store their data, and theoreticians to make detailed queries for their analysis.&lt;/p&gt;
</content><category term="misc"></category><category term="neuroscience"></category></entry><entry><title>Writing the IPython Cookbook, Second Edition</title><link href="https://cyrille.rossant.net/ipython-cookbook-second-edition/" rel="alternate"></link><published>2018-02-12T00:00:00+01:00</published><updated>2018-02-12T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2018-02-12:/ipython-cookbook-second-edition/</id><summary type="html">&lt;p&gt;&lt;a href="https://ipython-books.github.io/"&gt;&lt;img src="/images/cookbook.png" alt="IPython Cookbook, Second Edition" align="left" style="width: 140px; margin-right: 10px;" /&gt;&lt;/a&gt; I'm pleased to announce the release of the &lt;a href="https://ipython-books.github.io/"&gt;IPython Cookbook, Second Edition&lt;/a&gt;, more than three years after the first edition. All 100+ recipes have been updated to the latest versions of Python, IPython, Jupyter, and all of the scientific packages.&lt;/p&gt;
&lt;p&gt;There are a few new recipes introducing recent libraries such …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://ipython-books.github.io/"&gt;&lt;img src="/images/cookbook.png" alt="IPython Cookbook, Second Edition" align="left" style="width: 140px; margin-right: 10px;" /&gt;&lt;/a&gt; I'm pleased to announce the release of the &lt;a href="https://ipython-books.github.io/"&gt;IPython Cookbook, Second Edition&lt;/a&gt;, more than three years after the first edition. All 100+ recipes have been updated to the latest versions of Python, IPython, Jupyter, and all of the scientific packages.&lt;/p&gt;
&lt;p&gt;There are a few new recipes introducing recent libraries such as &lt;a href="https://dask.pydata.org/en/latest/"&gt;Dask&lt;/a&gt;, &lt;a href="https://altair-viz.github.io/"&gt;Altair&lt;/a&gt;, and &lt;a href="https://github.com/jupyterlab/jupyterlab"&gt;JupyterLab&lt;/a&gt;. As usual, &lt;a href="https://github.com/ipython-books/cookbook-2nd-code"&gt;all of the code is available on GitHub as Jupyter notebooks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, the main novelty is that &lt;a href="https://github.com/ipython-books/cookbook-2nd"&gt;&lt;strong&gt;almost the entire book is now freely available on GitHub&lt;/strong&gt;&lt;/a&gt;. The released text is available under the CC-BY-NC-ND license, while the code is under the MIT license. A few recipes are exclusive to the printed book and ebook, to be purchased on &lt;a href="https://www.packtpub.com/big-data-and-business-intelligence/ipython-interactive-computing-and-visualization-cookbook-second-e"&gt;Packt&lt;/a&gt; and &lt;a href="https://www.amazon.com/IPython-Interactive-Computing-Visualization-Cookbook-ebook/dp/B079KBGPQC"&gt;Amazon&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The writing process was &lt;a href="/writing-ipython-cookbook/"&gt;much less painful than with the first edition&lt;/a&gt;. In this post, I'll give an overview of the technical process I've used to write the book, using Markdown, Jupyter Notebook, pandoc, and pelican.&lt;/p&gt;


&lt;h2&gt;From the first edition's PDF to Markdown&lt;/h2&gt;
&lt;p&gt;I had written the first edition in Jupyter notebooks, and I had developed a home-made tool to convert the notebooks into Word, the only format accepted by Packt. Then, the editing process took place in Word and, after the layout process, in PDF. The text edits weren't backported into the original notebook sources. So I was left with two branches of the text : the original unedited notebooks, and the final, edited, proofread text in PDF.&lt;/p&gt;
&lt;p&gt;For the new edition, I wanted to start from the final version of the first edition. At the same time, I had negotiated with Packt Publishing that I would not use anything else than Markdown and Jupyter, except for the very last minor edits made by the publisher in PDF. To save time and to avoid the issues of the first edition, I obtained that only a light proofreading pass would be done by the editors.&lt;/p&gt;
&lt;p&gt;A restriction I had was that I wanted the Markdown files to be nicely rendered on GitHub. To see LaTeX equations in Markdown files on GitHub, one has to use an extension like &lt;a href="https://chrome.google.com/webstore/detail/github-with-mathjax/ioemnmodlmafdkllaclgeombjnmnbima/"&gt;this Chrome extension&lt;/a&gt;, because &lt;a href="https://github.com/github/markup/issues/897"&gt;GitHub doesn't support this natively&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;How to obtain Markdown files from the PDF ? I used &lt;a href="https://en.wikipedia.org/wiki/Pdftotext"&gt;pdftotext&lt;/a&gt;, a little tool that extracts plain text from a PDF file. I cleaned the output semi-manually with some Python. I also converted into Markdown the original Jupyter notebooks. Then, I manually merged the two versions, integrating the latest version of the text obtained from the PDF into the Markdown sources. This painstaking process took place over several weeks for the 100+ recipes.&lt;/p&gt;
&lt;p&gt;Eventually, I ended up with 100+ Markdown files with the latest version of the code and text of the first edition.&lt;/p&gt;
&lt;h2&gt;Editing Markdown files in the Notebook with podoc&lt;/h2&gt;
&lt;p&gt;To convert the original Jupyter notebooks into Markdown, I used &lt;a href="https://github.com/podoc/podoc"&gt;podoc&lt;/a&gt;, an experimental tool I'm still developing that aims at replacing my previous &lt;a href="https://github.com/rossant/ipymd"&gt;ipymd&lt;/a&gt; project. Instead of relying on a custom Markdown parser adapted from the &lt;a href="https://github.com/lepture/mistune"&gt;mistune&lt;/a&gt; Markdown parser in Python, podoc uses &lt;a href="http://pandoc.org/"&gt;pandoc&lt;/a&gt; via the &lt;a href="https://github.com/bebraw/pypandoc"&gt;pypandoc&lt;/a&gt; wrapper.&lt;/p&gt;
&lt;p&gt;Podoc converts files in any supported format into an in-memory abstract syntax tree (AST) that closely follows the internal pandoc AST. The tree can be manipulated in Python, and exported into any other format supported by pandoc. Podoc implements a Jupyter reader and writer, which makes Jupyter notebooks convertable to any pandoc-supported format.&lt;/p&gt;
&lt;p&gt;Another nice side-effect is that Markdown files can be directly edited in the Jupyter Notebook, exactly like ipymd. However, unlike ipymd, podoc supports image files. Output images like matplotlib figures are automatically exported in PNG in a subdirectory alongside the Markdown file.&lt;/p&gt;
&lt;p&gt;How are code cells supported? After all, Markdown doesn't know how to represent them. I chose a simple set of conventions.&lt;/p&gt;
&lt;p&gt;For input code, I use regular code blocks starting with &lt;code&gt;```python&lt;/code&gt;. This allows input code to be nicely rendered on GitHub, with syntax highlighting in Python. A limitation is that all Python code blocks are to be interpreted as Jupyter code cells, which was an acceptable limitation for the cookbook.&lt;/p&gt;
&lt;p&gt;For output, I use a special syntax, for example &lt;code&gt;```{output:stdout}&lt;/code&gt; for standard output of code cells. For images, I use the following convention: any standalone image in its own paragraph just after a code input block is an output image.&lt;/p&gt;
&lt;p&gt;With these conventions, it is easy to write Python code that transforms any AST into a Jupyter-aware AST, with input and output code blocks wrapped into dedicated &lt;code&gt;CodeCell&lt;/code&gt; AST elements. This modified AST can be trivially exported into a Jupyter notebook object, using &lt;a href="https://nbformat.readthedocs.io/en/latest/"&gt;nbformat&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This machinery allowed me to write the book either in a text editor that supports Markdown, or in the Jupyter Notebook. This was extremely convenient: I tend to prefer a text editor for prose, and the Notebook for interactive programming.&lt;/p&gt;
&lt;p&gt;Although podoc served me well for this project, I have to add a word of caution which is that the library is still wildly experimental, it has not reached an alpha state yet, and the API is all but stable. Use it at your own risks.&lt;/p&gt;
&lt;h2&gt;Updating the book&lt;/h2&gt;
&lt;p&gt;With the entire book in Markdown and editable in Jupyter, I could start to work on the update itself. Some recipes didn't require much changes, while others had to be significantly rewritten because the underlying library had changed so much, had disappeared, or a new library could make the code significantly simpler.&lt;/p&gt;
&lt;h2&gt;Converting to Word&lt;/h2&gt;
&lt;p&gt;Once I was happy with a chapter, I had to export it into Word. At Packt, editors cannot use anything else than this format. Fortunately, that was easy with podoc and pandoc. I just had to convert Markdown into an AST, and export the AST into a Word &lt;code&gt;.docx&lt;/code&gt; document using pandoc.&lt;/p&gt;
&lt;p&gt;A few things required extra care.&lt;/p&gt;
&lt;p&gt;Mathematical equations are supported by pandoc and, thus, podoc. However, Packt editors had a problem with importing Word equations into InDesign, and they asked me to provide PNG and EPS files for every single inline or block LaTeX equation.&lt;/p&gt;
&lt;p&gt;In many math-oriented recipes, I had used inline LaTeX equations everywhere in the text. There could be up to 100 little standalone inline or block equations in some recipes. For example, I had to provide three pairs of EPS/PNG files for the LaTeX symbols in the sentence: "the function &lt;span class="math"&gt;\(f\)&lt;/span&gt; reaches its maximum on &lt;span class="math"&gt;\([-1, 1]\)&lt;/span&gt; at the point &lt;span class="math"&gt;\(x_0\)&lt;/span&gt;".&lt;/p&gt;
&lt;p&gt;Again, podoc made this process relatively easy.&lt;/p&gt;
&lt;p&gt;First, I wrote a little &lt;a href="https://gist.github.com/rossant/b9a37747d37140105299b4564fafade1"&gt;quick-and-dirty Python script to convert LaTeX code into EPS and PNG&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then, I wrote a Python "visitor" function that, for every inline or block LaTeX equation in the AST, wrote the corresponding files.&lt;/p&gt;
&lt;p&gt;The editors apologized to make me waste my time exporting thousands of tiny little symbols, but I reassured them saying that it was all done automatically, and that I would never ever have done this by hand! It was actually me who was apologetic because every single of my little stupid EPS files had to be integrated &lt;em&gt;by hand&lt;/em&gt; into InDesign by the editors. In fact, when I checked the first converted chapter, I realized there was some vertical alignment problems in most inline equations.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/latex-vertical.png" style="width: 50%; display: block; margin: 0 auto;" /&gt;&lt;/p&gt;
&lt;p&gt;Fortunately, they fixed it all afterwards.&lt;/p&gt;
&lt;p&gt;Had I known this, I wouldn't have used so many inline LaTeX equations in the text.&lt;/p&gt;
&lt;p&gt;That was the main issue with the process. Apart from that, I advantageously used the AST to customize the exported Word documents: using the input and output code prompts I wanted, running an &lt;a href="https://github.com/hhatto/autopep8"&gt;autopep8&lt;/a&gt; pass on the code, making sure there was no more than X characters per line to avoid ugly unintended code wrapping in the PDF, and so on and so forth.&lt;/p&gt;
&lt;p&gt;I also used the AST to export just the code as Jupyter notebooks, and to write a small table of contents at the very beginning of every chapter, as required by Packt.&lt;/p&gt;
&lt;h2&gt;Editing process&lt;/h2&gt;
&lt;p&gt;In practice, for every chapter, I sent Packt one exported Word document per recipe, with all images and EPS/PNG equations. They took care of making the PDF layout with InDesign. There were a few edit-review cycles using PDF annotations. I have to admit they did a good job, and that the overall process was still time-consuming, but much less painful than with the first edition.&lt;/p&gt;
&lt;h2&gt;Website&lt;/h2&gt;
&lt;p&gt;Beyond the GitHub repository with the Markdown sources, I also wanted to make a little website for the freely-available recipes of the book. I used the &lt;a href="http://docs.getpelican.com/en/stable/"&gt;Pelican&lt;/a&gt; static site generator written in Python. This is what I use for &lt;a href="https://cyrille.rossant.net/"&gt;my own website&lt;/a&gt;. I also reused the same CSS theme. The website is served on &lt;a href="https://pages.github.com/"&gt;GitHub pages&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Even if Pelican supports Markdown contents out of the box, I wrote a Python script to make minor modifications to the sources (adding a header with the book cover image, a link to the book, the license), and to add redirections with &lt;a href="https://github.com/Nitron/pelican-alias"&gt;pelican_alias&lt;/a&gt;. I had to use a patched version of &lt;a href="https://github.com/rossant/Python-Markdown/tree/codehilite-css"&gt;Python-markdown&lt;/a&gt; to &lt;a href="https://blog.liang2.tw/posts/2016/02/markdown-codehilite-lang/"&gt;add the code block language name into the CSS classes&lt;/a&gt;. This was necessary to have a nice styling of the Jupyter code cells.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Writing this second edition took place over about a year because I had little time to devote to this project. However, although it was time-consuming, the overall process was not that painstaking. Also, it gave me a motivation to set up an efficient and flexible writing process with tools that I love, such as Markdown, Jupyter, pandoc, and of course Python.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>New paper in Nature</title><link href="https://cyrille.rossant.net/nature-paper/" rel="alternate"></link><published>2017-11-08T00:00:00+01:00</published><updated>2017-11-08T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2017-11-08:/nature-paper/</id><summary type="html">&lt;p&gt;We've just published &lt;a href="https://www.nature.com/articles/nature24636"&gt;&lt;em&gt;Fully integrated silicon probes for high-density recording of neural activity&lt;/em&gt;&lt;/a&gt; in Nature. The paper (signed by 35 authors) describes the results of a large research project involving the Allen Institute, University College London, HHMI's Janelia Research Campus, and imec, a nanoelectronics research center in Belgium.&lt;/p&gt;
&lt;p&gt;&lt;a href="/nature-paper/"&gt;&lt;img alt="New paper in Nature" src="/images/nature.png" /&gt;&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;The goal …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We've just published &lt;a href="https://www.nature.com/articles/nature24636"&gt;&lt;em&gt;Fully integrated silicon probes for high-density recording of neural activity&lt;/em&gt;&lt;/a&gt; in Nature. The paper (signed by 35 authors) describes the results of a large research project involving the Allen Institute, University College London, HHMI's Janelia Research Campus, and imec, a nanoelectronics research center in Belgium.&lt;/p&gt;
&lt;p&gt;&lt;a href="/nature-paper/"&gt;&lt;img alt="New paper in Nature" src="/images/nature.png" /&gt;&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;The goal of the project was to design and create a new silicon probe, called Neuropixels, for large-scale in-vivo extracellular recordings (384 channels). Tested in awake, behaving mice, the spiking activity of hundreds of neurons could be recorded simultaneously.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nature.com/articles/nature24636"&gt;Nature paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.alleninstitute.org/what-we-do/brain-science/news-press/press-releases/new-silicon-probes-record-activity-hundreds-neurons-simultaneously"&gt;Press release (Allen Institute): New Silicon Probes Record Activity of Hundreds of Neurons Simultaneously&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="misc"></category><category term="neuroscience"></category></entry><entry><title>Hiring a scientific developer</title><link href="https://cyrille.rossant.net/hiring/" rel="alternate"></link><published>2017-09-08T00:00:00+02:00</published><updated>2017-09-08T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2017-09-08:/hiring/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: the position has been filled.&lt;/p&gt;
&lt;p&gt;We're looking for an outstanding Python programmer to help us develop data sharing platforms and software for neuroscience data. This is a large collaboration between ~50 neuroscientists from 20 labs around the world.&lt;/p&gt;


&lt;p&gt;Required skills: Django, Django REST framework, PostgreSQL, MySQL, front-end web development …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: the position has been filled.&lt;/p&gt;
&lt;p&gt;We're looking for an outstanding Python programmer to help us develop data sharing platforms and software for neuroscience data. This is a large collaboration between ~50 neuroscientists from 20 labs around the world.&lt;/p&gt;


&lt;p&gt;Required skills: Django, Django REST framework, PostgreSQL, MySQL, front-end web development, sysadmin.&lt;/p&gt;
&lt;p&gt;Optional: scientific Python (NumPy), MATLAB, distributed computing.&lt;/p&gt;
&lt;p&gt;Location: mainly London, Paris, Lisbon, New York, remote negotiable.&lt;/p&gt;
&lt;p&gt;Positions to fill as soon as possible.&lt;/p&gt;
&lt;p&gt;Here are the official announcements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.internationalbrainlab.com/opportunities/#jobs"&gt;International Brain Laboratory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ucl.ac.uk/cortexlab/positions"&gt;UCL Cortical Processing Laboratory&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Contact me if you're interested (&lt;em&gt;myfirstname&lt;/em&gt;.&lt;em&gt;mylastname&lt;/em&gt;@gmail.com).&lt;/p&gt;</content><category term="misc"></category><category term="neuroscience"></category></entry><entry><title>New paper in Nature Neuroscience</title><link href="https://cyrille.rossant.net/nature-neuroscience-paper/" rel="alternate"></link><published>2016-04-14T00:00:00+02:00</published><updated>2016-04-14T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2016-04-14:/nature-neuroscience-paper/</id><content type="html">&lt;p&gt;We published a &lt;a href="http://www.nature.com/neuro/journal/v19/n4/full/nn.4268.html"&gt;new paper in Nature Neuroscience&lt;/a&gt; about our spike sorting method. This paper is accompanied by an open source software suite named &lt;a href="http://klusta.readthedocs.io/en/latest/"&gt;klusta&lt;/a&gt;, which includes automatic and manual programs for extracting spikes from large multielectrode recordings.&lt;/p&gt;
&lt;p&gt;&lt;a href="/nature-neuroscience-paper/"&gt;&lt;img alt="Paper in Nature Neuroscience" src="/images/nn.png" /&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="misc"></category><category term="neuroscience"></category></entry><entry><title>Setting up a blog with Pelican and GitHub Pages</title><link href="https://cyrille.rossant.net/pelican-github/" rel="alternate"></link><published>2016-02-01T00:00:00+01:00</published><updated>2016-02-01T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2016-02-01:/pelican-github/</id><summary type="html">&lt;p&gt;I describe how I set up my static blog/website in Python with &lt;a href="http://blog.getpelican.com/"&gt;Pelican&lt;/a&gt;, &lt;a href="http://pandoc.org/"&gt;pandoc&lt;/a&gt;, &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;, &lt;a href="http://www.dockerhub.com/"&gt;Dockerhub&lt;/a&gt;, &lt;a href="https://pages.github.com/"&gt;GitHub pages&lt;/a&gt;, and &lt;a href="https://travis-ci.org/"&gt;Travis CI&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;Here is the workflow I wanted to have:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I write new contents in Markdown files.&lt;/li&gt;
&lt;li&gt;I commit and push the sources to my GitHub repository.&lt;/li&gt;
&lt;li&gt;That's it. The …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;I describe how I set up my static blog/website in Python with &lt;a href="http://blog.getpelican.com/"&gt;Pelican&lt;/a&gt;, &lt;a href="http://pandoc.org/"&gt;pandoc&lt;/a&gt;, &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;, &lt;a href="http://www.dockerhub.com/"&gt;Dockerhub&lt;/a&gt;, &lt;a href="https://pages.github.com/"&gt;GitHub pages&lt;/a&gt;, and &lt;a href="https://travis-ci.org/"&gt;Travis CI&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;Here is the workflow I wanted to have:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I write new contents in Markdown files.&lt;/li&gt;
&lt;li&gt;I commit and push the sources to my GitHub repository.&lt;/li&gt;
&lt;li&gt;That's it. The website is automatically updated after two minutes, thanks to &lt;strong&gt;Travis CI&lt;/strong&gt; and &lt;strong&gt;Docker&lt;/strong&gt;. My CV is also automatically converted from Markdown to PDF via LaTeX.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Setting this up was not straightforward and it did require significant upfront investment.&lt;/p&gt;
&lt;h2&gt;Creating a GitHub repo for your website&lt;/h2&gt;
&lt;p&gt;I assume you're creating your personal webpage. You need to create a &lt;code&gt;yourname.github.io&lt;/code&gt; repo where &lt;code&gt;yourname&lt;/code&gt; is your GitHub login. You can also use the same method for an organization page, with minor adjustments. &lt;a href="https://github.com/rossant/rossant.github.io/"&gt;My repo is here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;master&lt;/code&gt; branch will contain the automatically-generated HTML contents. Only Travis CI will write to this branch with a force push. The sources will be in an &lt;a href="https://git-scm.com/docs/git-checkout/"&gt;&lt;em&gt;orphan branch&lt;/em&gt;&lt;/a&gt; named &lt;code&gt;sources&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Clone your repo. Let's assume your local path is &lt;code&gt;/home/yourname/git/yourname.github.io/&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Setting up Pelican&lt;/h2&gt;
&lt;p&gt;Now create your website locally with Pelican. If you're starting from scratch this is not the simplest step! You can refer to &lt;a href="http://docs.getpelican.com/en/stable/"&gt;Pelican's documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here is an excerpt of my repo's file structure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pelican-plugins/                    # git clone the official pelican-plugins repo
plugins/                            # put your own plugins here
content/                            # put your contents here
  images/                           # images that you use in your posts
  pages/                            # static pages
    about.md
    ...
  2016-01-01-my-blog-post.md        # URL will be http://yourname.github.io/my-blog-post/
  ...
themes/                             # put your themes and templates here
  pure/
    static/
    templates/
output/                             # HTML output generated by Pelican

Dockerfile                          # these two files are for Docker
run_docker.sh

Makefile                            # these files are auto-generated by Pelican
pelicanconf.py
publishconf.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I write pages and posts in Markdown files within the &lt;code&gt;contents/&lt;/code&gt; subdirectory. I can use the Jupyter Notebook to edit Markdown files with the &lt;a href="http://github.com/rossant/ipymd"&gt;ipymd&lt;/a&gt; package. This is convenient when my posts contain a lot of code.&lt;/p&gt;
&lt;p&gt;The theme's files (jinja templates, CSS and JS files) are in &lt;code&gt;themes/pure/&lt;/code&gt; (&lt;a href="http://purecss.io/"&gt;pure&lt;/a&gt; is the name of the CSS framework I'm using). I use a few Pelican plugins, which are in the &lt;code&gt;pelican-plugins/&lt;/code&gt; subdirectory (a &lt;a href="https://github.com/getpelican/pelican-plugins"&gt;cloned repo&lt;/a&gt;). I also have a custom plugin in &lt;code&gt;plugins/&lt;/code&gt; (see later in this post).&lt;/p&gt;
&lt;p&gt;When Pelican generates the website, the HTML files are saved in the &lt;code&gt;output/&lt;/code&gt; subfolder which is &lt;em&gt;not&lt;/em&gt; tracked by git.&lt;/p&gt;
&lt;p&gt;Pelican comes with a tool that initializes the file structure for a new site. It creates a default &lt;code&gt;pelicanconf.py&lt;/code&gt;, a complete &lt;code&gt;Makefile&lt;/code&gt;, and a few other things. You put all of your site's parameters in &lt;code&gt;pelicanconf.py&lt;/code&gt;. Here is an excerpt of my &lt;code&gt;pelicanconf.py&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;THEME&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;themes/pure&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;content&amp;#39;&lt;/span&gt;
&lt;span class="c1"&gt;# Extract a post&amp;#39;s date from the filename:&lt;/span&gt;
&lt;span class="n"&gt;FILENAME_METADATA&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;(?P&amp;lt;date&amp;gt;\d&lt;/span&gt;&lt;span class="si"&gt;{4}&lt;/span&gt;&lt;span class="s1"&gt;-\d&lt;/span&gt;&lt;span class="si"&gt;{2}&lt;/span&gt;&lt;span class="s1"&gt;-\d&lt;/span&gt;&lt;span class="si"&gt;{2}&lt;/span&gt;&lt;span class="s1"&gt;)-(?P&amp;lt;slug&amp;gt;.*)&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;STATIC_PATHS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;images&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;EXTRA_PATH_METADATA&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;images/favicon.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;path&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;favicon.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="c1"&gt;# Markdown extensions:&lt;/span&gt;
&lt;span class="n"&gt;MD_EXTENSIONS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;codehilite(css_class=highlight,&amp;#39;&lt;/span&gt;
                 &lt;span class="s1"&gt;&amp;#39;guess_lang=False,linenums=False)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="s1"&gt;&amp;#39;headerid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="s1"&gt;&amp;#39;extra&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="c1"&gt;# Pagination:&lt;/span&gt;
&lt;span class="n"&gt;DEFAULT_PAGINATION&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;PAGINATION_PATTERNS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{base_name}&lt;/span&gt;&lt;span class="s1"&gt;/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{base_name}&lt;/span&gt;&lt;span class="s1"&gt;/index.html&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{base_name}&lt;/span&gt;&lt;span class="s1"&gt;/page/&lt;/span&gt;&lt;span class="si"&gt;{number}&lt;/span&gt;&lt;span class="s1"&gt;/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{base_name}&lt;/span&gt;&lt;span class="s1"&gt;/page/&lt;/span&gt;&lt;span class="si"&gt;{number}&lt;/span&gt;&lt;span class="s1"&gt;/index.html&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;PLUGIN_PATHS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;pelican-plugins&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;plugins&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="c1"&gt;# Pelican plugins:&lt;/span&gt;
&lt;span class="n"&gt;PLUGINS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="c1"&gt;# These plugins are part of the official `pelican-plugins` repo:&lt;/span&gt;
           &lt;span class="s1"&gt;&amp;#39;render_math&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
           &lt;span class="s1"&gt;&amp;#39;summary&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
           &lt;span class="s1"&gt;&amp;#39;neighbors&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
           &lt;span class="c1"&gt;# This one is a custom plugin:&lt;/span&gt;
           &lt;span class="s1"&gt;&amp;#39;pdf&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
           &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;ARTICLE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{slug}&lt;/span&gt;&lt;span class="s1"&gt;/&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;ARTICLE_SAVE_AS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{slug}&lt;/span&gt;&lt;span class="s1"&gt;/index.html&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;PAGE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{slug}&lt;/span&gt;&lt;span class="s1"&gt;/&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;PAGE_SAVE_AS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{slug}&lt;/span&gt;&lt;span class="s1"&gt;/index.html&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;At this point, develop and configure your site locally until it's ready to be made public. I generally use &lt;code&gt;make html&lt;/code&gt; to generate the website locally, &lt;code&gt;make regenerate&lt;/code&gt; to have it regenerated automatically while I work on it, and &lt;code&gt;make serve&lt;/code&gt; to browse it locally at &lt;code&gt;http://localhost:8000&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;publishconf.py&lt;/code&gt; makes a few adjustements to your &lt;code&gt;pelicanconf.py&lt;/code&gt; to make your website ready to be published (mainly specifying the public URL of your website).&lt;/p&gt;
&lt;h2&gt;Automatically generating a PDF version of my CV&lt;/h2&gt;
&lt;p&gt;One of the pages of my site contains my CV in Markdown. I wanted to have a PDF version automatically available, using &lt;a href="http://pandoc.org/"&gt;pandoc&lt;/a&gt; and LaTeX to convert from Markdown to PDF. I created a quick-and-dirty plugin for this purpose:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# This is in `plugins/pdf/__init__.py`&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pelican&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;signals&lt;/span&gt;

&lt;span class="c1"&gt;# The pandoc command. The CV is saved in a static `pdfs/` subdirectory.&lt;/span&gt;
&lt;span class="n"&gt;CMD&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;pandoc &lt;/span&gt;&lt;span class="si"&gt;{fn}&lt;/span&gt;&lt;span class="s1"&gt; -o content/pdfs/cv.pdf &amp;#39;&lt;/span&gt;
       &lt;span class="s1"&gt;&amp;#39;-V geometry:margin=1in &amp;#39;&lt;/span&gt;
       &lt;span class="s1"&gt;&amp;#39;--template=template.tex&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;generate_pdf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TemporaryDirectory&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;tmpdir&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Generating cv.pdf&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;content/pages/about.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;contents&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;fn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tmpdir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;about.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;contents&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;contents&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;contents&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;---&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="c1"&gt;# Add title and author in Markdown front matter.&lt;/span&gt;
        &lt;span class="n"&gt;contents&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;---&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
                    &lt;span class="s1"&gt;&amp;#39;title: Curriculum vitae&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
                    &lt;span class="s1"&gt;&amp;#39;author: Cyrille Rossant&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
                    &lt;span class="s1"&gt;&amp;#39;---&lt;/span&gt;&lt;span class="se"&gt;\n\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                    &lt;span class="n"&gt;contents&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;contents&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CMD&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fn&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;register&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c1"&gt;# Create the PDF before generating the site.&lt;/span&gt;
    &lt;span class="n"&gt;signals&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;initialized&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;generate_pdf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, as part of the build process, a &lt;code&gt;content/pdfs/cv.pdf&lt;/code&gt; file is automatically generated. This ensures that the PDF is always in sync with that page. This PDF is not tracked by git. It will be automatically generated by Travis CI.&lt;/p&gt;
&lt;h2&gt;Setting up Travis CI&lt;/h2&gt;
&lt;p&gt;Now we're going to set up Travis CI. We'll tell Travis to build the website at every push to the &lt;code&gt;sources&lt;/code&gt; branch, and to force push the output to the &lt;code&gt;master&lt;/code&gt; branch. This ensures that the website is automatically built and deployed.&lt;/p&gt;
&lt;p&gt;Here's my &lt;code&gt;.travis.yml&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;language&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;python&lt;/span&gt;
&lt;span class="nt"&gt;python&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;3.5&amp;quot;&lt;/span&gt;
&lt;span class="nt"&gt;sudo&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;required&lt;/span&gt;
&lt;span class="nt"&gt;services&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;docker&lt;/span&gt;
&lt;span class="nt"&gt;branches&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nt"&gt;only&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;sources&lt;/span&gt;
&lt;span class="nt"&gt;env&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nt"&gt;global&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nt"&gt;secure&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;xxxxxxxxxxxx&amp;quot;&lt;/span&gt;
&lt;span class="nt"&gt;install&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;pip install ghp-import&lt;/span&gt;
&lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;git clone https://github.com/getpelican/pelican-plugins&lt;/span&gt;
&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;make publish github&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A few things to note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I use Docker to build the website and the PDF but this is optional.&lt;/li&gt;
&lt;li&gt;If you don't use Docker, you'll have to install Pelican and other dependencies to build your website.&lt;/li&gt;
&lt;li&gt;I put an encrypted version of an authentication key to allow Travis to push to the &lt;code&gt;master&lt;/code&gt; branch of the repo. Refer to &lt;a href="http://blog.mathieu-leplatre.info/publish-your-pelican-blog-on-github-pages-via-travis-ci.html"&gt;this page&lt;/a&gt; to see how to generate and encrypt an authentication key.&lt;/li&gt;
&lt;li&gt;I use the &lt;a href="https://github.com/davisp/ghp-import"&gt;&lt;code&gt;ghp-import&lt;/code&gt; tool&lt;/a&gt; to push the generated website to the &lt;code&gt;master&lt;/code&gt; branch. &lt;strong&gt;Note that this tool is destructive: here it will destroy your &lt;code&gt;master&lt;/code&gt; branch every time&lt;/strong&gt;. You will always have a single commit in &lt;code&gt;master&lt;/code&gt; with the latest version of your website.&lt;/li&gt;
&lt;li&gt;The build process occurs in &lt;code&gt;make publish github&lt;/code&gt; which is readily provided by the default &lt;code&gt;Makefile&lt;/code&gt;. What this command does is:&lt;ul&gt;
&lt;li&gt;Generate your website in &lt;code&gt;output/&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Commit the &lt;code&gt;output/&lt;/code&gt; to the &lt;code&gt;master&lt;/code&gt; branch.&lt;/li&gt;
&lt;li&gt;Push force that branch to GitHub. GitHub Pages takes care of the rest and updates your website automatically at &lt;code&gt;http://yourname.github.io&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Setting up Docker&lt;/h2&gt;
&lt;p&gt;The default &lt;code&gt;Makefile&lt;/code&gt; contains the command &lt;code&gt;pelican contents/ -o output/ -s publishconf.py&lt;/code&gt; to generate your website. However, since I'm using Docker, I've replaced this command by a &lt;code&gt;bash run_docker.sh&lt;/code&gt;, described below.&lt;/p&gt;
&lt;p&gt;The main reason why I'm using Docker here is that installing LaTeX takes a while, and using Docker makes the build process slightly faster on Travis CI. The image is big though (almost 1GB), mainly because of LaTeX, and I'd be happy to find a way to make it smaller. It would make the build process faster.&lt;/p&gt;
&lt;p&gt;Using Docker also gives me a bit more control on the dependencies I need. But it certainly makes the setup more complicated. Don't use it if you don't need it.&lt;/p&gt;
&lt;p&gt;First, install Docker locally. This is not necessarily straightforward: &lt;a href="https://docs.docker.com/engine/installation/"&gt;follow all instructions&lt;/a&gt;. Also, create a &lt;a href="https://hub.docker.com/"&gt;Dockerhub&lt;/a&gt; account, and create a &lt;code&gt;yourname/pelican&lt;/code&gt; repository. Dockerhub is like GitHub, but for Docker images.&lt;/p&gt;
&lt;p&gt;Then, create a &lt;code&gt;Dockerfile&lt;/code&gt; at the root of your repo with the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;FROM python:3
MAINTAINER yourname &amp;lt;your@email.com&amp;gt;

# Update OS
RUN apt-get update
RUN sed -i &amp;#39;s/# \(.*multiverse$\)/\1/g&amp;#39; /etc/apt/sources.list
RUN apt-get -y upgrade

# Install dependencies
# I need LaTeX and pandoc to generate the CV:
RUN apt-get install make git tex-common texlive pandoc -y
RUN pip install pelican Markdown ghp-import
RUN pip install --upgrade pelican Markdown ghp-import

WORKDIR /site
# Generate the website when running the container:
CMD pelican content/ -o output/ -s publishconf.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Starting from a Python 3 image, we add LaTeX, pandoc, Pelican, Markdown, and ghp-import, and we generate the website.&lt;/p&gt;
&lt;p&gt;When you'll run a container based on this image, you'll have to mount your repository as a data volume so that the Docker container has access to it.&lt;/p&gt;
&lt;p&gt;Build your container with &lt;code&gt;docker build -t yourname/pelican .&lt;/code&gt; (note the trailing dot!). This will download the Python 3 image and build an image with your Dockerfile instructions.&lt;/p&gt;
&lt;p&gt;Next step is to &lt;a href="https://docs.docker.com/engine/userguide/dockerrepos/"&gt;upload the image to your Dockerhub account&lt;/a&gt; with &lt;code&gt;docker login&lt;/code&gt; and &lt;code&gt;docker push yourname/pelican&lt;/code&gt;. Travis CI will download it and use it to build your website.&lt;/p&gt;
&lt;p&gt;Finally, here's a tiny bash script to pull the latest version of the image from Dockerhub and run it to generate the website:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# This is run_docker.sh&lt;/span&gt;
&lt;span class="c1"&gt;# Pull the latest Docker image&lt;/span&gt;
docker pull yourname/pelican
&lt;span class="c1"&gt;# Generate the site with pelican&lt;/span&gt;
docker run -t -v &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;:/site yourname/pelican
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The last line of the script runs our container. The &lt;code&gt;-v $(pwd):/site&lt;/code&gt; allows us to mount the current directory (typically your &lt;code&gt;~/git/yourname.github.io/&lt;/code&gt; repo) to the &lt;code&gt;/site&lt;/code&gt; directory, which is our container's working directory.&lt;/p&gt;
&lt;p&gt;Phew, that's it! Now I can edit the Markdown sources, commit and push to GitHub, and the website is built automatically by Travis CI. To sum up, the build process done by Travis CI at every push to &lt;code&gt;sources&lt;/code&gt; is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clone the current &lt;code&gt;yourname.github.io&lt;/code&gt; repo&lt;/li&gt;
&lt;li&gt;Pull the &lt;code&gt;yourname/pelican&lt;/code&gt; image from Dockerhub&lt;/li&gt;
&lt;li&gt;Create and run a container based on this image, with the current directory containing the sources mounted inside the container&lt;/li&gt;
&lt;li&gt;The container, which has Pelican, LaTeX, and pandoc installed, generates the website in &lt;code&gt;output/&lt;/code&gt;, including the PDF version of one of the pages&lt;/li&gt;
&lt;li&gt;The output is committed to the &lt;code&gt;master&lt;/code&gt; branch via &lt;code&gt;ghp-import&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;master&lt;/code&gt; branch is pushed to the GitHub &lt;code&gt;yourname.github.io&lt;/code&gt; repo thanks to the authentication token&lt;/li&gt;
&lt;/ul&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>Should you use HDF5?</title><link href="https://cyrille.rossant.net/should-you-use-hdf5/" rel="alternate"></link><published>2016-01-30T00:00:00+01:00</published><updated>2016-01-30T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2016-01-30:/should-you-use-hdf5/</id><summary type="html">&lt;p&gt;This is a follow-up on my post &lt;a href="/moving-away-hdf5/"&gt;&lt;em&gt;Moving away from HDF5&lt;/em&gt;&lt;/a&gt; (see also &lt;a href="http://blog.khinsen.net/posts/2016/01/07/on-hdf5-and-the-future-of-data-management/"&gt;Konrad Hinsen's post&lt;/a&gt;, and discussions on &lt;a href="https://twitter.com/cyrillerossant/status/684767653697683456"&gt;Twitter&lt;/a&gt; and &lt;a href="https://news.ycombinator.com/item?id=10858189"&gt;Hacker News&lt;/a&gt;). Here are some further thoughts, in no particular order.&lt;/p&gt;


&lt;p&gt;First, others have pointed out alternative implementations of the HDF5 specification (complete or not), notably in &lt;a href="https://cyrille.rossant.net/moving-away-hdf5/#comment-2445619778"&gt;Julia&lt;/a&gt; and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a follow-up on my post &lt;a href="/moving-away-hdf5/"&gt;&lt;em&gt;Moving away from HDF5&lt;/em&gt;&lt;/a&gt; (see also &lt;a href="http://blog.khinsen.net/posts/2016/01/07/on-hdf5-and-the-future-of-data-management/"&gt;Konrad Hinsen's post&lt;/a&gt;, and discussions on &lt;a href="https://twitter.com/cyrillerossant/status/684767653697683456"&gt;Twitter&lt;/a&gt; and &lt;a href="https://news.ycombinator.com/item?id=10858189"&gt;Hacker News&lt;/a&gt;). Here are some further thoughts, in no particular order.&lt;/p&gt;


&lt;p&gt;First, others have pointed out alternative implementations of the HDF5 specification (complete or not), notably in &lt;a href="https://cyrille.rossant.net/moving-away-hdf5/#comment-2445619778"&gt;Julia&lt;/a&gt; and &lt;a href="https://www.unidata.ucar.edu/software/thredds/current/netcdf-java/CDM/"&gt;Java&lt;/a&gt;. I haven't tried them so I don't know how good they are. I don't know of any alternative implementation in Python. It would be interesting to see a Python implementation of a subset of HDF5 that doesn't depend on libhdf5.&lt;/p&gt;
&lt;p&gt;Now about use cases. While HDF5 didn't appear to be the right tool for us, others reported that they were happy with it. For example, &lt;a href="http://blog.khinsen.net/posts/2016/01/07/on-hdf5-and-the-future-of-data-management/"&gt;Konrad Hinsen uses HDF5 with lots of tiny arrays&lt;/a&gt;, whereas we had no more than a few huge arrays. Also, we have large volumes of experimental data, whereas his data comes from numerical simulations. These are quite different use cases. HDF5 was probably overkill for us, whereas it may well be the best option in Konrad's case. The file system alternative I mention in my post may not be a good idea with zillions of small files.&lt;/p&gt;
&lt;p&gt;Another thing is that we must make a distinction between creating, analyzing, and sharing a dataset. With our file format we tried to do all of these things with the same structure. As far as I understand it, this is what HDF5 encourages you to do. But these different use cases pose different constraints on how you store your data.&lt;/p&gt;
&lt;p&gt;When creating a dataset, you want a fast write access. For analysis, you want a fast read access. For sharing, you want as few files as possible (ideally, one), with a clean internal structure. Of course this is overly simplistic.&lt;/p&gt;
&lt;p&gt;It's hard to have a one-size-fits-all format. In our experience, HDF5 seemed to be a good option for sharing large datasets, but not that good for our peculiar read/write access patterns.&lt;/p&gt;
&lt;p&gt;What we ended up doing at some point is using HDF5 only for sharing data. When importing the data into our software, we copied it into an internal format based on flat binary arrays. With this change, our software was much faster, at the expense of disk space and a longer initial loading time.&lt;/p&gt;
&lt;p&gt;Effectively, we used a different format for sharing and for analyzing our data. If you need a file format, think hard about your requirements. Which is the most important to you: sharing, reading, writing?&lt;/p&gt;
&lt;p&gt;Another question that came up was whether there were alternatives to HDF5. I'm not aware of a portable container format for storing numerical arrays that is not HDF5. If you are, please let me know. If you don't use HDF5, you can always use a folder hierarchy with one file per array. This is what we'll end up doing, although having many files isn't an ideal solution. If you want to make a single file out of a hierarchy of files and folders, you can always use tar or zip, of course.&lt;/p&gt;
&lt;p&gt;Finally, it is worth mentioning &lt;a href="http://asdf-standard.readthedocs.org/en/latest/"&gt;&lt;strong&gt;ASDF&lt;/strong&gt;&lt;/a&gt;, a new file format for astronomy from the Space Telescope Science Institute that aims to replace &lt;a href="http://fits.gsfc.nasa.gov/"&gt;FITS&lt;/a&gt;. It is somewhat similar in spirit to HDF5. &lt;a href="http://www.sciencedirect.com/science/article/pii/S2213133715000645"&gt;The paper&lt;/a&gt; by P. Greenfield, M. Droettboom, and E. Bray describes the issues with HDF5 and the motivations behind this new format. Here is an excerpt that largely overlaps with the arguments exposed in my previous post:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[HDF5] is an entirely binary format. [...] All inspection of HDF5 files must be done through HDF5 software. [...] The consequence of this for HDF5 is that the HDF5 toolset must be installed, and its software must be used if one wants to inspect the contents of the HDF5 file in any way.&lt;/p&gt;
&lt;p&gt;[...] Because of the complexity, there is effectively only one implementation. The drawback of having only one implementation is that it may deviate from the published specification (who would know since there is no independent verification?). [...]&lt;/p&gt;
&lt;p&gt;A related issue is that for some time the HDF format was not considered archival as it kept changing, and for a time it was considered more of a software API than a specific representation on disk. HDF5 has been relatively stable, though given the lack of multiple implementations and self documenting nature makes it less appropriate as an archival format. Will the future library be able to read much older files?&lt;/p&gt;
&lt;p&gt;HDF5 does not lend itself to supporting simpler, smaller text-based data files. As an example, many astronomers prefer to use simple ASCII tables for data that do not require very large files, primarily for the convenience in viewing and editing them without using special tools.&lt;/p&gt;
&lt;p&gt;The HDF5 Abstract Data Model is not flexible enough to represent the structures we need to represent, notably for generalized WCS (see Section  6.6). The set of data types in HDF5 does not include a variable-length mapping datatype (analogous to a Python dictionary or JavaScript object). While “Groups”, which are much like a filesystem directory, could be used for this purpose, “Groups” cannot be nested inside of variable-length arrays but only within each other. The “Compound” data type, analogous to a C struct also seems fruitful, but it cannot contain other “Compound” types or variable-length arrays. These arbitrary restrictions on nesting of data structures make some concepts much harder to represent than they otherwise need to be.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;According to the paper, ASDF is expected to be used with the James Webb Space Telescope, the successor to the Hubble telescope.&lt;/p&gt;
&lt;p&gt;Hopefully you should now be in a position to decide whether HDF5 is the right tool for you, or if you need to explore other options. The main question you should ask is: do you absolutely need a portable container format containing many numerical arrays? If the answer is yes, you might have no other choice than HDF5, and you should be aware of its drawbacks. Do prototypes and benchmarks to avoid bad surprises in production.&lt;/p&gt;
&lt;p&gt;The more important question is: do you &lt;em&gt;really&lt;/em&gt; need a file format in the first place? If you're targeting advanced users who are familiar with Python, it might be sufficient to provide a sensible API and let them deal with file format issues. Savvy users tend to prefer keeping control of their data.&lt;/p&gt;
&lt;p&gt;On the other hand, if your users aren't programmers and expect an easy-to-use integrated solution, you may have no other choice than deciding the file format and structure of the data generated by your software. This was our case. I tried to push hard our users (who are biologists) to learn Python and regain control of their workflows and data formats, but I failed. This is sad, as I think that in 2016 &lt;em&gt;any&lt;/em&gt; researcher needs to know a programming language, Unix, bash, a version control system, etc. Still, many researchers continue to be allergic to command-line interfaces and programming languages, and you might have to comply with their requests. Maybe the customer is always right.&lt;/p&gt;</content><category term="misc"></category></entry><entry><title>Moving away from HDF5</title><link href="https://cyrille.rossant.net/moving-away-hdf5/" rel="alternate"></link><published>2016-01-06T00:00:00+01:00</published><updated>2016-01-06T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2016-01-06:/moving-away-hdf5/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Update [2016-01-30]: &lt;a href="/should-you-use-hdf5/"&gt;I wrote a follow-up here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the research lab where I work, we've been developing a data processing pipeline for several years. This includes not only a program but also a new file format based on &lt;strong&gt;HDF5&lt;/strong&gt; for a specific type of data. While the choice of HDF5 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Update [2016-01-30]: &lt;a href="/should-you-use-hdf5/"&gt;I wrote a follow-up here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the research lab where I work, we've been developing a data processing pipeline for several years. This includes not only a program but also a new file format based on &lt;strong&gt;HDF5&lt;/strong&gt; for a specific type of data. While the choice of HDF5 was looking compelling on paper, we found many issues with it. &lt;strong&gt;Recently, despite the high costs, we decided to abandon this format in our software&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In this post, I'll describe what is HDF5 and what are the issues that made us move away from it.&lt;/p&gt;


&lt;h2&gt;What is HDF5?&lt;/h2&gt;
&lt;p&gt;For those who haven't come across it, &lt;a href="https://en.wikipedia.org/wiki/Hierarchical_Data_Format"&gt;&lt;strong&gt;Hierarchical Data Format&lt;/strong&gt;&lt;/a&gt;, or HDF [in this post I'll only talk about the current version, HDF5], is a multipurpose hierarchical container format capable of storing large numerical datasets with their metadata. The specification is open and the tools are open source. Development of HDF5 is done by the &lt;a href="https://www.hdfgroup.org/"&gt;&lt;strong&gt;HDF Group&lt;/strong&gt;&lt;/a&gt;, a non-profit corporation.&lt;/p&gt;
&lt;h3&gt;What's in an HDF5 file?&lt;/h3&gt;
&lt;p&gt;An HDF5 file contains a POSIX-like hierarchy of numerical arrays (aka &lt;strong&gt;datasets&lt;/strong&gt;) organized within &lt;strong&gt;groups&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;A dataset can be stored in two ways: &lt;strong&gt;contiguously or chunked&lt;/strong&gt;. If the former, the dataset is stored in a contiguous buffer in the file. If the latter, it is split uniformly in rectangular chunks organized in a B-tree.&lt;/p&gt;
&lt;p&gt;HDF5 also supports lossless compression of datasets.&lt;/p&gt;
&lt;h3&gt;File system within a file&lt;/h3&gt;
&lt;p&gt;Effectively, you can see HDF5 as &lt;strong&gt;a file system within a file&lt;/strong&gt;, where files are datasets and folders are groups. However, the &lt;a href="https://www.hdfgroup.org/HDF5/faq/whyhdf5.html"&gt;HDF Group doesn't seem to like this comparison&lt;/a&gt;. The major differences are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;An HDF5 file is portable&lt;/strong&gt;: the entire structure is contained in the file and doesn't depend on the underlying file system. However it does depend on the HDF5 library.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HDF5 datasets have a rigid structure&lt;/strong&gt;: they are all homogeneous (hyper)rectangular numerical arrays, whereas files in a file system can be anything.&lt;/li&gt;
&lt;li&gt;You can add &lt;strong&gt;metadata&lt;/strong&gt; to groups, whereas file systems don't support this.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;A short story&lt;/h2&gt;
&lt;p&gt;Many neuroscience labs working on extracellular recordings had been using a file format for almost two decades. This was meant to be a temporary file format and no one expected that it would become so widely used. For this reason, not much thought had been given to it. The format mixed text and binary files, metadata was stored in poorly-specified XML file. There were some quirks like off-by-one discrepancies between files. It could happen that scientific results were wrong because the experimenter was confused by the format. There were also serious performance problems, and the format wouldn't have scaled to modern recording devices.&lt;/p&gt;
&lt;p&gt;These files were used in a suite of graphical programs that had also been developed a while ago, and that wouldn't have scaled to these new devices.&lt;/p&gt;
&lt;p&gt;As we worked on a new version of the processing software, we decided to also design a &lt;strong&gt;new version of this file format that would be based on HDF5&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HDF5 looked like an ideal choice&lt;/strong&gt;: widely-supported, supposedly fast and scalable, versatile. We couldn't find any argument against it. The following advantages were the main reasons we chose HDF5 in the first place:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open&lt;/li&gt;
&lt;li&gt;Large community&lt;/li&gt;
&lt;li&gt;You can create symlinks between datasets and HDF5 files&lt;/li&gt;
&lt;li&gt;Transparent endianness support&lt;/li&gt;
&lt;li&gt;Portability and metadata, as seen above&lt;/li&gt;
&lt;li&gt;Chunked datasets can be resized along a given dimension&lt;/li&gt;
&lt;li&gt;Possible support for compression&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We spent months and years designing the perfect HDF5-based file format that would work for everyone. We ran many benchmarks on various configurations to find the best compromise between design and performance. We rewrote our entire Python software around this new format using the &lt;a href="http://www.h5py.org/"&gt;h5py library&lt;/a&gt;. People around the world started to generate petabytes of data with our program.&lt;/p&gt;
&lt;p&gt;That's when we started to see several practical problems, which also made us aware of deeper issues with HDF5:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;High risks of data corruption&lt;/li&gt;
&lt;li&gt;Bugs and crashes in the HDF5 library and in the wrappers&lt;/li&gt;
&lt;li&gt;Poor performance in some situations&lt;/li&gt;
&lt;li&gt;Limited support for parallel access&lt;/li&gt;
&lt;li&gt;Impossibility to explore datasets with standard Unix/Windows tools&lt;/li&gt;
&lt;li&gt;Hard dependence on a single implementation of the library&lt;/li&gt;
&lt;li&gt;High complexity of the specification and the implementation&lt;/li&gt;
&lt;li&gt;Opacity of the development and slow reactivity of the development team&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our users were upset. They couldn't do things they could do with the old format, however clunky it may have been. We implemented hacks and patches around these bugs and limitations, and ended up with an unmaintainable code mess.&lt;/p&gt;
&lt;p&gt;At some point, we said stop. For us, &lt;strong&gt;HDF5 was too much trouble, and we estimated that dropping it completely was the least painful choice&lt;/strong&gt;. With so much data in this format in the wild, we still need to provide support, conversion, and export facilities, but we encourage our users to move to a simpler format.&lt;/p&gt;
&lt;h2&gt;Disadvantages of HDF5&lt;/h2&gt;
&lt;p&gt;What has gone wrong? &lt;strong&gt;The first mistake we did was to design a file format in the first place&lt;/strong&gt;. This is an extremely hard problem, and the slightest mistake has huge and expensive consequences. This is better left off to dedicated working groups.&lt;/p&gt;
&lt;p&gt;Let's now see the disadvantages of HDF5 in detail.&lt;/p&gt;
&lt;h3&gt;Single implementation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;The &lt;a href="https://www.hdfgroup.org/HDF5/doc/H5.format.html"&gt;HDF5 specification&lt;/a&gt; is very complex and low level&lt;/strong&gt;. It spans about &lt;strong&gt;150 pages&lt;/strong&gt;. In theory, since the specification is open, anyone can write their own implementation. In practice, this is so complex that &lt;strong&gt;there is a single implementation, spanning over 300,000 lines of C code&lt;/strong&gt;. The library may be hard to compile on some systems. There are wrappers in many languages, including Python. They all rely on the same C library, so they all share the bugs and performance issues of this implementation. Of course, the wrappers can add their own bugs and issues.&lt;/p&gt;
&lt;p&gt;The code repository of the reference implementation is hard to find. It looks like there is an &lt;a href="https://github.com/live-clones/hdf5"&gt;unofficial GitHub clone&lt;/a&gt; of an &lt;a href="https://svn.hdfgroup.uiuc.edu/hdf5/trunk/"&gt;SVN repository&lt;/a&gt;. There are no issues, pull requests, little documentation, etc. just a bunch of commits. To understand the code properly, you have to become very familiar with the 150 pages of specification.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Overall, using HDF5 means that, to access your data, you're going to depend on a very complex specification and library, slowly developed over almost 20 years by a handful of persons, and which are probably understood by just a few people in the world&lt;/strong&gt;. This is a bit scary.&lt;/p&gt;
&lt;h3&gt;Corruption risks&lt;/h3&gt;
&lt;p&gt;Corruption may happen if your software crashes while it's accessing an HDF5 file. Once a file is corrupted, all of your data is basically lost forever. &lt;strong&gt;This is a major drawback of storing a lot of data in a single file, which is what HDF5 is designed for&lt;/strong&gt;. Users of our software have lost many hours of work because of this. Of course, you need to write your software properly to minimize the risk of crashes, but it is hard to avoid them completely. Some crashes are due to the HDF5 library itself.&lt;/p&gt;
&lt;p&gt;To mitigate corruption issues, journaling was being considered in a future version of HDF5. I can find mentions of this feature on the mailing list, &lt;a href="http://hdf-forum.184993.n3.nabble.com/hdf-forum-Recover-a-corrupt-HDF5-file-td193622.html"&gt;for example here in 2008&lt;/a&gt;, or in &lt;a href="http://hdf-forum.184993.n3.nabble.com/File-corruption-and-hdf5-design-considerations-td4025305.html"&gt;2012&lt;/a&gt;. It was planned for the &lt;strong&gt;1.10 version&lt;/strong&gt;, which itself was originally planned for &lt;a href="https://lists.hdfgroup.org/pipermail/hdf-forum_lists.hdfgroup.org/2011-September/005059.html"&gt;2011&lt;/a&gt;, if not earlier. Finally it looks like &lt;a href="https://hdfgroup.org/wp/2015/05/whats-coming-in-the-hdf5-1-10-0-release/"&gt;&lt;strong&gt;journaling is not going to make it into the 1.10 release&lt;/strong&gt;&lt;/a&gt; [see the &lt;em&gt;Comments&lt;/em&gt; section in this page]. This release is currently planned for 2016, and the &lt;a href="https://www.hdfgroup.org/HDF5/release/obtain5110.html"&gt;very first alpha version has been released a few days ago&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;[Anecdotally, this version seems to break compatibility in that &lt;em&gt;earlier releases [of HDF5] will not be able to read HDF5-1.10 files.&lt;/em&gt; Also, there is a big warning for the alpha release: &lt;em&gt;PLEASE BE AWARE that the file format is not yet stable. DO NOT keep files created with this version.&lt;/em&gt;]&lt;/p&gt;
&lt;h3&gt;Various limitations and bugs&lt;/h3&gt;
&lt;p&gt;Once, we had to tell our Windows users to downgrade their version of h5py because a &lt;a href="https://github.com/h5py/h5py/issues/593"&gt;segmentation fault occurred with variable-length strings&lt;/a&gt; in the latest version. This is one of the disadvantages of using a compiled library instead of a pure Python library. There is no other choice since the only known implementation of HDF5 is written in C.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://docs.h5py.org/en/latest/strings.html"&gt;UTF-8 support in HDF5 seems limited&lt;/a&gt;, so in practice you need to rely on ASCII to avoid any potential problems.&lt;/p&gt;
&lt;p&gt;There are few supported data types for metadata attributes. In Python, if your attributes are in an unsupported type (for example, tuples), they might be silently serialized via pickle to an opaque binary blog, making them unreadable in another language like MATLAB.&lt;/p&gt;
&lt;p&gt;A surprising limitation: &lt;strong&gt;as of today, you still can't delete an array in an HDF5 file&lt;/strong&gt;. More precisely, you can delete the link, but the data remains in the file so that the file size isn't reduced. The only way around this is to make a copy of the file &lt;em&gt;without&lt;/em&gt; the deleted array (for example with the &lt;em&gt;h5repack&lt;/em&gt; tool). This is problematic when you have 1TB+ files. The upcoming HDF5 1.10 promises to fix this partially, but it is still in alpha stage at the time of this writing.&lt;/p&gt;
&lt;h3&gt;Performance issues&lt;/h3&gt;
&lt;p&gt;Since HDF5 is a sort of file system within a file, it cannot benefit from the smart caching/predictive strategies provided by modern operating systems. This can lead to poor performance.&lt;/p&gt;
&lt;p&gt;If you use chunking, you need to be very careful with the &lt;a href="http://www.speedup.ch/workshops/w37_2008/HDF5-Tutorial-PDF/HDF5-Cach-Buf.pdf"&gt;chunk size&lt;/a&gt; and your CPU cache size, otherwise you might end up with terrible performance. Optimizing performance with HDF5 is a &lt;a href="http://www.pytables.org/usersguide/optimization.html"&gt;rather complicated topic&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In our application, we have a particular use-case where we have a large contiguous array with, say, 100,000 lines and 1000 columns (in reality these numbers may be much larger than that), and we need to access a small number of lines quickly. Unfortunately, there is no locality in our access patterns. We found out that using h5py led to very slow access times, but it's due to a &lt;a href="https://gist.github.com/rossant/7b4704e8caeb8f173084#gistcomment-1665072"&gt;known weakness of the implementation of fancy indexing in h5py&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When we perform a regular selection with slices, we also found that h5py is several times slower than memory-mapping a file with NumPy, but it's unclear if this is due to h5py or HDF5 itself.&lt;/p&gt;
&lt;p&gt;We also found that &lt;strong&gt;we can actually bypass libhdf5 when reading an HDF5 file&lt;/strong&gt;, provided that we use uncompressed contiguous datasets. All we have to do is find the address of the first byte of the array in the file, and memory-map the buffer with NumPy. This also leads to faster access times.&lt;/p&gt;
&lt;p&gt;Overall, &lt;strong&gt;in this situation, using memory-mapping instead of h5py/HDF5 leads to read access times that are significantly faster&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://gist.github.com/rossant/7b4704e8caeb8f173084"&gt;You'll find a standalone benchmark as a Jupyter notebook here.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In conclusion, we found out the hard way that &lt;strong&gt;HDF5 may be quite slower than simpler container formats, and as such, it is not always a good choice in performance-critical applications.&lt;/strong&gt; This was quite surprising as we (wrongly) expected HDF5 to be particularly fast in most situations. Note that performance might be good enough in other use-cases. If you consider using HDF5 or another format, be sure to run detailed benchmarks in challenging situations before you commit to it.&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Update&lt;/strong&gt;: note that an earlier version of this paragraph mentioned a 100x speed increase, but it's been pointed out in the comments below that the benchmark was not comparing the right thing. The paragraph above and the benchmark have been updated accordingly. Earlier versions of the benchmark can be found in the notebook history.]&lt;/p&gt;
&lt;h3&gt;Poor support on distributed architectures&lt;/h3&gt;
&lt;p&gt;Parallel access in HDF5 exists but it is a bit &lt;a href="https://github.com/rossant/hdf5-experiments/wiki/Summary-of-HDF5-parallel-features"&gt;limited&lt;/a&gt; and not easy to use. MPI is required for multiprocessing.&lt;/p&gt;
&lt;p&gt;HDF5 was designed at a time where &lt;a href="http://www.dursi.ca/hpc-is-dying-and-mpi-is-killing-it/"&gt;MPI was the state-of-the-art for high performance computing&lt;/a&gt;. Now, we have large-scale distributed architectures like Hadoop, Spark, etc. HDF5 isn't well supported on these systems. For example, on Spark, you have to &lt;a href="https://hdfgroup.org/wp/2015/03/from-hdf5-datasets-to-apache-spark-rdds/"&gt;split your data into multiple HDF5 files&lt;/a&gt;, which is precisely the opposite of what HDF5 encourages you to do [see also &lt;a href="https://www.hdfgroup.org/pubs/papers/Big_HDF_FAQs.pdf"&gt;this document&lt;/a&gt; by the HDF Group].&lt;/p&gt;
&lt;p&gt;By contrast, flat binary files are natively supported on Spark.&lt;/p&gt;
&lt;h3&gt;Opacity&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;You depend on the HDF5 library to do anything with an HDF5 file&lt;/strong&gt;. What is in a file? How many arrays there are? What are their paths, shapes, data types? What is the metadata? Without the HDF5 library, you can't answer any of these questions. Even when HDF5 is installed, you need dedicated tools or, worse, you need to write your own script. This adds considerable cognitive overhead when working with scientific data in HDF5.&lt;/p&gt;
&lt;p&gt;You can't use standard Unix/Windows tools like &lt;code&gt;awk&lt;/code&gt;, &lt;code&gt;wc&lt;/code&gt;, &lt;code&gt;grep&lt;/code&gt;, Windows Explorer, text editors, and so on, because the structure of HDF5 files is hidden in a binary blob that only the standard libhdf5 understands. There is a Windows-Explorer-like &lt;a href="https://www.hdfgroup.org/products/java/hdfview/"&gt;&lt;em&gt;HDFView&lt;/em&gt;&lt;/a&gt; tool written in Java that allows you to look inside HDF5 files, but it is very limited compared to the tools you find in modern operating systems.&lt;/p&gt;
&lt;p&gt;A simpler and roughly equivalent alternative to HDF5 would be to store each array in its own file, within a sensible file hierarchy, and with the metadata stored in JSON or YAML files. For the file format of the individual arrays, one can choose for example a raw binary format without a header (&lt;code&gt;arr.tofile()&lt;/code&gt; in NumPy), or the &lt;a href="http://docs.scipy.org/doc/numpy-dev/neps/npy-format.html"&gt;NumPy format &lt;code&gt;.npy&lt;/code&gt;&lt;/a&gt; which is just a flat binary file with a fixed-length ASCII header. [Note the paragraph about HDF5 in the page linked above] These files can be easily memory-mapped with very good performance since the file system and the OS are in charge in that case.&lt;/p&gt;
&lt;p&gt;This leads to a self-documenting format that anyone can immediately explore with any command-line shell, on any computer on the planet, with any programming language, without installing anything, and without reading any specific documentation. In 20 or 30 years, your files are much more likely to be readable if they are stored in this format than if they're stored in HDF5.&lt;/p&gt;
&lt;h3&gt;Philosophy&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;HDF5 encourages you to put within a single file many data arrays corresponding to a given experiment or trial&lt;/strong&gt;. These arrays are organized in a POSIX-like structure.&lt;/p&gt;
&lt;p&gt;One can wonder why not just use a hierarchy of files within a directory.&lt;/p&gt;
&lt;p&gt;Modern file systems are particularly complex. They have been designed, refined, battle-tested, and optimized over decades. As such, despite their complexity, they're now very robust. They're also highly efficient, and they implement advanced caching strategies. HDF5 is just more limited and slower. Perhaps things were different when HDF5 was originally developed.&lt;/p&gt;
&lt;p&gt;If you replace your HDF5 file by a hierarchy of flat binary files and text files, as described in the previous section, you obtain a file format that is more robust, more powerful, more efficient, more maintainable, more transparent, and more amenable to distributed systems than HDF5.&lt;/p&gt;
&lt;p&gt;The only disadvantage of this more rudimentary container format I can think of is portability. You can always zip up the archive, but this is generally slow, especially with huge datasets. That being said, today's datasets are so big that they don't tend to move a lot. Rather than sharing huge datasets, it might be a better idea to fire up a &lt;a href="http://jupyter.org/"&gt;Jupyter server&lt;/a&gt; and serve analysis notebooks.&lt;/p&gt;
&lt;p&gt;When datasets are really too big to fit on a single computer, distributed architectures like Spark are preferred, and we saw that these architectures don't support HDF5 well.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We've learned our lesson. &lt;strong&gt;Designing, maintaining, and promoting a file format within a community is hard&lt;/strong&gt;. It cannot be reasonably done by a small group of people who also need to write software, develop algorithms, and do research.&lt;/p&gt;
&lt;p&gt;I don't think we could have predicted all of our problems with HDF5, since we had only heard enthusiast opinions. Maybe HDF5 was great a decade ago, and it just became outdated.&lt;/p&gt;
&lt;p&gt;What I do know is that &lt;strong&gt;we wouldn't have had these problems if we hadn't tried to develop a file format in the first place&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We've now rewritten our software to make it modular and completely agnostic to file formats. &lt;strong&gt;We've moved from writing a monolithic application to writing a library&lt;/strong&gt;. We're encouraging our users to adapt these components to whatever file format they're already using. The APIs we provide make this straightforward.&lt;/p&gt;
&lt;p&gt;There is always a tension, in that many of our users are biologists without a computer science background [to simplify, they're using Windows, Word, and MATLAB instead of Unix, vim/emacs, and Python] and they expect an integrated single-click graphical program. The solution we've found is to develop the library &lt;em&gt;first&lt;/em&gt;, and &lt;em&gt;then&lt;/em&gt; write separately an integrated solution based on this library.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Max Hunter and others for their comments on this post.&lt;/em&gt;&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>New year</title><link href="https://cyrille.rossant.net/new-year/" rel="alternate"></link><published>2016-01-01T00:00:00+01:00</published><updated>2016-01-01T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2016-01-01:/new-year/</id><content type="html">&lt;p&gt;I didn't write a lot lately: only 2 posts in 2015! I'll try to do better this year: more and shorter posts about programming, technology, and science. There's no shortage of topics to discuss.&lt;/p&gt;
&lt;p&gt;Happy New Year.&lt;/p&gt;</content><category term="misc"></category></entry><entry><title>A compiler infrastructure for data visualization</title><link href="https://cyrille.rossant.net/compiler-data-visualization/" rel="alternate"></link><published>2015-07-24T00:00:00+02:00</published><updated>2015-07-24T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2015-07-24:/compiler-data-visualization/</id><summary type="html">&lt;p&gt;There are many data visualization tools out there. Yet, I believe we're still lacking a robust, scalable, and cross-platform visualization toolkit that can handle today's massive datasets.&lt;/p&gt;
&lt;p&gt;Most existing tools target simple plots with a few hundreds or thousands of points: bar plots, scatter plots, histograms and the like. Typically …&lt;/p&gt;</summary><content type="html">&lt;p&gt;There are many data visualization tools out there. Yet, I believe we're still lacking a robust, scalable, and cross-platform visualization toolkit that can handle today's massive datasets.&lt;/p&gt;
&lt;p&gt;Most existing tools target simple plots with a few hundreds or thousands of points: bar plots, scatter plots, histograms and the like. Typically, these figures represent aggregated statistical quantities. Maps are also particularly popular, and there are now really great open source tools.&lt;/p&gt;
&lt;p&gt;Perhaps contrary to a common belief, this is not the end of the story. There are much more complex visualization needs in academia and industry, and I've always been unsatisfied by the tools at our disposal.&lt;/p&gt;


&lt;h2&gt;Complex visualizations&lt;/h2&gt;
&lt;p&gt;The complex visualizations I'll be talking about throughout this post are generally based on large datasets, and they may or may not be in 3D.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Examples of complex visualizations" src="/images/vispy-complex.png" /&gt;&lt;/p&gt;
&lt;h3&gt;Large datasets&lt;/h3&gt;
&lt;p&gt;Most plotting libraries can't handle visualizations with millions of points. Crashes due to out-of-memory errors are not uncommon.&lt;/p&gt;
&lt;p&gt;An often-heard counter-argument is that you're never going to plot millions of points when your screen rarely has more than a few million pixels. This is true with standard visualizations, but not with complex visalizations of raw, unstructured datasets, like the ones you may find in many scientific and industrial applications.&lt;/p&gt;
&lt;p&gt;To give only one example in the discipline I know: neurophysiologists can now routinely record in animals' brains a thousand of simultaneous digital signals sampled at 20 kHz. This represents 20 million points &lt;em&gt;per second&lt;/em&gt;. Recordings can last several hours or days. High-density 4k screens can now contain about 10 million pixels, maybe several times more in a few years.&lt;/p&gt;
&lt;p&gt;The scientists I know absolutely &lt;em&gt;do&lt;/em&gt; want to visualize as much data as possible. They may have two, three, even four HiDPI screens, and they're eager to see all signals in a given time interval, as much as their screens' resolution allows (and they're starting do to it with the visualization prototypes we're developing). This is an unprecedented opportunity to really see what's going on in the brain. There is no way around looking at the raw data directly, because they wouldn't know how to simplify the data or make statistical aggregates out of it.&lt;/p&gt;
&lt;p&gt;I am convinced that the demand for these sorts of visualization is real not only in neuroscience, but also in genomics, astronomy, particle physics, meteorology, finance, and many other scientific and industrial disciplines that deal with complex and massive datasets.&lt;/p&gt;
&lt;p&gt;&lt;img alt="That's many screens you've got here" src="http://www.timothysykes.com/wp-content/uploads/2011/04/desk.jpg" /&gt;&lt;/p&gt;
&lt;h3&gt;3D&lt;/h3&gt;
&lt;p&gt;The second characteristic of complex visualizations is often 3D: most plotting libraries are designed for 2D, and when they support 3D, they don't do it well because 3D is implemented as an afterthought. On the other hand, 3D visualization libraries tend to be old, heavy, hard to use and to extend, and they do not support 2D visualizations well. There are more modern 3D libraries, like three.js for example, but they target video games more than scientific visualization.&lt;/p&gt;
&lt;p&gt;Finally, there is always the option to resort to low-level tools like OpenGL, which no sane scientist will ever do.&lt;/p&gt;
&lt;h2&gt;VisPy: where we are now&lt;/h2&gt;
&lt;p&gt;These are all the reasons why we've started the &lt;a href="http://vispy.org"&gt;&lt;strong&gt;VisPy project&lt;/strong&gt;&lt;/a&gt; more than two years ago. We wanted to design a high-performance visualization library in Python that would handle massive datasets well, and where 2D and 3D visualization would both be first-class citizens. The main idea of VisPy is to transparently leverage the massively parallel graphics card through the OpenGL library for data visualization purposes.&lt;/p&gt;
&lt;p&gt;VisPy now has half a dozen of core contributors and tens of occasional contributors. We've also just reached the highly-respected milestones of 666 stars on GitHub.&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/_3YoaeoiIFI" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;However, I personally consider the project to be still in its infancy. There is still a whole lot of work before VisPy gets to a mature and stable state. If the &lt;a href="http://blog.jupyter.org/2015/07/07/project-jupyter-computational-narratives-as-the-engine-of-collaborative-data-science/"&gt;Jupyter developers admit considering the notebook (almost 5 years old, estimated 2 million users) as a "validated MVP" (Minimum Viable Product)&lt;/a&gt;, I can definitely see VisPy as a proof-of-concept/prototype. This might sound crazy, but it's really not. To give an idea, matplotlib, the state-of-the-art visualization library in Python, is almost 15 years old; Python and OpenGL are about 25 years old; UNIX was developed half a century ago; and so on and so forth. We like to consider software as a fast-paced environment, but, in many respects, time scales can be much slower than what we think.&lt;/p&gt;
&lt;p&gt;What will it take to bring the project to the next level? What can we do to ensure it lives through the next 5, 10, even 15 years?&lt;/p&gt;
&lt;h2&gt;Current challenges&lt;/h2&gt;
&lt;p&gt;For this to happen, &lt;strong&gt;I believe we need to rethink the entire logic of the project from the ground up&lt;/strong&gt;. There are three main reasons.&lt;/p&gt;
&lt;h3&gt;A pure Python cross-platform library?&lt;/h3&gt;
&lt;p&gt;From the very beginning, we wanted a pure Python library. We were all using Python for our research, and we had all developed our own OpenGL-based Python prototypes for data visualization. Performance was excellent in our respective prototypes. We weren't using any compiled C extension or Cython, because we didn't need to. We were able to leverage OpenGL's performance quite efficiently thanks to ctypes and NumPy. So we decided to go with a pure Python library.&lt;/p&gt;
&lt;p&gt;One of the many reasons was that we wanted to avoid compiled extensions at any cost. Packaging and distributing compiled Python libraries used to be an absolute pain. However, this is no longer the case thanks to Anaconda.&lt;/p&gt;
&lt;p&gt;I'm now thinking that the whole "pure Python" idea is a bit overrated. None of the main scientific Python libraries (NumPy, SciPy, matplotlib, scikit-learn, pandas) is in pure Python. What does "pure Python" even mean, really? VisPy calls the OpenGL C API through ctypes: is it "pure Python"? Also, you could even argue that a "pure Python" program is being interpreted by CPython, which is all written in C... Finally, there are other great data analysis platforms out there that could potentially benefit from advanced visualization capabilities, like Julia, R, etc. That's not something you could do with a pure Python library.&lt;/p&gt;
&lt;p&gt;Another problem comes from VisPy itself. VisPy implements a powerful but complex system for managing transformations between objects in a scene. Because it is in pure Python, there always have been significant performance issues. This is a critical problem in a high-performance visualization library that needs to process huge datasets in real time. These issues are now getting mitigated thanks to heroic efforts by Luke Campagnola. But it should come as no surprise that achieving high performance in a pure Python library is overly difficult. Spending so many efforts just for the sake of being "pure Python" is not worth it in my opinion.&lt;/p&gt;
&lt;p&gt;Finally, the most important problem with being pure Python comes from a design goal that came slightly after the project started. We wanted to support the web platform as well as Python thanks to &lt;strong&gt;WebGL&lt;/strong&gt;, the browser's implementation of OpenGL. The web platform is now extremely popular, even in the scientific community via the Jupyter notebook. Many data visualization libraries (like D3, Bokeh) are built partly or entirely on the web platform. More and more video games and game engines are being ported to WebGL. Given the efforts spent by the industry, I really believe that this trend will continue for many years.&lt;/p&gt;
&lt;p&gt;How do you make Python work in the browser? The browser's language is JavaScript, a language fundamentally different from Python. I've been obsessed by this question for a few years. I've explored many options. Unfortunately, none of them is really satisfying. Now, &lt;strong&gt;my conclusion about Python in the browser is that it's never gonna happen&lt;/strong&gt;, at least not in the way you might think (more on this later).&lt;/p&gt;
&lt;p&gt;There is a similar issue with mobile devices. Sadly, apart from the excellent &lt;a href="http://kivy.org/#home"&gt;Kivy project&lt;/a&gt;, Python on mobile devices is getting very little attention, and I'm not sure that's ever going to change. Yet, there would be a huge interest in creating mobile applications from data visualizations made for the desktop.&lt;/p&gt;
&lt;p&gt;I believe these are fundamental problems about Python itself, which, in the case of VisPy, cannot be satisfactorily solved with our current approach. We do have temporary solutions for now, VisPy does have an experimental WebGL backend that works in the Jupyter notebook (described in the &lt;a href="https://books.google.com/books?hl=en&amp;amp;lr=&amp;amp;id=6crECQAAQBAJ&amp;amp;oi=fnd&amp;amp;pg=PA89&amp;amp;ots=Jq7h5UT9TC&amp;amp;sig=aEZX3_JhW_P9fbHsHPqJAIWDH_c&amp;amp;redir_esc=y#v=onepage&amp;amp;q&amp;amp;f=false"&gt;WebGL Insights chapter&lt;/a&gt; that Almar Klein and I wrote this year), but it is fundamentally &lt;em&gt;experimental&lt;/em&gt;. Because of the WebGL support, we need to stick with the lowest common denominator between the desktop and the browser. This means we cannot support recent OpenGL features like geometry shaders, tesselation shaders, or compute shaders. These issues are at odds with the idea of designing a solid codebase that can be maintained over many years.&lt;/p&gt;
&lt;h3&gt;Python and OpenGL&lt;/h3&gt;
&lt;p&gt;Another fundamental problem comes from OpenGL itself.&lt;/p&gt;
&lt;p&gt;Modern OpenGL features a GPU-specific language named GLSL. GLSL is a C-like language that has nothing to do with Python. We believe that scientists should never have to write their own GPU code in a C variant. Therefore, in VisPy, we try to hide GLSL completely to the user.&lt;/p&gt;
&lt;p&gt;To make this possible, we need to bridge the gap between Python and GLSL. The graphics driver typically converts GLSL strings on-the-fly for the GPU. In VisPy, we have no other choice than generating GLSL strings dynamically. We do this with string templates, regular expressions, parsers and so on. We have a large collection of reusable GLSL components (notably contributed by Nicolas Rougier) that are put together automatically as a function of what the user wants to visualize. Designing and implementing a modular API for this was extremely challenging, and as a consequence the code is quite complex. Again, this complexity is inherent to OpenGL and to our desire to generate visualizations on-the-fly with a nice high-level Python API.&lt;/p&gt;
&lt;p&gt;There are many other problems with OpenGL. All sorts of bugs in the drivers, depending on the graphics card's manufacturer. These bugs are hard to fix, and they need to be worked around with various hacks in the code. Memory accesses in the shaders are limited. Interoperability with GPGPU frameworks like CUDA and OpenCL are possible in practice, but so hard and buggy that it's not even worth trying. OpenGL's API is extremely obscure, and we need to hide this in the code through a dedicated abstraction layer. OpenGL has accumulated a lot of technical debt over the last 25 or so years. Everyone in the OpenGL community is well aware of the issue.&lt;/p&gt;
&lt;p&gt;This is one of the cases where you get the feeling that the technology is working against you, not with you. And there's absolutely nothing you can do about it: it's just how things work.&lt;/p&gt;
&lt;h3&gt;OpenGL's future?&lt;/h3&gt;
&lt;p&gt;All of this explains why I was so incredibly excited by the &lt;a href="https://www.khronos.org/news/press/khronos-reveals-vulkan-api-for-high-efficiency-graphics-and-compute-on-gpus"&gt;announcement made by the Khronos Group in March&lt;/a&gt;. They acknowledged that OpenGL was basically doomed (at least that's my interpretation), and they decided to start from scratch with a brand new low-level API for real-time graphics named &lt;a href="https://www.khronos.org/vulkan"&gt;&lt;strong&gt;Vulkan&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In my opinion this is just the best decision they could have ever made.&lt;/p&gt;
&lt;p&gt;Compared to OpenGL, Vulkan is closer to the metal. It is designed at a different level of abstraction. Graphics drivers for Vulkan should be simpler, lighter and, hopefully, less buggy than before. Consequently, applications will have much more control on the graphics pipeline, but they'll also need to implement many more things, notably memory management on the GPU.&lt;/p&gt;
&lt;p&gt;A major feature of the new API is &lt;a href="https://www.khronos.org/spir"&gt;&lt;strong&gt;SPIR-V&lt;/strong&gt;&lt;/a&gt;, an LLVM-like intermediate language for the GPU. Instead of providing shaders using GLSL strings, graphics applications will have the possibility to provide low-level GPU bitcode directly. &lt;a href="http://www.phoronix.com/scan.php?page=news_item&amp;amp;px=khronos-coming-spirv-llvm"&gt;There should be tools to translate LLVM IR to SPIR-V&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;OpenGL and GLSL will still work as before through via dedicated conversion layers, for obvious retrocompatibility reasons. There will be tools to compile GLSL code to SPIR-V. But applications won't have to go through GLSL if they don't want to.&lt;/p&gt;
&lt;p&gt;This might just be the perfect solution for VisPy. Instead of mixing two different languages (Python and GLSL) with strings, templates, regexes, lexers and parsers, we could design a &lt;strong&gt;compiler architecture for data visualization around LLVM and SPIR-V&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Shaders and GPU kernels will no longer have to be written in GLSL; they could be written in &lt;strong&gt;any language that can be compiled down to LLVM&lt;/strong&gt; (and, as a consequence, to SPIR-V). This includes low-level languages like GLSL and C/C++, but also Python thanks to &lt;a href="http://numba.pydata.org/"&gt;&lt;strong&gt;Numba&lt;/strong&gt;&lt;/a&gt;. Numba can compile an increasing variety of pure Python functions to LLVM. The primary use-case of Numba is high-performance computing, but it could also be used to write GPU kernels for visualization.&lt;/p&gt;
&lt;p&gt;This could remove a huge layer of complexity in VisPy.&lt;/p&gt;
&lt;p&gt;It might also be a solution to the cross-platform problems. We could potentially port visualizations to the browser by compiling them to JavaScript thanks to &lt;a href="http://kripken.github.io/emscripten-site/"&gt;emscripten&lt;/a&gt;, or to mobile devices thanks to LLVM compilers for Android and iOS.&lt;/p&gt;
&lt;p&gt;I'd now like to open the discussion on what a future Vulkan-based data visualization toolkit could look like, on what use-cases it could enable.&lt;/p&gt;
&lt;p&gt;I should precise that everything that comes next is kind of speculative and depends on very partial information released by the Khronos group on early specification drafts. Also, I am well aware that this is a really ambitious and optimistic vision that might just be too hard to implement. But I believe it is worth trying. This journey is completely independent from the normal development of the VisPy library as it exists today. The two roads will only cross in the most optimistic case, and not before several years.&lt;/p&gt;
&lt;p&gt;Before we see in more details how all of this could work, let's describe a hypothetical data visualization use-case that could come true with Vulkan.&lt;/p&gt;
&lt;h2&gt;Use-case example&lt;/h2&gt;
&lt;p&gt;There is a new data analysis pipeline that is going to process terabytes of data, and you're in charge of writing the analysis and visualization software. Your users have highly specific visualization needs. They want a fast, reactive, and user-friendly interface to interact with the data in various and complex ways.&lt;/p&gt;
&lt;p&gt;You start to design a visualization prototype in the Jupyter notebook around your data. Through a Python API, you carefully design how to process and visualize the data on the GPU. This is not more complicated than &lt;a href="http://numba.pydata.org/numba-doc/dev/user/vectorize.html"&gt;creating a NumPy universal function (&lt;em&gt;ufunc&lt;/em&gt;) in pure Python with Numba&lt;/a&gt;: it's really the same idea of stream processing, but in a context of data visualization. You describe how your data is stored on the GPU, and how it's converted to vertices and pixels. There is a learning curve, but it is not as bad as OpenGL/GLSL because you are still writing 100% Python code.&lt;/p&gt;
&lt;p&gt;As part of this process, you also integrate interactivity by specifying how user actions (mouse, keyboard, touch gestures) influence the visualization.&lt;/p&gt;
&lt;p&gt;At this point, you can embed your interactive visualization in a desktop Python application (for example with PyQt).&lt;/p&gt;
&lt;p&gt;Now, your users are happy, they can visualize their data on the desktop, but they want more. They want a web interface to access, share, and visualize their data, all in the browser. The way it would happen today is that you'd hire one or two web developers to reimplement all your application in JavaScript and WebGL. Now, you have two implementations of the same applications, in two different languages, for two different platforms.&lt;/p&gt;
&lt;p&gt;I believe we can do better.&lt;/p&gt;
&lt;p&gt;You go back to your Python visualization. Now, instead of running it interactively, you &lt;em&gt;compile&lt;/em&gt; it automatically to a platform-independent bitcode file. Under the hood, this uses the LLVM platform. You get a binary file that implements the entire logic of your interactive visualization. This includes the GPU kernels, the rendering flow, and (possibly) interactivity. In a way, this is similar to running a C++ program generating a function dynamically via the LLVM API, versus compiling a function to an LLVM bitcode file.&lt;/p&gt;
&lt;p&gt;Once you have this file, you start writing your web application in HTML and JavaScript (maybe using some of the future Jupyter notebook components). But instead of reimplementing the whole visualization and interactivity logic, you compile your exported file to JavaScript via emscripten. Then, you have your whole interactive visualization in the browser practically for free.&lt;/p&gt;
&lt;p&gt;Of course, this will only work if Vulkan is eventually ported to the browser. There are no such plans yet, Vulkan being such an early project at this point, but I suppose it will depend on the user demand. We might obtain more details during &lt;a href="http://s2015.siggraph.org/"&gt;SIGGRAPH&lt;/a&gt; in a couple of weeks, where Vulkan could be discussed at length.&lt;/p&gt;
&lt;p&gt;Now, your users are even happier, but they want even more. They want a mobile application for visualizing their data interactively. Again, you could compile your platform-independent visualization file to Android or iOS (both platforms are LLVM backends). Or maybe, who knows, mobile browsers will support Vulkan at some point, so your web application will just work!&lt;/p&gt;
&lt;p&gt;Depending on your use-cases, the rest of the analysis pipeline can very well be implemented server-side in any language, like Python (potentially using Jupyter notebook components). It could even involve a cloud engine like Spark. The visualization logic could remain client-side, but you might have to implement custom level-of-detail techniques adapted to your data.&lt;/p&gt;
&lt;h2&gt;Architecture&lt;/h2&gt;
&lt;p&gt;What would it take to make this use-case a reality?&lt;/p&gt;
&lt;p&gt;There are several components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;strong&gt;compiler API&lt;/strong&gt; to specify interactive visualizations programmatically and compile them to platform-independent files&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;Vulkan runtime&lt;/strong&gt; that executes visualizations on the GPU&lt;/li&gt;
&lt;li&gt;Optionally, a &lt;strong&gt;CPU runtime&lt;/strong&gt; that executes visualizations on the CPU, as a fallback if a GPU is not available&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The API will have to be designed at the most appropriate level of abstraction: higher than Vulkan, but low enough to support a wide variety of use cases. This would be the Vulkan equivalent of VisPy's &lt;em&gt;gloo&lt;/em&gt; API, built on top of OpenGL. It would not have the limitations inherent to OpenGL.&lt;/p&gt;
&lt;p&gt;The API would cover memory management with data arrays on the GPU, compilation of shaders and kernels, and the rendering workflow.&lt;/p&gt;
&lt;h3&gt;Language&lt;/h3&gt;
&lt;p&gt;In what cross-platform languages could we implement these components? At least for the runtime, Python is not really an option because it cannot run on the browser or mobile devices.&lt;/p&gt;
&lt;p&gt;I believe that a sensible option (notably for the runtime) would be &lt;strong&gt;modern C++&lt;/strong&gt; (typically C++ 11).&lt;/p&gt;
&lt;p&gt;I used to dislike old-style C++, however I discovered in C++ 11 a really different language. It is modern, safe, mature, with a wide community and solid documentation. The standard library looks reasonably powerful and well-designed.&lt;/p&gt;
&lt;p&gt;C++ 11 can be compiled on many architectures, including JavaScript through the LLVM-based emscripten project. It seems to be well-supported on mobile devices as well. It is worth noting that the LLVM API itself is implemented in C++.&lt;/p&gt;
&lt;p&gt;Obviously, choosing a relatively low-level language like C++ doesn't mean that end-users will have to write a single line of C++. There could be a Python (3-only, while we're at it!) library wrapping the C++ engine via ctypes, cffi, Cython, or something else. This is not really different from wrapping OpenGL via ctypes like we do in VisPy. Instead of leveraging a graphics driver that we cannot control at all, we use a C++ library on which we have full control.&lt;/p&gt;
&lt;p&gt;While the runtime would likely be implemented in C++, the compiler could be written either in Python or in C++. If it is written in Python, other languages like R or Julia would need to implement it as well. But a Python implementation of the compiler might be an interesting first step.&lt;/p&gt;
&lt;p&gt;The C++ Vulkan and CPU runtimes could be ported to the browser and to mobile platforms via the LLVM toolchain.&lt;/p&gt;
&lt;h3&gt;Library of functions&lt;/h3&gt;
&lt;p&gt;The compiler and runtime are just the core components. Then, to make the users' lives easier, we'd have to implement a rich library of functions, visuals, interactivity routines, and high-level APIs. Having a highly modular architecture is critical here.&lt;/p&gt;
&lt;p&gt;There could be a rich user-contributed library of reusable pure LLVM functions, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;geometric transformations: linear, polar, logarithmic, various Earth projections, etc.&lt;/li&gt;
&lt;li&gt;color space transformations and colormaps&lt;/li&gt;
&lt;li&gt;easing functions for animations&lt;/li&gt;
&lt;li&gt;special mathematical functions&lt;/li&gt;
&lt;li&gt;linear algebra routines&lt;/li&gt;
&lt;li&gt;geometric tests&lt;/li&gt;
&lt;li&gt;collision detection&lt;/li&gt;
&lt;li&gt;tesselation algorithms&lt;/li&gt;
&lt;li&gt;classical mechanics equations&lt;/li&gt;
&lt;li&gt;optics and lighting equations&lt;/li&gt;
&lt;li&gt;standard marker equations&lt;/li&gt;
&lt;li&gt;antialiasing routines&lt;/li&gt;
&lt;li&gt;font generators with signed distance functions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Most of these functions could be written in any language that compiles to LLVM. This includes C/C++, GLSL, but also Python via Numba, making user contributions much easier.&lt;/p&gt;
&lt;p&gt;I should note that VisPy already implements many of these functions in Python or GLSL, so we could reuse a lot of code.&lt;/p&gt;
&lt;h3&gt;Memory model&lt;/h3&gt;
&lt;p&gt;Vulkan gives applications a lot of freedom regarding memory management. Therefore, we should come up with a simple yet powerful memory model that handles CPU-GPU transfers efficiently. One possibility could be to implement a NumPy-like ndarray structure that lives on both the CPU and GPU. It would be automatically and lazily synchronized between the two.&lt;/p&gt;
&lt;p&gt;This is the option chosen by &lt;a href="http://glumpy.github.io/"&gt;&lt;strong&gt;Glumpy&lt;/strong&gt;&lt;/a&gt;, VisPy's sister project maintained by Nicolas Rougier. VisPy uses a more complex memory model where data can be stored on the GPU only; while this might save some RAM, it is more complicated to work with this model. Also, the host has typically much more RAM than the GPU.&lt;/p&gt;
&lt;p&gt;SPIR-V has a nice support for arbitrarily complex data types, and a NumPy-like API could be used.&lt;/p&gt;
&lt;p&gt;One significant advantage of Vulkan and SPIR-V over OpenGL is that the framework encompasses OpenCL-like GPGPU kernels as well as visualization shaders. Therefore, it would be possible to execute computation kernels on the same GPU data structures than those that are used for visualization, with no copy at all. Typical examples include real-time visualization of numerically-simulated systems like fluids, n-body simulations, biological networks, and so on.&lt;/p&gt;
&lt;h3&gt;Higher-level APIs&lt;/h3&gt;
&lt;p&gt;All of this represents the core of a relatively low-level data visualization toolkit. A core that would let users create powerful and scalable interactive visualizations in any language, on any platform, and with optimal performance.&lt;/p&gt;
&lt;p&gt;On top of this, we could imagine plotting libraries with various programming interfaces. The hypothetical core I've been describing would be a sort of "game engine, but for data visualization".&lt;/p&gt;
&lt;h2&gt;Advantages&lt;/h2&gt;
&lt;p&gt;This vision represents a significant departure from the current state of the VisPy library. As a summary, I list here the advantages of choosing this path.&lt;/p&gt;
&lt;h3&gt;Future-proof&lt;/h3&gt;
&lt;p&gt;We can consider that OpenGL is on a rather slow deprecation road since Vulkan has been announced last March. Of course, OpenGL is so widely used that it's not going to disappear before many, many years. But by choosing to move forward with a brand new API, the Khronos Group sent a clear signal to the industry.&lt;/p&gt;
&lt;p&gt;I also believe that LLVM has a clear future.&lt;/p&gt;
&lt;h3&gt;Truly cross-platform&lt;/h3&gt;
&lt;p&gt;By moving forward with a C++ core and an LLVM-based compiler architecture, we obtain a truly cross-platform framework. We are not prisonners of a given language like Python, but we have the possibility to target various low-level and high-level languages at leisure. We have potentially access to x86-64, ARM, desktop, mobile, and browser platforms.&lt;/p&gt;
&lt;p&gt;This is made possible thanks to great projects such as LLVM, emscripten, clang, and Numba.&lt;/p&gt;
&lt;h3&gt;Modular and extendable architecture&lt;/h3&gt;
&lt;p&gt;A modular and extendable architecture is key to a future-proof and sustainable software project. An architecture designed around a compiler, a runtime, a library of pure LLVM functions, and a small number of APIs should meet these criteria.&lt;/p&gt;
&lt;h3&gt;A "pure Python" end-user experience&lt;/h3&gt;
&lt;p&gt;Perhaps ironically, achieving a "pure Python" end-user experience is made possible by designing a compiler architecture around C++ and LLVM, not by writing a 100% Python engine... I think that having an entire codebase in Python is not a requisite for being pure Python; however, having an entirely Pythonic Python API is. That your Python code leverages CPython, a C++ library, or is being compiled straight to LLVM IR or assembly doesn't matter much from the user's point of view. It's still "just Python".&lt;/p&gt;
&lt;h3&gt;Access to modern GPU features&lt;/h3&gt;
&lt;p&gt;Vulkan gives access to modern GPU features such as geometry shaders, tesselation shaders, and GPGPU compute kernels. This allows for an exceptional degree of customization in complex visualizations.&lt;/p&gt;
&lt;h3&gt;Optimal performance with C++&lt;/h3&gt;
&lt;p&gt;Being a pure Python library, VisPy needs to resort to many tricks to achieve good performance. For example, every OpenGL call is quite expensive, because of the driver overhead, but also because of the Python bindings. For this reason, we need to batch as many calls as possible on the GPU. This is the main motivation for the &lt;em&gt;collections&lt;/em&gt; API, where severaly independent but similar items are concatenated together and rendered at once on the GPU. This is a somewhat complex system.&lt;/p&gt;
&lt;p&gt;With a C++ engine and Vulkan command buffers, implementing collections might be unnecessary. We could still batch-rendering calls, but on the CPU instead of on the GPU, which is much easier. Performance might be similar than VisPy's collections, but this remains to be tested.&lt;/p&gt;
&lt;p&gt;More generally, on the CPU side, we have much more freedom on the algorithms we can implement. For example, implementing polygon triangulation should not represent a major problem, whereas it would be much more complicated in Python. Since it's C++, we're no longer limited by CPython's performance.&lt;/p&gt;
&lt;h3&gt;GPGPU-powered visualizations&lt;/h3&gt;
&lt;p&gt;The ability to combine compute kernels with visualization kernels on the GPU is also a major advantage of the system. This feature basically comes "for free" with Vulkan, and it is no longer necessary to mess with arcane interoperability commands.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Since this is such a major departure from the current state of the project, the system discussed here should be explored independently from the development of the VisPy library. This is an experiment to investigate a radically different system based on a brand new low-level graphics API.&lt;/p&gt;
&lt;p&gt;Obviously, these are just ideas that need a lot of discussions, and many details need to be worked out. But I think this is a really interesting project to pursue.&lt;/p&gt;
&lt;p&gt;If this experiment is successful, the system could potentially become the basis of VisPy in several years.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category><category term="dataviz"></category><category term="gpu"></category></entry><entry><title>NumPy in the browser: proof of concept with Numba, LLVM, and emscripten</title><link href="https://cyrille.rossant.net/numpy-browser-llvm/" rel="alternate"></link><published>2015-02-18T00:00:00+01:00</published><updated>2015-02-18T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2015-02-18:/numpy-browser-llvm/</id><summary type="html">&lt;p&gt;It's been a while since I wanted to try to bring some of NumPy to the browser. I've already discussed the motivations for this &lt;a href="https://cyrille.rossant.net/scientific-python-in-the-browser-its-coming/"&gt;in a previous post last year&lt;/a&gt;. As far as I'm concerned, the main use case would be to enable interactive data visualization in offline notebooks (including …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It's been a while since I wanted to try to bring some of NumPy to the browser. I've already discussed the motivations for this &lt;a href="https://cyrille.rossant.net/scientific-python-in-the-browser-its-coming/"&gt;in a previous post last year&lt;/a&gt;. As far as I'm concerned, the main use case would be to enable interactive data visualization in offline notebooks (including nbviewer), which often require client-based array operations for interactivity. In this post, I'll describe a proof-of-concept of compiling NumPy-aware Python functions to JavaScript using Numba, LLVM, and emscripten.&lt;/p&gt;


&lt;h2&gt;How to bring NumPy to the browser?&lt;/h2&gt;
&lt;p&gt;There are at least two quite different approaches.&lt;/p&gt;
&lt;p&gt;The first approach consists of reimplementing a tiny subset of NumPy in JavaScript. Many computations can be implemented with a minimum feature set of NumPy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the ndarray structure&lt;/li&gt;
&lt;li&gt;array creation functions&lt;/li&gt;
&lt;li&gt;indexing&lt;/li&gt;
&lt;li&gt;universal functions (ufuncs)&lt;/li&gt;
&lt;li&gt;a few shape manipulation routines&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Good performance can be expected in JavaScript by using &lt;a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Typed_arrays"&gt;TypedArrays&lt;/a&gt;: these structures represent data in contiguous segments of memory. The JIT compilers of modern browsers should be smart enough to compile regular loops on these arrays quite efficiently.&lt;/p&gt;
&lt;p&gt;Although only a small subset of NumPy would be sufficient for most purposes, this approach does represent quite some work. There is no fundamental challenge behind it: it just necessitates quite a bit of slightly boring work. Yet, I think there can be some interest in having a lightweight "numpy.js" JavaScript library.&lt;/p&gt;
&lt;p&gt;The other approach is radically different and much more sophisticated. Starting from a Python function operating on NumPy arrays, compile it to LLVM, and then compile the LLVM code to JavaScript. The road from Python/NumPy to LLVM already exists: it's called &lt;a href="http://numba.pydata.org/"&gt;&lt;strong&gt;Numba&lt;/strong&gt;&lt;/a&gt;. As for LLVM -&amp;gt; JavaScript, there's &lt;a href="http://kripken.github.io/emscripten-site/"&gt;&lt;strong&gt;emscripten&lt;/strong&gt;&lt;/a&gt;. In theory, it should be possible to connect the LLVM output of Numba to the LLVM input of emscripten. That sounds easy, right?&lt;/p&gt;
&lt;p&gt;Not so fast. A while ago, &lt;a href="https://groups.google.com/a/continuum.io/d/msg/numba-users/ELAzQPFl6Ec/dbq6eQK134sJ"&gt;I had asked the Numba developers about the feasibility of this approach&lt;/a&gt;. A major problem is that Python functions that are JIT-compiled with Numba use CPython under the hood. So some of CPython would have to be compiled to JavaScript as well. That sounds overly complicated, especially when it comes to small, self-contained Python functions operating exclusively on NumPy arrays. So I let it go.&lt;/p&gt;
&lt;p&gt;Recently, I heard about a new release of Numba, and I had another look. I discovered the &lt;a href="http://numba.pydata.org/numba-doc/0.17.0/glossary.html#term-nopython-mode"&gt;&lt;strong&gt;nopython mode&lt;/strong&gt;&lt;/a&gt;, which appeared to have been around for some time. This mode sounds like something interesting for our purposes: if Python functions are compiled to LLVM without relying on CPython at all, maybe they can be successfully compiled to JavaScript?&lt;/p&gt;
&lt;p&gt;Since I had long wanted to play with LLVM, I decided to have a go.&lt;/p&gt;
&lt;h2&gt;What is LLVM?&lt;/h2&gt;
&lt;p&gt;But first, what is LLVM exactly? It is a modular compiler architecture. The core of LLVM is a machine-independent assembly-like language called the &lt;strong&gt;LLVM Intermediate Representation&lt;/strong&gt; (IR). Think of it as a strongly-typed instruction set for a virtual machine (even if &lt;em&gt;the scope of the project is not limited to the creation of virtual machines&lt;/em&gt;, &lt;a href="http://en.wikipedia.org/wiki/LLVM"&gt;tells us Wikipedia&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The IR abstracts away details of the compilation target. As such, it is common target for various language frontends (C, C++, Haskell, Python, and many others) and microarchitecture backends (x86, ARM, Nvidia PTX which is used in CUDA-enabled GPUs, etc.). LLVM also comes with a powerful and modular architecture for optimization passes.&lt;/p&gt;
&lt;p&gt;LLVM seems to be quite popular these days, with a strong industrial support, notably by Apple. For example, Apple's &lt;strong&gt;Clang&lt;/strong&gt; is a LLVM-based C/C++/Objective C compiler that aims at replacing GCC's compilers for these languages. The compilers of modern languages like Julia and Rust are also built with LLVM.&lt;/p&gt;
&lt;h2&gt;What is Numba?&lt;/h2&gt;
&lt;p&gt;Now, the idea of Numba is the following. Take a Python function performing numerical operations on NumPy arrays. Normally, this function is interpreted by CPython. It performs Python and NumPy C API calls to execute these operations efficiently.&lt;/p&gt;
&lt;p&gt;With Numba, things happen quite differently. At runtime, the function bytecode is analyzed, types are inferred, and LLVM IR is generated before being compiled to machine code. In &lt;em&gt;nopython mode&lt;/em&gt;, the LLVM IR doesn't make Python C API calls. There are many situations where a Python function cannot be compiled in nopython mode because it uses non-trivial Python features or data structures. In this case, the &lt;em&gt;object mode&lt;/em&gt; is activated and the LLVM IR makes many Python C API calls.&lt;/p&gt;
&lt;p&gt;That's it for the theory. Now let's get our hands dirty.&lt;/p&gt;
&lt;h2&gt;Getting the LLVM IR of a Python function with Numba&lt;/h2&gt;
&lt;p&gt;Let's first import Numba (I installed the latest stable release with conda):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;llvmlite.binding&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;ll&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;llvmlite.ir&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;llvmir&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numba&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;numba&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;jit&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;numba&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;int32&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It seems that there is an easy way to get the LLVM IR of a JIT'ed function in the development version of Numba, but this version didn't work for me, so here is a custom function doing the same thing (we'll make extensive use of unstable API in this post so most things are likely to break with different versions of Numba and other libraries...):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;llvm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sig&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Return the LLVM IR of a @jit&amp;#39;ed function.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;sig&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;sig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;signatures&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_compileinfos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sig&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;library&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_final_module&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Let's define a trivial function operating on scalars:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, let's compile it in nopython mode:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nd"&gt;@jit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;nopython&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For simplicity, we have specified the input and output types explicitely. Numba can compile several overloaded versions of the same function at runtime, depending on the types of the arguments.&lt;/p&gt;
&lt;p&gt;Let's have a look at the generated LLVM IR:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;[...]&lt;/span&gt;

&lt;span class="c"&gt;; Function Attrs: nounwind&lt;/span&gt;
&lt;span class="k"&gt;define&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="vg"&gt;@__main__.f.int32.int32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="k"&gt;nocapture&lt;/span&gt; &lt;span class="nv"&gt;%ret&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="k"&gt;nocapture&lt;/span&gt; &lt;span class="k"&gt;readnone&lt;/span&gt; &lt;span class="nv"&gt;%env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="nv"&gt;%arg.x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="nv"&gt;%arg.y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="vg"&gt;#0&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="nl"&gt;entry:&lt;/span&gt;
  &lt;span class="nv"&gt;%.15&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;add&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="nv"&gt;%arg.y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%arg.x&lt;/span&gt;
  &lt;span class="k"&gt;store&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="nv"&gt;%.15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%ret&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;align&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;
  &lt;span class="k"&gt;ret&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;[...]&lt;/span&gt;

&lt;span class="k"&gt;define&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="vg"&gt;@wrapper.__main__.f.int32.int32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="k"&gt;nocapture&lt;/span&gt; &lt;span class="k"&gt;readnone&lt;/span&gt; &lt;span class="nv"&gt;%py_closure&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%py_args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%py_kws&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="nl"&gt;entry:&lt;/span&gt;
  &lt;span class="nv"&gt;%.4&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;alloca&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;align&lt;/span&gt; &lt;span class="m"&gt;8&lt;/span&gt;
  &lt;span class="nv"&gt;%.5&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;alloca&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;align&lt;/span&gt; &lt;span class="m"&gt;8&lt;/span&gt;
  &lt;span class="nv"&gt;%.6&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;**,&lt;/span&gt; &lt;span class="p"&gt;...)*&lt;/span&gt; &lt;span class="vg"&gt;@PyArg_ParseTupleAndKeywords&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%py_args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%py_kws&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="k"&gt;getelementptr&lt;/span&gt; &lt;span class="k"&gt;inbounds&lt;/span&gt; &lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;]*&lt;/span&gt; &lt;span class="vg"&gt;@.const.OO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;**&lt;/span&gt; &lt;span class="k"&gt;getelementptr&lt;/span&gt; &lt;span class="k"&gt;inbounds&lt;/span&gt; &lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*]*&lt;/span&gt; &lt;span class="vg"&gt;@.kwlist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;**&lt;/span&gt; &lt;span class="nv"&gt;%.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;**&lt;/span&gt; &lt;span class="nv"&gt;%.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nv"&gt;%.7&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;icmp&lt;/span&gt; &lt;span class="k"&gt;eq&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="nv"&gt;%.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
  &lt;span class="k"&gt;br&lt;/span&gt; &lt;span class="k"&gt;i1&lt;/span&gt; &lt;span class="nv"&gt;%.7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;label&lt;/span&gt; &lt;span class="nv"&gt;%entry.if&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;label&lt;/span&gt; &lt;span class="nv"&gt;%entry.endif&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;!prof&lt;/span&gt; &lt;span class="nv nv-Anonymous"&gt;!0&lt;/span&gt;

&lt;span class="nl"&gt;entry.if:&lt;/span&gt;                                         &lt;span class="c"&gt;; preds = %entry.endif1.1.endif, %entry.endif1.1, %entry.endif, %entry&lt;/span&gt;
  &lt;span class="nv"&gt;%merge&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;phi&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="k"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%entry.endif1.1&lt;/span&gt; &lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="k"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%entry.endif&lt;/span&gt; &lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="k"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%entry&lt;/span&gt; &lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;%.57&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%entry.endif1.1.endif&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="k"&gt;ret&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%merge&lt;/span&gt;

&lt;span class="nl"&gt;entry.endif:&lt;/span&gt;                                      &lt;span class="c"&gt;; preds = %entry&lt;/span&gt;
  &lt;span class="nv"&gt;%.11&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;load&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;**&lt;/span&gt; &lt;span class="nv"&gt;%.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;align&lt;/span&gt; &lt;span class="m"&gt;8&lt;/span&gt;
  &lt;span class="nv"&gt;%.12&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="vg"&gt;@PyNumber_Long&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%.11&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nv"&gt;%.13&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt; &lt;span class="vg"&gt;@PyLong_AsLongLong&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%.12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="vg"&gt;@Py_DecRef&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%.12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nv"&gt;%.16&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="vg"&gt;@PyErr_Occurred&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="nv"&gt;%.17&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;icmp&lt;/span&gt; &lt;span class="k"&gt;eq&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%.16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;null&lt;/span&gt;
  &lt;span class="k"&gt;br&lt;/span&gt; &lt;span class="k"&gt;i1&lt;/span&gt; &lt;span class="nv"&gt;%.17&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;label&lt;/span&gt; &lt;span class="nv"&gt;%entry.endif1.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;label&lt;/span&gt; &lt;span class="nv"&gt;%entry.if&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;!prof&lt;/span&gt; &lt;span class="nv nv-Anonymous"&gt;!1&lt;/span&gt;

&lt;span class="nl"&gt;entry.endif1.1:&lt;/span&gt;                                   &lt;span class="c"&gt;; preds = %entry.endif&lt;/span&gt;
  &lt;span class="nv"&gt;%.21&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;load&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;**&lt;/span&gt; &lt;span class="nv"&gt;%.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;align&lt;/span&gt; &lt;span class="m"&gt;8&lt;/span&gt;
  &lt;span class="nv"&gt;%.22&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="vg"&gt;@PyNumber_Long&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%.21&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nv"&gt;%.23&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt; &lt;span class="vg"&gt;@PyLong_AsLongLong&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%.22&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="vg"&gt;@Py_DecRef&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%.22&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nv"&gt;%.26&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="vg"&gt;@PyErr_Occurred&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="nv"&gt;%.27&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;icmp&lt;/span&gt; &lt;span class="k"&gt;eq&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%.26&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;null&lt;/span&gt;
  &lt;span class="k"&gt;br&lt;/span&gt; &lt;span class="k"&gt;i1&lt;/span&gt; &lt;span class="nv"&gt;%.27&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;label&lt;/span&gt; &lt;span class="nv"&gt;%entry.endif1.1.endif&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;label&lt;/span&gt; &lt;span class="nv"&gt;%entry.if&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;!prof&lt;/span&gt; &lt;span class="nv nv-Anonymous"&gt;!1&lt;/span&gt;

&lt;span class="nl"&gt;entry.endif1.1.endif:&lt;/span&gt;                             &lt;span class="c"&gt;; preds = %entry.endif1.1&lt;/span&gt;
  &lt;span class="nv"&gt;%.15.i&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;add&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt; &lt;span class="nv"&gt;%.23&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%.13&lt;/span&gt;
  &lt;span class="nv"&gt;%sext&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;shl&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt; &lt;span class="nv"&gt;%.15.i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;32&lt;/span&gt;
  &lt;span class="nv"&gt;%.51&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;ashr&lt;/span&gt; &lt;span class="k"&gt;exact&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt; &lt;span class="nv"&gt;%sext&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;32&lt;/span&gt;
  &lt;span class="nv"&gt;%.57&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="vg"&gt;@PyInt_FromLong&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i64&lt;/span&gt; &lt;span class="nv"&gt;%.51&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;br&lt;/span&gt; &lt;span class="k"&gt;label&lt;/span&gt; &lt;span class="nv"&gt;%entry.if&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;That's a lot of code for such a simple function! And yet I have only kept the most relevant bits.&lt;/p&gt;
&lt;p&gt;Two LLVM functions are defined here (&lt;code&gt;define&lt;/code&gt; instruction):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;@__main__.f.int32.int32&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@wrapper.__main__.f.int32.int32&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In LLVM, the names of global variables and functions start with a &lt;code&gt;@&lt;/code&gt;. Names can contain many non-alphanumerical characters, including dots &lt;code&gt;.&lt;/code&gt; and quotes &lt;code&gt;"&lt;/code&gt;. Comments start with a semi-colon &lt;code&gt;;&lt;/code&gt;. &lt;a href="http://llvm.org/docs/LangRef.html"&gt;The LLVM Language Reference Manual&lt;/a&gt; is a great source of documentation.&lt;/p&gt;
&lt;p&gt;LLVM IR is a strongly-typed language. As we can see in the function definitions, the first function takes four parameters (&lt;code&gt;i32*&lt;/code&gt;, &lt;code&gt;i8*&lt;/code&gt;, &lt;code&gt;i32&lt;/code&gt;, &lt;code&gt;i32&lt;/code&gt;) and returns a &lt;code&gt;i32&lt;/code&gt; value. &lt;code&gt;i8&lt;/code&gt; and &lt;code&gt;i32&lt;/code&gt; are 8-bit (=byte) and 32-bit integer types, respectively.&lt;/p&gt;
&lt;p&gt;Let's try to reverse-engineer this function. The return value of this LLVM value is a success/failure output value. The actual value returned by our Python function is set in the pointer passed as a first argument. I'm not quite clear about the purpose of the second &lt;code&gt;i8*&lt;/code&gt; argument; it might be related to the CPython environment and it doesn't seem important for what we're doing here. The last two &lt;code&gt;i32&lt;/code&gt; arguments are our actual arguments &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The body of that function seems to do what we expect:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;%.15&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;add&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="nv"&gt;%arg.y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%arg.x&lt;/span&gt;
&lt;span class="k"&gt;store&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="nv"&gt;%.15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%ret&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;align&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;add&lt;/code&gt; instructions adds our two input numbers and saves them into a local variable &lt;code&gt;%.15&lt;/code&gt;. Then, the &lt;code&gt;store&lt;/code&gt; instruction puts that value into the &lt;code&gt;%ret&lt;/code&gt; pointer passed as input: that's the return value of the function.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;@wrapper.__main__.f.int32.int32&lt;/code&gt; function is more complicated and we won't detail it at all here. This function wraps the core LLVM function &lt;code&gt;@__main__.f.int32.int32&lt;/code&gt; and exposes it to the Python interpreter. For example, our input numbers are actually Python objects. Some works needs to be done with the Python C API to extract the actual numbers from these objects and pass them to the core LLVM function.&lt;/p&gt;
&lt;p&gt;Since our ultimate goal is to compile &lt;code&gt;f()&lt;/code&gt; in JavaScript where there's no such thing as a CPython interpreter, we only need the &lt;code&gt;@__main__.f.int32.int32&lt;/code&gt; function here.&lt;/p&gt;
&lt;p&gt;Now, let's try to compile this to JavaScript with emscripten!&lt;/p&gt;
&lt;h2&gt;Compiling the LLVM IR to JavaScript with emscripten&lt;/h2&gt;
&lt;p&gt;Emscripten is an impressive piece of software. It can compile C/C++ code, even large projects like game engines (&lt;a href="https://blog.mozilla.org/blog/2014/03/12/mozilla-and-epic-preview-unreal-engine-4-running-in-firefox/"&gt;Unreal Engine&lt;/a&gt; for example), to JavaScript. Emscripten uses Clang to compile C/C++ to LLVM, and a custom LLVM backend named &lt;em&gt;Fastcomp&lt;/em&gt; to compile LLVM IR to JavaScript/&lt;strong&gt;asm.js&lt;/strong&gt; (&lt;em&gt;an extraordinarily optimizable, low-level subset of JavaScript&lt;/em&gt; &lt;a href="http://asmjs.org/"&gt;according to the project page&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Let's get started. I first tried to use the SDK installer, but I had some issues and I had to compile emscripten from source (note: I'm using Ubuntu 14.04 64-bit). &lt;a href="http://kripken.github.io/emscripten-site/docs/building_from_source/building_emscripten_from_source_on_linux.html#building-emscripten-on-linux"&gt;Here are the installation instructions&lt;/a&gt;. Also, I ended up using the &lt;code&gt;merge-3.5/merge-pnacl-3.5&lt;/code&gt; branches of emscripten and fastcomp, but using &lt;code&gt;master&lt;/code&gt; may work as well. The point was to ensure the same version of LLVM is used in Numba and emscripten, to avoid compatibility issues.&lt;/p&gt;
&lt;p&gt;For some reasons, fastcomp appears to share code with &lt;a href="http://en.wikipedia.org/wiki/Google_Native_Client"&gt;PNaCl&lt;/a&gt;, a project by Google that brings native applications to the Chrome browser through a sandboxing technology based on LLVM. It's a bit unclear to me how the two projects are related exactly.&lt;/p&gt;
&lt;p&gt;Here is a little function returning the LLVM library of a Python JIT'ed function. We'll use it later.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_lib&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sig_index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;sig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;signatures&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sig_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;compiled&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_compileinfos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sig&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;lib&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;compiled&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;library&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;lib&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, we save the LLVM IR code to a &lt;code&gt;.ll&lt;/code&gt; file (the extension for files containing LLVM IR code), and we call &lt;code&gt;emcc&lt;/code&gt; (the emscripten compiler):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;lib&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_lib&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;scalar.ll&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;fh&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;fh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_final_module&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;./emscripten/emcc scalar.ll -o scalar.js -O3 -s NO_EXIT_RUNTIME=1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getsize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;scalar.js&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;138022&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;!&lt;/span&gt;&lt;span class="n"&gt;cut&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt; &lt;span class="n"&gt;scalar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;js&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n5&lt;/span&gt;
&lt;span class="n"&gt;var&lt;/span&gt; &lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;!&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;typeof&lt;/span&gt; &lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="o"&gt;!==&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;undefined&amp;quot;&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="p"&gt;{};&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;
&lt;span class="n"&gt;var&lt;/span&gt; &lt;span class="n"&gt;asm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;global&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;use asm&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt; &lt;span class="k"&gt;global&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Int8Array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt; &lt;span class="k"&gt;global&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Int16Array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="n"&gt;EMSCRIPTEN_START_FUNCS&lt;/span&gt;
&lt;span class="n"&gt;function&lt;/span&gt; &lt;span class="n"&gt;ma&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;-&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt; &lt;span class="n"&gt;na&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;&lt;span class="n"&gt;ret&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We now have a JavaScript file that supposedly implements our function. How do we call it from JavaScript? After all, what we have here is a sort of function compiled for a virtual machine in JavaScript. With Numba, we had a LLVM wrapper for Python that let us call the function from Python. Here, we have nothing, and we need to write our own wrapper.&lt;/p&gt;
&lt;p&gt;A few more details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Programs compiled with emscripten are generally regular C programs with a main loop. However, what we want is an interactive access to our LLVM function from JavaScript. The &lt;code&gt;NO_EXIT_RUNTIME=1&lt;/code&gt; option prevents the runtime exit at the end of the function execution.&lt;/li&gt;
&lt;li&gt;According to the documentation of emscripten, there is a way to access the LLVM functions from JavaScript. However, I must have done something wrong because I only managed to access the &lt;code&gt;main&lt;/code&gt; entry point function (which actually doesn't exist).&lt;/li&gt;
&lt;li&gt;So I ended up creating a &lt;code&gt;main()&lt;/code&gt; function in LLVM wrapping &lt;code&gt;@__main__.f.int32.int32()&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are surely better ways to do it, but here is a little Python function adding this wrapper:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;add_wrapper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Add a main entry point calling the function.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;    define i32 @main(i64* &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;rg0, i8* &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;rg1, i32 &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;rg2, i32 &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;rg3)&lt;/span&gt;
&lt;span class="s2"&gt;    {&lt;/span&gt;
&lt;span class="s2"&gt;        &lt;/span&gt;&lt;span class="si"&gt;%o&lt;/span&gt;&lt;span class="s2"&gt;ut = call i32 @__main__.add.int32.int32(i64* &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;rg0, i8* &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;rg1, i32 &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;rg2, i32 &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;rg3)&lt;/span&gt;
&lt;span class="s2"&gt;        ret i32 &lt;/span&gt;&lt;span class="si"&gt;%o&lt;/span&gt;&lt;span class="s2"&gt;ut&lt;/span&gt;
&lt;span class="s2"&gt;    }&lt;/span&gt;
&lt;span class="s2"&gt;    declare i32 @__main__.add.int32.int32(i64*, i8*, i32, i32)&lt;/span&gt;
&lt;span class="s2"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="n"&gt;ll_module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ll&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_assembly&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ll_module&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;verify&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_llvm_module&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ll_module&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;RuntimeError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Warning: the module as already been added.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;lib&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It's a bit ugly because the wrapper is hard-coded with the function's signature.&lt;/p&gt;
&lt;p&gt;Once we have this &lt;code&gt;main()&lt;/code&gt; function, we can finally access it from JavaScript. But we're not done yet, because we need a way to retrieve the result. Recall that the result is stored via a pointer passed as a first argument to our LLVM function.&lt;/p&gt;
&lt;p&gt;After a bit of googling, I implemented a quick-and-dirty JavaScript wrapper:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;Buffer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="c1"&gt;// see http://kapadia.github.io/emscripten/2013/09/13/emscripten-pointers-and-pointers.html&lt;/span&gt;
    &lt;span class="c1"&gt;// data must be a TypedArray.&lt;/span&gt;
    &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;_typed_array&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="c1"&gt;// Get data byte size, allocate memory on Emscripten heap, and get pointer&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;nDataBytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;BYTES_PER_ELEMENT&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;dataPtr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;_malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;nDataBytes&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="c1"&gt;// Copy data to Emscripten heap (directly accessed from Module.HEAPU8)&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;dataHeap&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;Uint8Array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;HEAPU8&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;dataPtr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;nDataBytes&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="nx"&gt;dataHeap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;Uint8Array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
    &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;_data_heap&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;dataHeap&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;pointer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;dataHeap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;byteOffset&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nx"&gt;Buffer&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prototype&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;get&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;_typed_array&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;constructor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;_data_heap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                             &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;_data_heap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;byteOffset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                             &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;_typed_array&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nx"&gt;Buffer&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;prototype&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;free&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;_free&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;_data_heap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;byteOffset&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;is_array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;tp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;tp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;indexOf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// wrap the main() LLVM function&lt;/span&gt;
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;wrap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;

    &lt;span class="c1"&gt;// return pointer, env&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;arg_types&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;number&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;number&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;

    &lt;span class="c1"&gt;// one number per argument&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nx"&gt;args&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nx"&gt;arg_types&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;push&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;number&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;func_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;main&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="c1"&gt;// here&amp;#39;s how emscripten lets us access LLVM functions&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;cwrap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;func_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;number&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;arg_types&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;wrapped&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;return_arr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;

        &lt;span class="c1"&gt;// Wrap TypedArrays into emscripten buffers.&lt;/span&gt;
        &lt;span class="c1"&gt;// Buffer with the return buffer, initialized with an array&lt;/span&gt;
        &lt;span class="c1"&gt;// passed as argument.&lt;/span&gt;
        &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;buffer_out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;Buffer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;return_arr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

        &lt;span class="c1"&gt;// Wrap function arguments.&lt;/span&gt;
        &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;func_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;buffer_out&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;pointer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;

        &lt;span class="c1"&gt;// Skip the first argument which is the return array.&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nx"&gt;arguments&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;arg&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

            &lt;span class="c1"&gt;// Define the argument to send to the wrapped function.&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;is_array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="c1"&gt;// If that argument is an array, pass the pointer to&lt;/span&gt;
                &lt;span class="c1"&gt;// an emscripten buffer containing the data.&lt;/span&gt;
                &lt;span class="nx"&gt;arg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;Buffer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;arguments&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]).&lt;/span&gt;&lt;span class="nx"&gt;pointer&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="c1"&gt;// Otherwise, just pass the argument directly.&lt;/span&gt;
                &lt;span class="nx"&gt;arg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;arguments&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="nx"&gt;func_args&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;push&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;arg&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;

        &lt;span class="c1"&gt;// we call the LLVM function&lt;/span&gt;
        &lt;span class="nx"&gt;func&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;undefined&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;func_args&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

        &lt;span class="c1"&gt;// we get the result by reading the output buffer&lt;/span&gt;
        &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;buffer_out&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;get&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;result&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;};&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;wrapped&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This wrapper connects JavaScript TypedArray buffers to the virtual machine buffers and pointers. We finally get a chance to call our compiled LLVM functions from JavaScript. Here is an interactive example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;// We get the input numbers.&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;arg1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;parseInt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;#my_arg1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;val&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;arg2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;parseInt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;#my_arg2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;val&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;

&lt;span class="c1"&gt;// We wrap the LLVM main() function, specifying the signature.&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;add&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;wrap&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;int&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;int&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;

&lt;span class="c1"&gt;// We create a buffer that will contain the result.&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;Int32Array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;span class="nx"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;result&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;arg1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;arg2&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;// We display the result.&lt;/span&gt;
&lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;#my_output&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;val&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Recall that we started from this function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nd"&gt;@jit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;nopython&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We now can use this function from JavaScript. Type some numbers below:&lt;/p&gt;
&lt;iframe src="/widgets/emscripten-scalar.html" style="height: 60px;" scrolling="no"&gt;&lt;/iframe&gt;

&lt;p&gt;We have successfully compiled our first Python function to Javascript!&lt;/p&gt;
&lt;h2&gt;Now with NumPy arrays&lt;/h2&gt;
&lt;p&gt;This sounds promising. Now, let's try to go further and use NumPy arrays in our original function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nd"&gt;@jit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;[:]),&lt;/span&gt; &lt;span class="n"&gt;nopython&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;np_sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Let's have a look at the LLVM IR:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;llvm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np_sum&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;[...]&lt;/span&gt;
&lt;span class="k"&gt;define&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="vg"&gt;@&amp;quot;__main__.np_sum.array(int32,_1d,_A,_nonconst)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="k"&gt;nocapture&lt;/span&gt; &lt;span class="nv"&gt;%ret&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="k"&gt;nocapture&lt;/span&gt; &lt;span class="k"&gt;readnone&lt;/span&gt; &lt;span class="nv"&gt;%env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}*&lt;/span&gt; &lt;span class="k"&gt;nocapture&lt;/span&gt; &lt;span class="k"&gt;readonly&lt;/span&gt; &lt;span class="nv"&gt;%arg.x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="vg"&gt;#0&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="nl"&gt;entry:&lt;/span&gt;
  &lt;span class="nv"&gt;%.4&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;load&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}*&lt;/span&gt; &lt;span class="nv"&gt;%arg.x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;align&lt;/span&gt; &lt;span class="m"&gt;8&lt;/span&gt;
  &lt;span class="nv"&gt;%.4.fca.3.extract&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;extractvalue&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nv"&gt;%.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;
  &lt;span class="nv"&gt;%.4.fca.4.0.extract&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;extractvalue&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nv"&gt;%.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
  &lt;span class="nv"&gt;%.4.fca.5.0.extract&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;extractvalue&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nv"&gt;%.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
  &lt;span class="nv"&gt;%.35.i&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;icmp&lt;/span&gt; &lt;span class="k"&gt;eq&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt; &lt;span class="nv"&gt;%.4.fca.4.0.extract&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
  &lt;span class="k"&gt;br&lt;/span&gt; &lt;span class="k"&gt;i1&lt;/span&gt; &lt;span class="nv"&gt;%.35.i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;label&lt;/span&gt; &lt;span class="nv"&gt;%&amp;quot;numba.targets.arrayobj.array_sum_impl.array(int32,_1d,_A,_nonconst).exit&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;label&lt;/span&gt; &lt;span class="nv"&gt;%B16.endif.lr.ph.i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;!prof&lt;/span&gt; &lt;span class="nv nv-Anonymous"&gt;!0&lt;/span&gt;
&lt;span class="p"&gt;[...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The code is several hundreds of lines long. Again, we have a core LLVM function and a Python wrapper. Let's examine the signature of the core function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;i32&lt;/span&gt; &lt;span class="vg"&gt;@&amp;quot;__main__.np_sum.array(int32,_1d,_A,_nonconst)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%ret&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;%env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}*&lt;/span&gt; &lt;span class="nv"&gt;%arg.x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The signature follows the same pattern as before. The first argument is the integer output. The third argument is the most interesting: it represents our input array. It is a pointer to a structure containing six fields. After looking into Numba's code, we find out the signification of these six fields:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;i8* parent&lt;/code&gt;: apparently mostly relevant to CPython&lt;/li&gt;
&lt;li&gt;&lt;code&gt;i64 nitems&lt;/code&gt;: number of items in the array&lt;/li&gt;
&lt;li&gt;&lt;code&gt;i64 itemsize&lt;/code&gt;: number of bytes per item&lt;/li&gt;
&lt;li&gt;&lt;code&gt;i32* data&lt;/code&gt;: a pointer to the data buffer&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[1 x i64] shape&lt;/code&gt;: the shape of the array&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[1 x i64] strides&lt;/code&gt;: the strides of the array&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This time too, we need a wrapper. We'll do something even uglier than before: we'll hardcode the array metadata (dtype, shape, etc.) in the wrapper, considering a &lt;code&gt;(10,) int32&lt;/code&gt; array.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;add_wrapper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;    define i32 @main(i32* nocapture &lt;/span&gt;&lt;span class="si"&gt;%r&lt;/span&gt;&lt;span class="s2"&gt;et, i8* nocapture readnone &lt;/span&gt;&lt;span class="si"&gt;%e&lt;/span&gt;&lt;span class="s2"&gt;nv, i32* nocapture readonly &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;rr)&lt;/span&gt;
&lt;span class="s2"&gt;    {&lt;/span&gt;
&lt;span class="s2"&gt;        %tmp = alloca i8&lt;/span&gt;
&lt;span class="s2"&gt;        store i8 0, i8* %tmp&lt;/span&gt;
&lt;span class="s2"&gt;        &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg1 = insertvalue { i8*, i64, i64, i32*, [1 x i64], [1 x i64] } undef, i8* %tmp, 0             ; parent&lt;/span&gt;
&lt;span class="s2"&gt;        &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg2 = insertvalue { i8*, i64, i64, i32*, [1 x i64], [1 x i64] } &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg1, i64 10, 1                ; nitems&lt;/span&gt;
&lt;span class="s2"&gt;        &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg3 = insertvalue { i8*, i64, i64, i32*, [1 x i64], [1 x i64] } &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg2, i64 4, 2                ; itemsize&lt;/span&gt;
&lt;span class="s2"&gt;        &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg4 = insertvalue { i8*, i64, i64, i32*, [1 x i64], [1 x i64] } &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg3, i32* &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;rr, 3            ; data&lt;/span&gt;
&lt;span class="s2"&gt;        &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg5 = insertvalue { i8*, i64, i64, i32*, [1 x i64], [1 x i64] } &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg4, [1 x i64] [i64 10], 4    ; shape&lt;/span&gt;
&lt;span class="s2"&gt;        &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg6 = insertvalue { i8*, i64, i64, i32*, [1 x i64], [1 x i64] } &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg5, [1 x i64] [i64 4], 5    ; strides&lt;/span&gt;
&lt;span class="s2"&gt;        %ptr = alloca { i8*, i64, i64, i32*, [1 x i64], [1 x i64] }&lt;/span&gt;
&lt;span class="s2"&gt;        store { i8*, i64, i64, i32*, [1 x i64], [1 x i64] } &lt;/span&gt;&lt;span class="si"&gt;%a&lt;/span&gt;&lt;span class="s2"&gt;gg6, { i8*, i64, i64, i32*, [1 x i64], [1 x i64] }* %ptr&lt;/span&gt;
&lt;span class="s2"&gt;        &lt;/span&gt;&lt;span class="si"&gt;%o&lt;/span&gt;&lt;span class="s2"&gt;ut = call i32 @&amp;quot;__main__.np_sum.array(int32,_1d,_A,_nonconst)&amp;quot;(i32* &lt;/span&gt;&lt;span class="si"&gt;%r&lt;/span&gt;&lt;span class="s2"&gt;et, i8* &lt;/span&gt;&lt;span class="si"&gt;%e&lt;/span&gt;&lt;span class="s2"&gt;nv, { i8*, i64, i64, i32*, [1 x i64], [1 x i64] }* %ptr)&lt;/span&gt;
&lt;span class="s2"&gt;        ret i32 &lt;/span&gt;&lt;span class="si"&gt;%o&lt;/span&gt;&lt;span class="s2"&gt;ut&lt;/span&gt;
&lt;span class="s2"&gt;    }&lt;/span&gt;
&lt;span class="s2"&gt;    declare i32 @&amp;quot;__main__.np_sum.array(int32,_1d,_A,_nonconst)&amp;quot;(i32* nocapture, i8* nocapture readnone, { i8*, i64, i64, i32*, [1 x i64], [1 x i64] }* nocapture readonly)&lt;/span&gt;
&lt;span class="s2"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;ll_module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ll&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_assembly&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ll_module&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;verify&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_llvm_module&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ll_module&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;RuntimeError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Warning: the module as already been added.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;lib&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;What does this wrapper do? It takes the data buffer of an array as an input, it creates an appropriate structure for the corresponding NumPy array, and it calls our compiled Python function. Note that the &lt;code&gt;alloca&lt;/code&gt; instruction creates a pointer, while &lt;code&gt;insertvalue&lt;/code&gt; lets us create the LLVM ndarray structure.&lt;/p&gt;
&lt;p&gt;This wrapper will make our lives easier in JavaScript. We'll just pass the data buffer, and this LLVM wrapper will take care of creating the appropriate array structure. The drawback is that the shape of the array is fixed at compile time here. For sure, there are much cleaner ways to do it.&lt;/p&gt;
&lt;p&gt;Let's compile this with emscripten:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;lib&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_lib&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np_sum&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;add_wrapper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;array.ll&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;fh&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;fh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_final_module&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;./emscripten/emcc array.ll -o array.js -O3 -s NO_EXIT_RUNTIME=1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;256&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nl"&gt;Value:&lt;/span&gt;   &lt;span class="nv"&gt;%.4.fca.4.0.extract&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;extractvalue&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nv"&gt;%.4.insert15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="nl"&gt;Value:&lt;/span&gt;   &lt;span class="nv"&gt;%.4.insert15&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;insertvalue&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;i8&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;i32&lt;/span&gt;&lt;span class="p"&gt;*,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nv"&gt;%.4.insert12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="k"&gt;x&lt;/span&gt; &lt;span class="k"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="nv"&gt;%.4.field14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt;
&lt;span class="err"&gt;LLVM&lt;/span&gt; &lt;span class="nl"&gt;ERROR:&lt;/span&gt; &lt;span class="err"&gt;ExpandStructRegs&lt;/span&gt; &lt;span class="err"&gt;does&lt;/span&gt; &lt;span class="err"&gt;not&lt;/span&gt; &lt;span class="err"&gt;handle&lt;/span&gt; &lt;span class="err"&gt;nested&lt;/span&gt; &lt;span class="err"&gt;structs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This doesn't sound very good. A bit of googling tells us that &lt;a href="https://code.google.com/p/nativeclient/issues/detail?id=3815"&gt;PNaCl and emscripten do not support nested structures very well&lt;/a&gt;. The bug is still open at this time. Apparently, these projects target LLVM IR generated by Clang, which doesn't seem to use nested structs (?). I opened &lt;a href="https://github.com/numba/numba/issues/993"&gt;an issue&lt;/a&gt; on the Numba GitHub repository, and someone suggested to disable the Numba optimizations. It worked, but then I had another similar bug. It looked like a dead-end.&lt;/p&gt;
&lt;p&gt;Fortunately, after some more googling I found out that &lt;a href="http://code.google.com/p/nativeclient/issues/detail?id=3932"&gt;other people had encountered the same bug&lt;/a&gt; with LLVM IR code generated by Julia and Rust. On this bug report, someone mentioned &lt;a href="https://github.com/epdtry/rust-emscripten-passes"&gt;a fix for Rust&lt;/a&gt;. So I tried it. I had to patch a C++ file in PNaCl and run a custom LLVM pass on the LLVM IR generated by Numba. It was a long shot, but it actually worked.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;emscripten-fastcomp/build/Release/bin/opt &amp;quot;&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;-load=rust-emscripten-passes/BreakStructArguments.so &amp;quot;&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;-O3 -break-struct-arguments -globaldce array.ll -S -o array_fixed.ll&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;./emscripten/emcc array_fixed.ll -o array.js -O3 -s NO_EXIT_RUNTIME=1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is the result. Let's first recall the original function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nd"&gt;@jit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;[:]),&lt;/span&gt; &lt;span class="n"&gt;nopython&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;np_sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Type some numbers below to compute the sum (no more than 10 numbers):&lt;/p&gt;
&lt;iframe src="/widgets/emscripten-array.html" style="height: 80px;" scrolling="no"&gt;&lt;/iframe&gt;

&lt;p&gt;This is better than what I expected! I also managed to pass 2D arrays with a little more work with the wrappers. The following example computes the index of the row with the maximum value for &lt;code&gt;x&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nd"&gt;@numba&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numba&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numba&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;[:,::&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Click on a number to change it:&lt;/p&gt;
&lt;iframe src="/widgets/emscripten-table.html" style="height: 350px;" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h2&gt;Performance&lt;/h2&gt;
&lt;p&gt;I've done some quick and somewhat non-scientific benchmarks. The test function is just &lt;code&gt;np.sum()&lt;/code&gt; on an array containing one million random 32-bit integers uniformly sampled between -100 and 100. On my laptop, NumPy computes the sum in 0.85 ms. What about Numba/Emscripten and vanilla JavaScript? Click on the button to run the benchmark yourself:&lt;/p&gt;
&lt;iframe src="/widgets/emscripten-benchmark.html" style="height: 200px;" scrolling="no"&gt;&lt;/iframe&gt;

&lt;p&gt;The Emscripten-compiled version appears to be 1-2 orders of magnitude slower than vanilla JavaScript and NumPy.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;There are several things that I didn't manage or didn't try to do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Returning an array&lt;/li&gt;
&lt;li&gt;Passing several arrays as arguments&lt;/li&gt;
&lt;li&gt;Using ufuncs&lt;/li&gt;
&lt;li&gt;Using array operations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although interesting in itself, this proof-of-concept has important limitations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is inherently limited by what Numba's nopython mode provides. Currently, just the most basic constructs of &lt;a href="http://numba.pydata.org/numba-doc/0.17.0/reference/pysupported.html"&gt;Python&lt;/a&gt; and &lt;a href="http://numba.pydata.org/numba-doc/0.17.0/reference/numpysupported.html"&gt;NumPy&lt;/a&gt; are available in this mode. There is no array creation, reshaping, no array operations without preallocating the output arrays, etc. Python features are also quite limited; for example, no containers (lists, dicts, sets, etc.) are available as these constructs require the Python C API. It's unclear to me how much the Numba devs want to implement in the nopython mode.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There is currently limited interest in using this approach compared to writing vanilla JavaScript by hand when needed. Fore sure, JavaScript doesn't support ndarrays (even if there are some JS &lt;a href="https://github.com/scijs/ndarray"&gt;ndarray libraries&lt;/a&gt; out there), but we've seen that Numba support for NumPy array computations is still a bit limited. Things would be quite different if we could compile a significant and non-trivial Python/NumPy codebase in nopython mode.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I hard-coded the LLVM wrappers manually, which is quite horrible. However, I believe it would not be too complicated to build such wrappers dynamically using llvmlite.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Performance could be better.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This seems obvious, but: this approach only lets you compile Python functions ahead-of-time. Once you're in JavaScript, you can't write or compile your own functions on-the-fly. By contrast, the first approach I described in the introduction would let you do that.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The whole approach is quite hackish (you need to apply obscure patches to unstable branches of various projects written in 3 or 4 different languages) and it feels like you're trying to fit a square peg in a round hole. I don't believe it could be ever used in production in any form.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Still, it was a lot of fun!&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>Big Data visualization with WebGL, part 2: VisPy</title><link href="https://cyrille.rossant.net/big-data-visualization-webgl-part2/" rel="alternate"></link><published>2014-12-11T00:00:00+01:00</published><updated>2014-12-11T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2014-12-11:/big-data-visualization-webgl-part2/</id><summary type="html">&lt;p&gt;In this post series, I'm describing the big data visualization platform I'm currently developing with WebGL. I'll detail in this second post the &lt;a href="http://vispy.org"&gt;VisPy library&lt;/a&gt; which is the basis of the project.&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cyrille.rossant.net/big-data-visualization-webgl-part1/"&gt;Part 1: Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Part 2: VisPy&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Birth of the project&lt;/h2&gt;
&lt;p&gt;I started to be interested in high-performance data …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post series, I'm describing the big data visualization platform I'm currently developing with WebGL. I'll detail in this second post the &lt;a href="http://vispy.org"&gt;VisPy library&lt;/a&gt; which is the basis of the project.&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cyrille.rossant.net/big-data-visualization-webgl-part1/"&gt;Part 1: Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Part 2: VisPy&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Birth of the project&lt;/h2&gt;
&lt;p&gt;I started to be interested in high-performance data visualization technologies three years ago. I was left unsatisfied by existing visualization libraries in Python like matplotlib. Although rich and powerful, matplotlib is slow when it comes to interactive visualization, particularly with datasets containing more than a few thousands of points. Yet, I was often dealing with digital time-dependent signals containing millions of points or more. It struck me to find out that no existing library would let me pan and zoom in a plot containing a long signal. More generally, there was no way to visualize interactively a large dataset.&lt;/p&gt;
&lt;p&gt;Being familiar with graphics processing units (GPUs) for general-purpose computing, I started to investigate the possibility to leverage the hardware acceleration offered by these devices for interactive data visualization. I ended up releasing an experimental visualization toolkit named Galry for this purpose. With Galry, I was able to interactively explore plots containing tens to hundreds of millions of points. I've already detailed this work in previous posts (&lt;a href="https://cyrille.rossant.net/introducing-galry/"&gt;here&lt;/a&gt;, &lt;a href="https://cyrille.rossant.net/shaders-opengl/"&gt;here&lt;/a&gt;, &lt;a href="https://cyrille.rossant.net/galrys-story-or-the-quest-of-multi-million-plots/"&gt;here&lt;/a&gt;, and &lt;a href="https://cyrille.rossant.net/hardware-accelerated-interactive-data-visualization-in-python/"&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In late 2012, other developers of similar libraries and I decided to join forces to create a brand new visualization library that would scale to very big datasets. The VisPy library was born.&lt;/p&gt;
&lt;h2&gt;What is VisPy?&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://vispy.org"&gt;VisPy&lt;/a&gt; is a scientific visualization library in Python that focuses on scalability and performance. It is based on OpenGL, an open industry-standard visualization library that can leverage the hardware acceleration of graphics processing units.&lt;/p&gt;
&lt;p&gt;&lt;img alt="VisPy examples" src="https://cyrille.rossant.net/images/vispy-examples.png" /&gt;&lt;/p&gt;
&lt;p&gt;VisPy focuses on &lt;em&gt;modern&lt;/em&gt; OpenGL. Whereas legacy OpenGL uses a fixed function pipeline with a limited predefined list of rendering features, modern OpenGL lets users customize all aspects of the rendering pipeline. This is done through through small programs named &lt;strong&gt;shaders&lt;/strong&gt;. These programs are written in a low-level C-like language called GLSL. Shaders run on the GPU and benefit from the massively parallel architecture of GPUs.&lt;/p&gt;
&lt;p&gt;A major challenge of the project is to offer visualization facilities that are simultaneously user-friendly, flexible, and efficient. The high flexibility of OpenGL should be reflected by the user API. Yet, these constraints tend to be mutually exclusive. An easy-to-use library tends to offer less possibilities than a complex one. This is particularly problematic in a visualization library, where users needs can be highly diverse.&lt;/p&gt;
&lt;p&gt;To overcome these issues, VisPy provides several interfaces and abstraction levels that vary in terms of accessibility and flexibility. These interfaces are presented here in decreasing order of user-friendliness, and increasing order of flexibility.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;plot&lt;/strong&gt; interface will offer a high-level plotting API similar to the interfaces provided by other visualization toolkits like matplotlib, bokeh, ggplot, and others. This interface will be available in the long term; in the meantime, VisPy will offer a fast backend to these popular high-level interfaces.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;scene&lt;/strong&gt; interface lets users position graphical objects (also known as &lt;em&gt;visuals&lt;/em&gt;) in 2D or 3D within a scene graph. Various cameras implementing specific interaction patterns are provided.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Visuals&lt;/strong&gt; are types of graphical objects like points, lines, polygons, meshes, graphs, images, volumes, among others. Advanced users can customize existing visuals or create brand new visuals.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Gloo&lt;/strong&gt; offers a Pythonic, object-oriented interface to OpenGL. The OpenGL API is known for its verbosity and complexity. Yet, the main concepts are relatively simple. Gloo lets users easily create GLSL shaders, bind GLSL variables to Python variables and NumPy arrays, and render OpenGL programs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although quite young and relatively experimental at this point, VisPy is slowly starting to mature and to get a user base. At this point, gloo is quite stable, whereas the visuals and scene interfaces are still experimental and rough around the edges. We expect to make good progress on these interfaces in early 2015.&lt;/p&gt;
&lt;h2&gt;WebGL backend&lt;/h2&gt;
&lt;p&gt;Although VisPy is primarily meant to execute on a desktop running Python, we are also working on a WebGL backend. There are two use-cases for this backend:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Showing interactive VisPy visualizations in the IPython/Jupyter notebook.&lt;/li&gt;
&lt;li&gt;Exporting interactive visualizations to a standalone HTML document.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Going forward, we would love to let users export interactive applications written with Python and VisPy into standalone web/mobile applications.&lt;/p&gt;
&lt;p&gt;In the next post, I'll describe one of the key components of VisPy's distributed architecture.&lt;/p&gt;</content><category term="misc"></category><category term="dataviz"></category><category term="gpu"></category></entry><entry><title>Writing the IPython Cookbook</title><link href="https://cyrille.rossant.net/writing-ipython-cookbook/" rel="alternate"></link><published>2014-10-30T00:00:00+01:00</published><updated>2014-10-30T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2014-10-30:/writing-ipython-cookbook/</id><summary type="html">&lt;p&gt;My latest book was released a few weeks ago. This project has been one of the most challenging projects I've ever done, and not necessarily for the reasons I would have originally thought. Here is a little story of those fifteen months writing the IPython cookbook.&lt;/p&gt;


&lt;p&gt;The story begins shortly …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My latest book was released a few weeks ago. This project has been one of the most challenging projects I've ever done, and not necessarily for the reasons I would have originally thought. Here is a little story of those fifteen months writing the IPython cookbook.&lt;/p&gt;


&lt;p&gt;The story begins shortly after the release of the IPython minibook, my first book, and the prequel of the cookbook. The editors proposed me to write a follow-up to this introduction to IPython, and I accepted. I had felt limited in terms of page count while writing the minibook, and I thought it would be a great idea to expand further on the subjects I couldn't develop properly in the minibook.&lt;/p&gt;
&lt;p&gt;The only constraint was that this new book would be a &lt;em&gt;cookbook&lt;/em&gt;. This was a very strong constraint. The book had to be a collection of short focused recipes, each tackling a very specific problem.&lt;/p&gt;
&lt;p&gt;I then spent a few days working on a detailled table of contents. My idea was really to expand on the topics addressed in the minibook, namely the use of IPython and the scientific Python stack to solve problems in numerical analysis and data science. I came up with a list of fifteen chapters covering a wide range of the subject.&lt;/p&gt;
&lt;p&gt;I organized the timeline of the next 6-9 months with the help of the IPython developers. IPython 1.0 had yet to be released, but I wanted to target 2.0 in order to cover the interactive widgets. I had to organize my work carefully, because I was going to start the writing before the availability of some critical features. For this reason, I was unable to write the chapters in order. I came up with a very precise writing order, with the chapters depending the most on the widgets being due last. For example, I planned to write the chapter dedicated to the notebook &lt;em&gt;last&lt;/em&gt;, whereas it is one of the first chapters in the book.&lt;/p&gt;
&lt;p&gt;Having such a rigid cookbook structure for the book made it easier to plan the writing. Since all recipes were relatively independent, I could create them in any order and even in parallel.&lt;/p&gt;
&lt;p&gt;In the end, it was clear to me that this would be a hard and challenging project. I just had no idea that it would be &lt;em&gt;that&lt;/em&gt; hard.&lt;/p&gt;
&lt;h2&gt;Planning&lt;/h2&gt;
&lt;p&gt;I started to lay out the list of recipes in every chapter. I wanted to cover a broad range of the subject without entering too much into the details of every method. Further, I also wanted to illustrate all methods on various real-world examples.&lt;/p&gt;
&lt;p&gt;I kept a few text files with all ideas I had and a provisional list of recipes. Using simple text files using the Markdown syntax, synchronized with Dropbox, is the most effective way I know to keep notes organized. I had tried Evernote and other similar services, and I always ended up coming back to my little text files. It's just so simple and effective.&lt;/p&gt;
&lt;p&gt;Over the course of many months, I would constantly update my notes as ideas went on. I also kept a bookmark folder with all interesting websites I could find. This would become the main source of references for the book.&lt;/p&gt;
&lt;p&gt;I then started to write the very first chapters over the summer.&lt;/p&gt;
&lt;p&gt;I had a precise and relatively tight timeline imposed by the editors. I chose to stick to a virtual timeline, much tighter, by security. This way, I would always be ahead of schedule, or at least I wouldn't miss the editors' timeline.&lt;/p&gt;
&lt;p&gt;In practice, this proved to be essential. Since my virtual timeline was so tight (a couple of weeks per chapter), I always had to push back a bit the remaining deadlines. But I always managed to respect the official deadlines. I also made use of the few months before the official start of the writing; I was able to start the writing early and always be ahead of schedule.&lt;/p&gt;
&lt;h2&gt;Microsoft Word and the notebook&lt;/h2&gt;
&lt;p&gt;Like for the minibook, I started to write the book in this wonderful program called Microsoft Word. As all programmers know, writing text and code examples in Word is a real joy when we're used to text editors (and yet, I'm not a vi or emacs guru, I only use graphical text editors). Since the publisher's workflow is built around this program, I had no choice but using it for the book. I set up a few keyboard shortcuts to make the experience less painful, but it became clear that it would be nearly impossible to write &lt;em&gt;500 pages&lt;/em&gt; of text, code, and mathematical equations in Word. The only tool I wanted to use was obviously the IPython notebook.&lt;/p&gt;
&lt;p&gt;At first, I had a small Python script that would convert notebooks to formatted ASCII text that I could copy and paste in Word. I could write and test the code in the notebook. I did that for a couple of chapters, and then I gave up. I just wanted to write &lt;em&gt;everything&lt;/em&gt; in the notebook, not just the code. Text (rich text with bold, italics, etc.), lists, input code, output text, figures, equations, references, links, Tip boxes, and so on and so forth.&lt;/p&gt;
&lt;p&gt;So I tried something crazy. I investigated the possibility to write a full notebook-to-Word converter that was adapted to the Word template provided by the publisher. I knew that automating this process would take a lot of work, but would be beneficial in the long run. After all, I had more than &lt;em&gt;one hundred&lt;/em&gt; recipes to write (one recipe = one notebook).&lt;/p&gt;
&lt;p&gt;I explored a few options, notably using the Open XML format, or using COM (an inter-process communication framework for Windows). I can't remember exactly why, but I decided not to use Open XML. I might have thought that I had to use the old &lt;code&gt;.doc&lt;/code&gt; format, because the publisher was still using old versions of Word (I'm not sure if that's true anymore). Anyway, I ended up playing with COM in Python.&lt;/p&gt;
&lt;p&gt;It wasn't as bad as it sounds. Word's COM interface is &lt;em&gt;okay&lt;/em&gt;, and using it from Python is straightforward (I was "fortunate" enough to be a Windows user at the time). I wrote a small Python class to write documents programmatically from Python, and using the &lt;code&gt;.dot&lt;/code&gt; template that had been provided by the publisher.&lt;/p&gt;
&lt;p&gt;The hard part was actually to write the converter: parsing the notebook's JSON, including Markdown text. I basically had to write my own Markdown parser using a battery of regular expressions in order to support lists, equations, code, and so on. It wasn't an easy task, especially given that I was running out of time. I could have used an existing Markdown parser but I didn't manage to use them properly. My quick-and-dirty converter seemed to work okay, although not very quickly (the bottleneck seemed to be due to the inter-process communication anyway).&lt;/p&gt;
&lt;p&gt;For images, I wanted to have the possibility to integrate images with the Markdown syntax, or to use matplotlib figures. For the latter situation, all I had to do was to save the plots in PNG and integrate them in Word. I used a custom matplotlib parameter file, notably to use a higher DPI.&lt;/p&gt;
&lt;p&gt;Supporting LaTeX equations was harder. I didn't manage to convert them into Microsoft Equations, and I wasn't sure they would be supported by the publisher anyway. So I decided to convert all equations to images. I took some code from matplotlib to do that, using my local LaTeX installation.&lt;/p&gt;
&lt;p&gt;I used cell metadata in the notebook to specify some formatting options, like Tip boxes.&lt;/p&gt;
&lt;p&gt;Eventually, after maybe a month of work, I ended up with a command-line tool that took a list of notebooks and generated an entire chapter in Word, perfectly and entirely formatted. This was a clear victory, because it meant that I was able to write &lt;em&gt;exclusively&lt;/em&gt; in the notebook without even thinking about Word. It meant I could just focus on the text, the examples, and the code, and not on how unhappy I was to use Word.&lt;/p&gt;
&lt;p&gt;If only I knew what would come next.&lt;/p&gt;
&lt;p&gt;In the meantime anyway, I was relieved.&lt;/p&gt;
&lt;h2&gt;The first draft&lt;/h2&gt;
&lt;p&gt;I wrote the first draft within several months. The hardest bit was to find interesting examples and use-cases illustrating each method. I tried to use examples from a wide variety of disciplines in order to emphasize the wide applicability of the Python scientific stack today.&lt;/p&gt;
&lt;p&gt;Finding compelling open datasets that could be used to illustrate specific methods wasn't easy. Getting a good idea is not enough: you have to test it and check that it gives interesting results.&lt;/p&gt;
&lt;p&gt;The rigid structure imposed by the cookbook format was both interesting and challenging. Every recipe had to contain an introduction, a list of installation instructions and requirements (&lt;em&gt;Getting ready&lt;/em&gt;), a numbered list of steps (&lt;em&gt;How to do it&lt;/em&gt;), the explanations (&lt;em&gt;How it works&lt;/em&gt;), a discussion (&lt;em&gt;There's more&lt;/em&gt;), and a list of references. At least I didn't have to care about the structure as it was all imposed to me. However, some recipes didn't fit this outline very well. The constraint of putting the instructions before the explanations didn't always work. Sometimes you want to understand what you're doing &lt;em&gt;while&lt;/em&gt; you're doing it, not &lt;em&gt;after&lt;/em&gt;. Some recipes were also a list of tips rather than a list of instructions. So I had to fight a bit with the editors to alleviate this constraint in a few recipes.&lt;/p&gt;
&lt;p&gt;Eventually, I had finished all recipes by the end of the winter.&lt;/p&gt;
&lt;h2&gt;The revisions&lt;/h2&gt;
&lt;p&gt;Shorty after, I started to receive the first reviews of my chapters by the technical reviewers. This is where my notebook-to-Word workflow started to be problematic. The reviews were made in the Word documents themselves (sent by e-mail), using this awesome &lt;em&gt;Track changes&lt;/em&gt; feature. So I had to make corrections in the Word documents themselves, not in the notebooks. Since I didn't have the time to make a reverse Word-to-notebook converter, my process was unidirectional. There was no going back. Once I'd started to edit the automatically-generated Word documents, I couldn't go back to the notebook, and the two versions diverged permanently.&lt;/p&gt;
&lt;p&gt;All code changes had to be done twice: in the text, and also in the notebook (so that future readers get the last version of the code by downloading the notebooks).&lt;/p&gt;
&lt;p&gt;The reviews were globally positive, and I didn't have an enormous amount of work to do for the revisions.&lt;/p&gt;
&lt;p&gt;That being said, I had to add a few new recipes, because some subjects were not sufficiently covered in the first draft according to some reviewers. This was something unusual at this stage, so I had to convince my editors to let me do it.&lt;/p&gt;
&lt;p&gt;Finally, I finished the second draft within a couple of months.&lt;/p&gt;
&lt;h2&gt;The editing process&lt;/h2&gt;
&lt;p&gt;Once all the writing was finished, the next stage started. The goal was to go from the revised manuscript in Word to a corrected, proof-read, edited, laid out PDF. Perhaps surprisingly, this proved to be by far the hardest and most painful experience ever.&lt;/p&gt;
&lt;p&gt;A team of half a dozen editors appointed by the publisher started to process the entire manuscript in parallel to check for errors, inconsistencies, typos, grammar errors, and so on. That's the theory. In practice, this stage ended up in a chaotic nightmare.&lt;/p&gt;
&lt;p&gt;First, all editors had different ways of working, different opinions on the many conventions that compose a book, and were differently zealous. In the end, every chapter looked different in the way the recipes were organized, the links and references were presented, and so on and so forth.&lt;/p&gt;
&lt;p&gt;Second, some editors decided unilaterally to change the formatting of some words, to add or delete some words here and there, or even to delete entire paragraphs. These changes would make sense when they are motivated by actual issues in the text. However, this wasn't the case in the majority of instances. The worse part is that these changes would make a sentence or a paragraph incomprehensible, misleading, or just plain wrong. I often had to look back in the original version to understand what I originally meant and to fix the change.&lt;/p&gt;
&lt;p&gt;There could be hundreds of such changes in a single chapter (multiplied by fifteen chapters). Word's &lt;em&gt;Track changes&lt;/em&gt; feature made the process even more enjoyable. It not only tracks changes in the text, but also formatting and many other non-relevant changes. In the end, the actual changes that could result in errors were flooded within thousands of non-relevant edits. I couldn't find a way to automatically filter these non-relevant edits.&lt;/p&gt;
&lt;p&gt;Oh, and if you forget to enable &lt;em&gt;Track changes&lt;/em&gt;, then your changes are completely lost. This is because Word tracks actual changes rather than comparing two versions like a sane version system like Git would do.&lt;/p&gt;
&lt;p&gt;I spent tens if not hundreds of hours tracking and correcting these edits. It is ironic to think that this process was supposed to increase the overall quality of the book. If I hadn't been sufficiently vigilant, many "new" errors (introduced during the editing phase) would have slipped by.&lt;/p&gt;
&lt;p&gt;At the same time, the editors were instructed to try the code and check that it didn't contain any virus (sic). These poor souls had no programming experience and had to try all the code of this advanced-level book. I could see they were completely lost when they asked me why &lt;code&gt;random()&lt;/code&gt; didn't return the same number as in the book when they tried it. I had to fight and convince the publisher that this was nothing less than a pure waste of time for me and the editors to try out all the code this way. I ended up doing this step myself.&lt;/p&gt;
&lt;p&gt;I was lucky enough to be aided by a few trustworthy people during this process, because I probably wouldn't have managed to do it on my own.&lt;/p&gt;
&lt;p&gt;Later in the process, it was decided that all equations would be reformatted by the editors with an adequate equation tool rather than with images. I also had to track down these hundreds of instances. There were a few errors, but it wasn't as bad as I feared.&lt;/p&gt;
&lt;p&gt;Still, look at the life cycle of this little equation. As any self-respecting equation, it started its life as LaTeX code.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Original LaTeX equation" src="https://cyrille.rossant.net/images/eq1.png" /&gt;&lt;/p&gt;
&lt;p&gt;The conversion to Word resulted to a few minor mutilations.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Word equation" src="https://cyrille.rossant.net/images/eq2.png" /&gt;&lt;/p&gt;
&lt;p&gt;For an unkown reason, it suffered a lot during its conversion to PDF.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Conversion to PDF... waaat?!" src="https://cyrille.rossant.net/images/eq3.png" /&gt;&lt;/p&gt;
&lt;p&gt;Fortunately I spotted out the problem and had it corrected.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Final version" src="https://cyrille.rossant.net/images/eq4.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In the end, I managed to finish the editing phase in time, and the book was finally published late September. It was by far the hardest and most tedious experience I've ever done.&lt;/p&gt;
&lt;p&gt;The main conclusion of this is that I'm now convinced that Word is an abomination. I think it is one of the worse human creation after the atomic bomb. Everyone knows that writing in Word and sending over &lt;code&gt;chapter3.rev57.new.new-old.rev-final.doc&lt;/code&gt; files by e-mail is a nightmare, but no one &lt;em&gt;really&lt;/em&gt; knows until they have to do it for real with a 500-pages book full of code listings, images, mathematical equations, and URLs.&lt;/p&gt;
&lt;p&gt;Text files. Markdown. Distributed version control systems. Diff and merge. These are the right way to work collaboratively in the 21st century. Anyone thinking otherwise is stuck in the last millenium.&lt;/p&gt;
&lt;p&gt;I won't start any new project if I'm forced to use Word, and you should do the same.&lt;/p&gt;
&lt;p&gt;Recently, I read &lt;a href="https://medium.com/@chacon/living-the-future-of-technical-writing-2f368bd0a272"&gt;this&lt;/a&gt;. I also stumbled over &lt;a href="https://atlas.oreilly.com/"&gt;this&lt;/a&gt; and &lt;a href="https://www.gitbook.com/"&gt;this&lt;/a&gt;. Integrating the IPython notebook in these toolchains should be doable. I can't imagine working with anything else from now on.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>Big Data visualization with WebGL, part 1: Overview</title><link href="https://cyrille.rossant.net/big-data-visualization-webgl-part1/" rel="alternate"></link><published>2014-10-15T00:00:00+02:00</published><updated>2014-10-15T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2014-10-15:/big-data-visualization-webgl-part1/</id><summary type="html">&lt;p&gt;In this post series, I'll talk about the big data visualization platform I'm currently developing with WebGL. I'll give in this first post the main motivations for this project. The next posts will contain the technical details.&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Part 1: Overview&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cyrille.rossant.net/big-data-visualization-webgl-part2/"&gt;Part 2: Vispy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;This project brings together several modern …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post series, I'll talk about the big data visualization platform I'm currently developing with WebGL. I'll give in this first post the main motivations for this project. The next posts will contain the technical details.&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Part 1: Overview&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cyrille.rossant.net/big-data-visualization-webgl-part2/"&gt;Part 2: Vispy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;This project brings together several modern trends in data science and computing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Big Data&lt;/li&gt;
&lt;li&gt;Cloud computing&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;The IPython/Jupyter notebook&lt;/li&gt;
&lt;li&gt;The modern Web platform&lt;/li&gt;
&lt;li&gt;Mobile devices&lt;/li&gt;
&lt;li&gt;Graphics Processing Units&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Big Data&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Big Data&lt;/strong&gt;, like every buzzword, is often misused. It will die eventually. Yet, it is not completely meaningless. We are really drowning in the volume of data. In the &lt;a href="http://www.ucl.ac.uk/cortexlab"&gt;experimental neuroscience lab&lt;/a&gt; I'm working in, we're constantly buying new multi-terabytes hard drives and NAS boxes. We're always running out of disk space. Yet, this is only for &lt;em&gt;storage&lt;/em&gt;. Processing, analyzing, and visualizing these terabytes of data is harder and harder. Our algorithms, software, and hardware are not scaling as fast as our acquisition systems.&lt;/p&gt;
&lt;p&gt;This is not going to stop, on the contrary; it's going to get worse with international research projects such as the &lt;a href="https://www.humanbrainproject.eu/"&gt;Human Brain Project&lt;/a&gt; or the &lt;a href="http://www.whitehouse.gov/share/brain-initiative"&gt;BRAIN Initiative&lt;/a&gt;. Although raising huge technical challenges, this deluge of data is nevertheless expected to lead to important &lt;a href="http://www.moore.org/programs/science/data-driven-discovery"&gt;data-driven discoveries&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is not only true in experimental neuroscience, but also in virtually any academic and industrial discipline.&lt;/p&gt;
&lt;h3&gt;Cloud computing&lt;/h3&gt;
&lt;p&gt;In more and more disciplines, datasets are becoming too big for our computers. Cloud computing architectures let networks of computers process huge datasets in parallel. These platforms have been used by large Internet companies for many years. Academia is now trying to embrace this trend.&lt;/p&gt;
&lt;p&gt;Another thing to consider is &lt;strong&gt;big data inertia&lt;/strong&gt;. A huge, multi-terabytes dataset is going to be stored in a computer, a network drive, or in the cloud. You're not going to move it around in order to analyze and visualize it. Data transfers at this scale come at a huge cost, so you'll have to &lt;strong&gt;bring your code to the data rather than the other way around&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In terms of visualization, this implies that scalable solutions have to be distributed. Enabling &lt;strong&gt;remote data access&lt;/strong&gt; for analysis and visualization is now a requirement.&lt;/p&gt;
&lt;h3&gt;Python&lt;/h3&gt;
&lt;p&gt;Python is one of the leading &lt;strong&gt;open platforms for data analysis and visualization&lt;/strong&gt;. More and more scientists are using it. Yet, it lags behind other solutions when it comes to &lt;em&gt;big data&lt;/em&gt; analysis and visualization. Another drawback of Python is the difficulty of installing a working scientific Python distribution on a computer (although &lt;a href="http://conda.pydata.org/"&gt;conda&lt;/a&gt; is not far from solving this problem altogether).&lt;/p&gt;
&lt;p&gt;Because of this, &lt;em&gt;sharing&lt;/em&gt; and &lt;em&gt;diffusing&lt;/em&gt; data analysis reports in Python containing interactive visualizations is far from being straightforward, particularly when large datasets are involved. Innovative solutions are required in this area.&lt;/p&gt;
&lt;h3&gt;The IPython notebook&lt;/h3&gt;
&lt;p&gt;One of the most popular features of the scientific Python platform is the &lt;a href="http://ipython.org/notebook.html"&gt;IPython notebook&lt;/a&gt; (now also called &lt;a href="https://speakerdeck.com/fperez/project-jupyter"&gt;Jupyter&lt;/a&gt; notebook). This tool lets scientists write code, text, and create figures in a single document, all within their Web browser. This document can be tracked by a version control system, shared, and converted to HTML, PDF, and other formats.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://colaboratory.jupyter.org"&gt;Collaborative work on notebooks is becoming possible&lt;/a&gt;. Notebooks now support non-Python languages (R, Julia, Haskell, and many others). Finally, interactive graphical applications can be built in the notebook thanks to IPython widgets.&lt;/p&gt;
&lt;h3&gt;The modern Web platform&lt;/h3&gt;
&lt;p&gt;Whereas Python is one of the leading data analysis platforms, &lt;strong&gt;JavaScript is simply one of the most popular programming languages in the world&lt;/strong&gt;. I'm not sure how we got here, because JavaScript is not really known to be the most elegant language ever. However, the JavaScript community and ecosystem are huge nowadays. Also, the Web industry leaders have spent a considerable effort on building blazingly fast JavaScript interpreters for their browsers. JavaScript is probably here to stay, and we'll have to live with it.&lt;/p&gt;
&lt;p&gt;More optimistically, HTML5, CSS3, JavaScript, and the various WebSomething (WebGL, WebAudio, WebSocket, and so on) technologies offer an open, standardized, cross-platform, and highly capable platform for application development. For example, &lt;a href="http://www.chromeexperiments.com/webgl/"&gt;WebGL&lt;/a&gt; offers a standard API to display hardware-accelerated 2D and 3D graphics in real-time in the browser. Quite a few video games are written in WebGL now.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;With Web applications, deployment is basically trivial&lt;/strong&gt; (from a user perspective, at least). Open an URL with your browser and you instantaneously get your application running (possibly in the cloud). No installation, no plugin. That's probably one of the main reasons why this platform is so popular today.&lt;/p&gt;
&lt;h3&gt;Mobile devices&lt;/h3&gt;
&lt;p&gt;People spend more and more time on their mobile devices, and less and less time on their personal computers. That's not true everywhere, and many professionals still need a desktop computer. But I think this trend is not going to stop. Many scientists would love to access their data and analyses remotely through their mobile devices. Multi-touch interfaces on mobile devices would also make scientists more productive when they're visualizing and analyzing data.&lt;/p&gt;
&lt;h3&gt;Graphics Processing Units&lt;/h3&gt;
&lt;p&gt;The video game industry has been fostered the computational power of graphics processing units (GPUs) in the last two decades. Today, the GPU is often the most powerful processing unit in a computer. GPUs are now everywhere: desktop computers, laptops, tablets, smartphones, and even watches! We wouldn't have fast and fluid graphical interfaces without GPUs.&lt;/p&gt;
&lt;p&gt;GPUs are now routinely used in scientific disciplines for general-purpose computing applications. Some kinds of numerical problems can be solved highly efficiently on GPUs thanks to their massively parallel architecture. But GPUs were primarily designed for real-time rendering and 3D video games. We can also very well use them for big data visualization. I've been working on &lt;a href="http://journal.frontiersin.org/Journal/10.3389/fninf.2013.00036/full"&gt;this idea&lt;/a&gt; for two years, and this is the core idea of the project I'll be talking about here.&lt;/p&gt;
&lt;h2&gt;Bringing these technologies together&lt;/h2&gt;
&lt;p&gt;What would be an ideal, modern workflow for big data analysis and visualization? Here's my take:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Perform an experiment&lt;/strong&gt;. Acquire a huge dataset, store it in a remote server or in the cloud.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Start your analysis&lt;/strong&gt; by opening your Web browser and going to a secure URL.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Write code&lt;/strong&gt; in a notebook interface to access and visualize your data. You can launch analyses in parallel, and get status reports asynchronously.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use a GUI&lt;/strong&gt;. There are specific situations where text-based interfaces are not enough, and you really need a user-friendly graphical interface for data processing. For example, you may need to run a semi-automatic analysis involving human supervision. This interface may involve complex interactive visualizations.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Collaborate&lt;/strong&gt;. You're in the middle of an analysis session, and you want to share your findings &lt;em&gt;in real-time&lt;/em&gt; with a colleague in another city or country. You just give her the URL, and she immediately gets access to your notebook.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Save your work&lt;/strong&gt; using a distributed version control such as Git.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Access your work remotely&lt;/strong&gt;. On your way back home, you can still access your notebook and your data from your smartphone.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Share your findings&lt;/strong&gt; with colleagues or in a blog post. You can convert your notebook to an interactive self-contained HTML document containing your data, analyses, code, results, and interactive figures.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Publish&lt;/strong&gt; a paper by converting your notebook to a publication-ready paper (we're not there yet!).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Most of what is described here is &lt;strong&gt;already possible today using the IPython notebook&lt;/strong&gt;. The architecture enabling interactive widgets was implemented in IPython 2.0. Collaborative work and multi-language support should be brought by IPython 3.0. Interactive visualization tools in JavaScript exist; &lt;a href="http://d3js.org"&gt;d3.js&lt;/a&gt; is the most popular one, and it can be effectively integrated in the notebook (although this requires quite some work at the moment, unless you use &lt;a href="http://mpld3.github.io/"&gt;mpld3&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;What is currently missing is a &lt;strong&gt;fast and scalable big data visualization tool in the browser&lt;/strong&gt;. &lt;a href="http://vispy.org"&gt;Vispy&lt;/a&gt; is a hardware-accelerated big data visualization library in Python. I'm currently working on this library together with several other developers. Plotting interfaces are still being worked out at the moment, but data visualization widgets can already be written using lower-level interfaces. These visualizations are fast and scalable because the GPU is optimally leveraged thanks to &lt;strong&gt;OpenGL&lt;/strong&gt; (Open Graphics Library).&lt;/p&gt;
&lt;p&gt;The last missing feature is the ability to &lt;strong&gt;run a Vispy visualization in the IPython notebook and in the browser&lt;/strong&gt;. WebGL is an implementation of OpenGL in the Web browser. It is supported by all modern browsers on desktop computers and mobile devices. It is today the best technology at our disposal for distributed big data visualization.&lt;/p&gt;
&lt;p&gt;In the next posts, I'll describe how we're going to bring Vispy to the IPython notebook and the browser through WebGL. The main challenge will be to make Python and JavaScript communicate effectively, and to let users get the most of the architecture without asking them to write JavaScript code themselves.&lt;/p&gt;</content><category term="misc"></category><category term="dataviz"></category><category term="gpu"></category></entry><entry><title>IPython Cookbook released</title><link href="https://cyrille.rossant.net/ipython-cookbook-released/" rel="alternate"></link><published>2014-09-26T00:00:00+02:00</published><updated>2014-09-26T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2014-09-26:/ipython-cookbook-released/</id><summary type="html">&lt;p&gt;My new book, &lt;a href="https://ipython-books.github.io/cookbook/"&gt;IPython Interactive Computing and Visualization Cookbook&lt;/a&gt;, has just been released! A sequel to my previous &lt;a href="https://ipython-books.github.io/minibook/"&gt;beginner-level book on Python for data analysis&lt;/a&gt;, this new 500-page book is a &lt;strong&gt;complete advanced-level guide to Python for data science&lt;/strong&gt;. The 100+ recipes cover not only interactive and high-performance computing topics …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My new book, &lt;a href="https://ipython-books.github.io/cookbook/"&gt;IPython Interactive Computing and Visualization Cookbook&lt;/a&gt;, has just been released! A sequel to my previous &lt;a href="https://ipython-books.github.io/minibook/"&gt;beginner-level book on Python for data analysis&lt;/a&gt;, this new 500-page book is a &lt;strong&gt;complete advanced-level guide to Python for data science&lt;/strong&gt;. The 100+ recipes cover not only interactive and high-performance computing topics, but also data science methods in statistics, data mining, machine learning, signal processing, image processing, network analysis, and mathematical modeling.&lt;/p&gt;


&lt;p&gt;Here is a glimpse of the topics addressed in this book:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IPython notebook, &lt;strong&gt;interactive widgets&lt;/strong&gt; in IPython 2+&lt;/li&gt;
&lt;li&gt;Best practices in interactive computing: version control, workflows with IPython, testing, debugging, continuous integration...&lt;/li&gt;
&lt;li&gt;Data analysis with pandas, NumPy/SciPy, and matplotlib&lt;/li&gt;
&lt;li&gt;Advanced data visualization with &lt;strong&gt;seaborn, Bokeh, mpld3, d3.js, Vispy&lt;/strong&gt;...&lt;/li&gt;
&lt;li&gt;Code profiling and optimization&lt;/li&gt;
&lt;li&gt;High-performance computing with &lt;strong&gt;Numba, Cython, GPGPU with CUDA/OpenCL, MPI, HDF5, Julia&lt;/strong&gt;...&lt;/li&gt;
&lt;li&gt;Statistical data analysis with &lt;strong&gt;SciPy, PyMC, R&lt;/strong&gt;...&lt;/li&gt;
&lt;li&gt;Machine learning with &lt;strong&gt;scikit-learn&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Signal processing with SciPy, image processing with &lt;strong&gt;scikit-image&lt;/strong&gt; and OpenCV&lt;/li&gt;
&lt;li&gt;Analysis of graphs and social networks with &lt;strong&gt;NetworkX&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Geographic Information Systems in Python&lt;/li&gt;
&lt;li&gt;Mathematical modeling: dynamical systems, symbolic mathematics with &lt;strong&gt;SymPy&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of the code is freely available as IPython notebooks on the &lt;a href="https://github.com/ipython-books/cookbook-code"&gt;book's GitHub repository&lt;/a&gt;. This repository is also the place where you can signal errata or propose improvements to any part of the book.&lt;/p&gt;
&lt;p&gt;The book uses Python 3, although most of the code will work fine on Python 2.&lt;/p&gt;
&lt;p&gt;You'll find the book on &lt;a href="https://www.packtpub.com/big-data-and-business-intelligence/ipython-interactive-computing-and-visualization-cookbook"&gt;Packt's website&lt;/a&gt;, &lt;a href="http://www.amazon.com/IPython-Interactive-Computing-Visualization-Cookbook/dp/1783284811/ref=sr_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1410688253&amp;amp;sr=1-1"&gt;Amazon&lt;/a&gt;, and many other bookstores.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>New blog</title><link href="https://cyrille.rossant.net/new-blog/" rel="alternate"></link><published>2014-09-23T00:00:00+02:00</published><updated>2014-09-23T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2014-09-23:/new-blog/</id><summary type="html">&lt;p&gt;I finally took the time to update my Wordpress blog and make it static. Having a PHP-based website in 2014 felt archaic. The new site is generated with &lt;a href="http://blog.getpelican.com/"&gt;Pelican&lt;/a&gt;, a great Python-based static blog generator.&lt;/p&gt;


&lt;p&gt;Pelican doesn't get in my way, it's highly customizable, and it works with Markdown out …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I finally took the time to update my Wordpress blog and make it static. Having a PHP-based website in 2014 felt archaic. The new site is generated with &lt;a href="http://blog.getpelican.com/"&gt;Pelican&lt;/a&gt;, a great Python-based static blog generator.&lt;/p&gt;


&lt;p&gt;Pelican doesn't get in my way, it's highly customizable, and it works with Markdown out of the box. That being said, I have the feeling that ReST is slightly better supported. I had to tweak a python-markdown extension to enforce Python as the default code highlighting language.&lt;/p&gt;
&lt;p&gt;Previously, I had a home-made solution that was not very convenient. I would wrote a post in Markdown and convert it to HTML thanks to a custom Python script (calling pandoc under the hood). Then, I had to copy-paste the HTML code into Wordpress' admin interface. Wordpress was so slow, hard to configure and export, tricky to update, full of security holes. It seemed overkill for a basic personal website like this one.&lt;/p&gt;
&lt;p&gt;Now, I can write my blog posts in Markdown and generate the entire website with Pelican. Then I just have to push the generated HTML pages on GitHub.&lt;/p&gt;
&lt;p&gt;I found some plugins to add support for LaTeX equations (rendered with MathJax), code highlighting (with codehilite), and IPython notebooks.&lt;/p&gt;
&lt;p&gt;For the theme, I used a &lt;a href="https://github.com/PurePelicanTheme/pure-single"&gt;Pelican theme&lt;/a&gt; built on &lt;a href="http://purecss.io"&gt;Pure&lt;/a&gt;, a lightweight CSS responsive framework. It is less widespread than Bootstrap, but it feels less heavy and a bit simpler to use. It works great on mobile devices. I tweaked this theme by taking inspiration from a few blogs, included &lt;a href="http://www.loria.fr/~rougier/"&gt;Nicolas Rougier's&lt;/a&gt;. I particularly like the font, &lt;a href="https://www.google.com/fonts/specimen/Source+Sans+Pro"&gt;Source Sans Pro&lt;/a&gt;. The font for the code is &lt;a href="https://www.google.com/fonts/specimen/Ubuntu+Mono"&gt;Ubuntu Mono&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Finally, I used &lt;a href="https://www.disqus.com/"&gt;Disqus&lt;/a&gt; for the comments. I was able to transfer the previous Wordpress comments into Disqus easily.&lt;/p&gt;</content><category term="misc"></category></entry><entry><title>Why you should move to Python 3 – now</title><link href="https://cyrille.rossant.net/why-you-should-move-to-python-3-now/" rel="alternate"></link><published>2014-07-01T00:00:00+02:00</published><updated>2014-07-01T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2014-07-01:/why-you-should-move-to-python-3-now/</id><summary type="html">&lt;p&gt;I started to learn Python in 2008. The same year, Python 3 was released. Yet, almost six years later, I'm still using Python 2. Like the &lt;a href="http://ipython.org/usersurvey2013.html"&gt;vast majority of scientific Python programmers, apparently&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But now is the time for me to move to Python 3. You should too. Here's why …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I started to learn Python in 2008. The same year, Python 3 was released. Yet, almost six years later, I'm still using Python 2. Like the &lt;a href="http://ipython.org/usersurvey2013.html"&gt;vast majority of scientific Python programmers, apparently&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But now is the time for me to move to Python 3. You should too. Here's why.&lt;/p&gt;


&lt;h2&gt;Why would you want to move to Python 3?&lt;/h2&gt;
&lt;p&gt;Six years is a long time in computer science. Yet, the vast majority of scientific Python users are still on Python 2. That is despite the fact that the main scientific Python libraries are all compatible with Python 3 now (NumPy, SciPy, matplotlib, Pandas, IPython, SymPy, and many others). Others have already written about this issue (notably &lt;a href="http://jakevdp.github.io/blog/2013/01/03/will-scientists-ever-move-to-python-3/"&gt;Jake Vanderplas&lt;/a&gt;). My interpretation is that &lt;strong&gt;scientists think that the benefit-cost ratio for moving from Python 2 to Python 3 is too low&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Python 2 is working fine for them because &lt;strong&gt;their core expertise is in array programming with NumPy&lt;/strong&gt;. Array processing with NumPy hasn't changed at all between Python 2 or Python 3. By constrast, other Python developers (like in sysadmin or Web dev) use pure Python algorithms or string processing, and those things have been &lt;em&gt;vastly&lt;/em&gt; improved in Python 3.&lt;/p&gt;
&lt;p&gt;Most scientists think they have very little to gain by moving to Python 3, while it represents a significant investment (not only updating old code, but also reinstalling an entire Python distribution which has always been a pain).&lt;/p&gt;
&lt;p&gt;I was one of them.&lt;/p&gt;
&lt;p&gt;Until recently, when I bought the &lt;a href="http://shop.oreilly.com/product/0636920027072.do"&gt;Python Cookbook&lt;/a&gt;, Third Edition, by David Beazley and Brian K. Jones. This book is a must-read for anyone doing anything serious with Python. It contains lots of advanced recipes for &lt;em&gt;Python 3 only&lt;/em&gt;. In the Preface, the authors warn the reader:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;All of the recipes have been written and tested with Python 3.3 without regard to past Python versions or the "old way" of doing things. In fact, &lt;strong&gt;many of the recipes will only work with Python 3.3 and above&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ouch. The 260 recipes look pretty cool, but if you're in Python 2, you're out. While many might be irritated by this decision, I find it brilliant. This book is exactly the thing you need if you're waiting to be convinced to move to Python 3. (Maybe that's a lesson for the developers of the main scientific Python packages: provide Python 3-only features...)&lt;/p&gt;
&lt;p&gt;While going through the book, I discovered many elegant solutions to very common problems. I had no idea those solutions were possible, because I had no idea Python 3 had been so much improved.&lt;/p&gt;
&lt;p&gt;For sure, if you're only doing numerical computing, Python 2 may well be sufficient for you most of the time. But the one time you need to do advanced string processing, or you need to code some complex algorithm in pure Python, you will appreciate those fancy Python 3 features.&lt;/p&gt;
&lt;p&gt;I won't go into the details, but you can find several excellent references online about the things you miss by staying on Python 2, notably &lt;a href="http://asmeurer.github.io/python3-presentation/slides.html"&gt;this presentation by Aaron Meurer&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Updating courses and tutorials to Python 3&lt;/h2&gt;
&lt;p&gt;Now, I would argue that there are more important reasons to move to Python 3. It's a decision you should not only make for your individual interest, but also for the general interest. It is obvious that this split between Python 2 and Python 3 isn't good for the community. That's particularly bad for people &lt;em&gt;outside&lt;/em&gt; the community who are considering moving from MATLAB/Excel/whatever to Python. I don't think this split is making a first good impression.&lt;/p&gt;
&lt;p&gt;That's why I think it is important that more courses, tutorials and documentation use Python 3 now. While &lt;a href="https://ipython-books.github.io/minibook/"&gt;my first book&lt;/a&gt; uses Python 2, the second edition will use Python 3. Also, my &lt;a href="https://ipython-books.github.io/cookbook/"&gt;new book&lt;/a&gt; uses Python 3. That being said, the code will &lt;em&gt;just work&lt;/em&gt; with Python 2; nothing has fundamentally changed when it comes to array processing and scientific computing.&lt;/p&gt;
&lt;p&gt;If you've created any sort of tutorial or documentation in Python 2, please consider updating it. My bet is that you'll just have to change a few &lt;code&gt;print X&lt;/code&gt; to &lt;code&gt;print(X)&lt;/code&gt; here and there, and a couple of &lt;code&gt;map(...)&lt;/code&gt; to &lt;code&gt;list(map(...))&lt;/code&gt;. Much of the work can be done automatically. Once again, I won't go into the details, and you'll find &lt;a href="https://github.com/ipython-books/cookbook-code/blob/master/references/chapter02_best_practices.md#python-2python-3"&gt;many references here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A last note about installation: yes, installing a Python distribution with all its packages has always been a nightmare. Fortunately, most of these problems are being solved by Anaconda/conda/miniconda/binstar. &lt;a href="http://continuum.io/blog/anaconda-2-released"&gt;These tools now support Python 3 natively&lt;/a&gt;, so moving to a Python 3 distribution is becoming straightforward in many situations.&lt;/p&gt;
&lt;h2&gt;Why moving to Python 3 might not be easy for you&lt;/h2&gt;
&lt;p&gt;Okay, so, that was for the optimistic part. Python 3 is great, stable, most scientific Python libraries work just as before, and your core expertise relying on NumPy/SciPy doesn't have to change at all.&lt;/p&gt;
&lt;p&gt;But things aren't always that easy. There are some cases where moving to Python 3 is not possible, or where it isn't only your decision.&lt;/p&gt;
&lt;h3&gt;You're using package X and it's stuck to Python 2&lt;/h3&gt;
&lt;p&gt;So you're using NumPy and SciPy and many other great packages that work just fine with Python 3. And there's this package X, for Python 2 only, that you absolutely need. It answers a specific need of yours, and there's no other package in the entire world that solves it as well.&lt;/p&gt;
&lt;p&gt;What can you do?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Begging the authors to move to Python 3 (kidnapping and torture forbidden).&lt;/li&gt;
&lt;li&gt;Doing it yourself. After all, it's open source!&lt;/li&gt;
&lt;li&gt;Writing your own package.&lt;/li&gt;
&lt;li&gt;Finding an alternative package (compatible with Python 3, of course) and making it better (it's open source).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If none of these solutions is possible, you're kind of stuck.&lt;/p&gt;
&lt;p&gt;Maybe we should maintain a sort of &lt;a href="https://python3wos.appspot.com/"&gt;Python 3 "Wall of Shame"&lt;/a&gt; for scientific Python libraries. A few examples would include &lt;code&gt;line_profiler&lt;/code&gt; (but there's an ongoing &lt;a href="https://bitbucket.org/robertkern/line_profiler/pull-request/2/python-25-33-compatibility-using-a-single/"&gt;pull request&lt;/a&gt;) or &lt;a href="https://github.com/enthought/mayavi/issues/84"&gt;Mayavi/VTK&lt;/a&gt; (hopefully &lt;a href="http://vispy.org"&gt;Vispy&lt;/a&gt; will provide the foundations for an alternative solution in the near future).&lt;/p&gt;
&lt;h3&gt;You have to use legacy code in Python 2&lt;/h3&gt;
&lt;p&gt;This time, you're the one to blame. :) You have some old code you wrote a while ago, and it doesn't work on Python 3. Or maybe you use someone else's code. Take an afternoon and try to update the code.&lt;/p&gt;
&lt;p&gt;Chances are that it's not going to be as bad as it sounds. And you have tools to automate much of the work.&lt;/p&gt;
&lt;p&gt;But in some situations (with &lt;a href="http://python3porting.com/cextensions.html"&gt;C extension modules&lt;/a&gt; for instance), the cost may just be too high.&lt;/p&gt;
&lt;h3&gt;You have to use old systems that don't support Python 3 well&lt;/h3&gt;
&lt;p&gt;You don't always have the luxury to choose the machines and operating systems you work on. I know many people who are imposed old systems that don't support Python 3 well. There's nothing much you can do, unfortunately. Except one thing: learn how to write Python 2 code that's going to work just fine with Python 3 (&lt;code&gt;print(X)&lt;/code&gt; instead of &lt;code&gt;print X&lt;/code&gt; and so on). You'll find many references online.&lt;/p&gt;
&lt;h3&gt;Many of your end-users are stuck with Python 2&lt;/h3&gt;
&lt;p&gt;You're writing software that's going to be installed on many machines you don't control. You know that many of your users are not on Python 3 (yet). The best thing you can do is probably to write your software for both Python 2 and Python 3. There are techniques and tools that make that possible. Importantly, follow strong software engineering practices: version control, unit testing, code coverage, continuous integration. These practices increase your confidence that your code is working fine on Python 2 and Python 3 at all times.&lt;/p&gt;
&lt;p&gt;If you follow these rules, maybe &lt;em&gt;you&lt;/em&gt; can move to Python 3 while you're developing your software.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;If you're a scientist using Python 2, please at least think about moving to Python 3. Check &lt;a href="https://github.com/ipython-books/cookbook-code/blob/master/references/chapter02_best_practices.md#python-2python-3"&gt;these references&lt;/a&gt;, &lt;a href="http://shop.oreilly.com/product/0636920027072.do"&gt;have a look at this book&lt;/a&gt;, &lt;a href="http://continuum.io/blog/anaconda-2-released"&gt;install Anaconda 2&lt;/a&gt; and give Python 3 a try.&lt;/p&gt;
&lt;p&gt;If you're teaching, maintaining tutorials, courses or books about Python, please consider updating your materials to Python 3.&lt;/p&gt;
&lt;p&gt;It would be a bit sad that, in 2014, new Python users invest time on Python 2 only.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>Open Data Hackathon: road accidents</title><link href="https://cyrille.rossant.net/opendata-interior-hackathon/" rel="alternate"></link><published>2014-06-26T00:00:00+02:00</published><updated>2014-06-26T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2014-06-26:/opendata-interior-hackathon/</id><summary type="html">&lt;p&gt;I've participated at an &lt;a href="http://fr.okfn.org/2014/05/29/premier-hackaton-sur-les-donnees-du-ministere-de-linterieur/"&gt;Open Data hackathon&lt;/a&gt; organized by the French Minister of the Interior and several open data institutions. Together with Rue89 journalists and an OCTO Web developer, we created in two days an &lt;a href="http://rue89.nouvelobs.com/2014/06/25/carte-presque-tous-les-accidents-route-2012-253113"&gt;interactive map of all 62,000 road accidents in France in 2012&lt;/a&gt;. We used a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've participated at an &lt;a href="http://fr.okfn.org/2014/05/29/premier-hackaton-sur-les-donnees-du-ministere-de-linterieur/"&gt;Open Data hackathon&lt;/a&gt; organized by the French Minister of the Interior and several open data institutions. Together with Rue89 journalists and an OCTO Web developer, we created in two days an &lt;a href="http://rue89.nouvelobs.com/2014/06/25/carte-presque-tous-les-accidents-route-2012-253113"&gt;interactive map of all 62,000 road accidents in France in 2012&lt;/a&gt;. We used a &lt;a href="https://www.data.gouv.fr/fr/datasets/base-de-donnees-accidents-corporels-de-la-circulation/"&gt;very rich dataset&lt;/a&gt; released by the Minister of the Interior and Etalab.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Road accidents" src="/images/accidents.jpg" /&gt;&lt;/p&gt;


&lt;p&gt;Every road accident is timestamped and geolocated. The geolocation of many accidents was wrong in the original file, so we requested the help of a couple of developers highly experienced with geolocation. They were able to considerably improve the quality of the location of many accidents thanks to &lt;a href="http://openstreetmap.fr/tags/bano"&gt;OpenStreetMap's BANO database&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are many details per accident: gender and age of every person involved, severity of the wounds, seat belt worn or not, type and age of the vehicles, collision point on the vehicles, type of the road at the location of impact, climatic conditions, and many other details. In fact, the details are so precise that it may be possible to identify severe accidents by cross-checking with the local press.&lt;/p&gt;
&lt;p&gt;On our interactive map, one can click on each accident and get all the details available. One can also filter according to different criteria.&lt;/p&gt;
&lt;p&gt;For the preparation of the data file, I used the IPython notebook, NumPy, and pandas. The original dataset consisted of four CSV files that had to be linked together using unique identifiers (like SQL tables). It is almost trivial to do that with pandas (&lt;code&gt;join&lt;/code&gt;, &lt;code&gt;merge&lt;/code&gt;, &lt;code&gt;concatenate&lt;/code&gt;, etc.).&lt;/p&gt;
&lt;p&gt;The main challenge was to mine the raw data and generate the user-friendly textual information that would appear on the map, regarding the climatic conditions, the type of the vehicles, and the details about the users. I was amazed about how easy it was to do that with pandas. I didn't have to use any &lt;code&gt;for&lt;/code&gt; loop. Despite the dataset containing tens of thousands of data points, the data manipulations were very fast.&lt;/p&gt;
&lt;p&gt;I may share later the notebooks that allowed me to do these data manipulations.&lt;/p&gt;
&lt;p&gt;For the interactive map, we used Google Fusion Tables and Google Maps, because they were very easy to set up. I'd be interested in knowing open source alternatives that are almost as easy to use.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category><category term="opendata"></category></entry><entry><title>Scientific Python in the Browser: it's coming!</title><link href="https://cyrille.rossant.net/scientific-python-in-the-browser-its-coming/" rel="alternate"></link><published>2014-03-31T00:00:00+02:00</published><updated>2014-03-31T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2014-03-31:/scientific-python-in-the-browser-its-coming/</id><summary type="html">&lt;p&gt;There is currently a manifest trend in the scientific Python ecosystem: Python is slowly but surely coming to the browser. It's a real challenge, but we're getting there. In this post, I want to give an overview of where we are, and where we're headed.&lt;/p&gt;


&lt;h2&gt;Why it's a good thing …&lt;/h2&gt;</summary><content type="html">&lt;p&gt;There is currently a manifest trend in the scientific Python ecosystem: Python is slowly but surely coming to the browser. It's a real challenge, but we're getting there. In this post, I want to give an overview of where we are, and where we're headed.&lt;/p&gt;


&lt;h2&gt;Why it's a good thing&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Python is becoming &lt;a href="https://cyrille.rossant.net/why-using-python-for-scientific-computing/"&gt;one of the most popular open source platforms for scientific computing and data analysis&lt;/a&gt;&lt;/strong&gt;. The language is easy-to-use, expressive, open to the rest of the universe, and the scientific ecosystem is quite solid.&lt;/p&gt;
&lt;p&gt;On the other hand, the Web is today the &lt;a href="https://blog.mozilla.org/blog/2012/02/27/mozilla-in-mobile-the-web-is-the-platform/"&gt;platform of choice&lt;/a&gt; for client-side applications. What we called &lt;em&gt;Web 2.0&lt;/em&gt; some time ago is now just the &lt;em&gt;Web&lt;/em&gt;. Social networks have pervaded our lives and sharing things on the Web with our acquaintances is now entirely natural. The Web is also becoming a solid mobile platform, maybe not quite as powerful as native platforms yet, but it should eventually get there (at least that's my hope).&lt;/p&gt;
&lt;p&gt;Marrying Python and the Web seems natural. &lt;strong&gt;The power and expressivity of Python for numerical computing, and the popularity of the Web for diffusion and dissemination, interactive data visualization, rich client applications...&lt;/strong&gt; Why hasn't it happened yet? The main reason is technical. Python is Python, Javascript is Javascript. Those two just don't get along.&lt;/p&gt;
&lt;p&gt;It doesn't have to be that way. Technical difficulties can be overcome. We're not there yet, but we're getting there. Here's why.&lt;/p&gt;
&lt;h2&gt;The signs it's coming&lt;/h2&gt;
&lt;p&gt;It's like different pieces of a puzzle popping here and there, suggesting a barely perceptible convergence. From time to time, Python timidly tempts to approach the Web platform.&lt;/p&gt;
&lt;h3&gt;The IPython notebook&lt;/h3&gt;
&lt;p&gt;The most dazzling attempt so far has decidedly been the &lt;a href="http://ipython.org/notebook.html"&gt;&lt;strong&gt;IPython notebook&lt;/strong&gt;&lt;/a&gt;. This impressively architectured piece of software has been particularly well received by the community. The reason is that it was just the exactly right answer to a desperate need. The fact that it's a browser-based technology is almost a detail, and yet that is precisely my point. Many people now &lt;em&gt;live&lt;/em&gt; in the browser, so bringing Python there just seems absolutely right.&lt;/p&gt;
&lt;p&gt;To me, &lt;strong&gt;the IPython notebook is the first revolution in the convergence between Python and the Web platform&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The second revolution is &lt;a href="http://ipython.org/ipython-doc/dev/whatsnew/development.html#notebook-widgets"&gt;&lt;strong&gt;IPython 2.0 and its interactive widgets&lt;/strong&gt;&lt;/a&gt;. Those may sound like a gadget, but they &lt;em&gt;really&lt;/em&gt; are not. They represent a fundamental change of paradigm that brings Python and the browser yet closer. We now have the right architecture to make Python and Javascript communicate in real time. We now have extendable graphical widgets that interact dynamically with Python. We now have the technology to create small Web-based client-side applications that are backed by Python. All that in the notebook.&lt;/p&gt;
&lt;p&gt;The third revolution has yet to come. It will complete the union between Python and Javascript by bringing an important part of scientific Python &lt;em&gt;within&lt;/em&gt; the browser. That's probably a controversial idea, but I think it's both desirable and achievable within the next few years.&lt;/p&gt;
&lt;h3&gt;Web-based visualization libraries in Python&lt;/h3&gt;
&lt;p&gt;Another trend concerns interactive data visualization technologies that come to the browser.&lt;/p&gt;
&lt;p&gt;Libraries like &lt;a href="http://bokeh.pydata.org"&gt;Bokeh&lt;/a&gt;, or online services like &lt;a href="https://plot.ly"&gt;plot.ly&lt;/a&gt;, allow people to design figures in Python in order to obtain Web-based visualizations. The rationale behind these ideas is that scientists are no longer satisfied with static publication-ready plots: they want &lt;em&gt;interactive&lt;/em&gt; plots. There really can be scientific information in interactivity (think about linked brushing for instance).&lt;/p&gt;
&lt;p&gt;A widely popular interactive visualization library in the Web community is &lt;a href="http://d3js.org/"&gt;d3.js&lt;/a&gt;. It's no surprise that several Python libraries try to target it as a backend. There's &lt;a href="http://vincent.readthedocs.org/en/latest/"&gt;Vincent&lt;/a&gt; that lets you design a visualization in Python, export it to &lt;a href="http://trifacta.github.io/vega/"&gt;Vega&lt;/a&gt; (a visualization grammar), and finally generate a d3.js visualization from there.&lt;/p&gt;
&lt;p&gt;And there's &lt;a href="http://mpld3.github.io/"&gt;mpld3&lt;/a&gt;, a wonderful attempt to bring matplotlib and d3.js together. &lt;a href="https://github.com/jakevdp/mpld3/issues/69"&gt;The idea is conceptually very simple&lt;/a&gt;: &lt;a href="https://github.com/mpld3/mplexporter"&gt;export a matplotlib figure to JSON&lt;/a&gt;, and generate a d3.js visualization from there. &lt;a href="http://mpld3.github.io/examples/custom_plugin.html"&gt;The end-result is stunning&lt;/a&gt;: your matplotlib figures become &lt;em&gt;intrinsically&lt;/em&gt; interactive. You no longer need a live Python server to pan and zoom in your figure: it's just there, in your browser.&lt;/p&gt;
&lt;p&gt;Finally, I want to mention &lt;a href="http://vispy.org/"&gt;Vispy&lt;/a&gt;, a project I'm currently involved in. The idea is to leverage the power of the graphics card (through OpenGL) for fast high-performance interactive visualization of potentially huge datasets. Although it is a Python project, we think hard about ways to bring Vispy to the browser. The most promising (and challenging) approach is quite similar to mpld3: export a visualization in JSON, and render it in the browser with WebGL.&lt;/p&gt;
&lt;p&gt;In the end, it seems like data visualization is today a hot topic that concentrates a large part of the various efforts to bring scientific Python to the browser.&lt;/p&gt;
&lt;h3&gt;Mobile devices&lt;/h3&gt;
&lt;p&gt;I've given the arguments from the Python side. Here are those from the browser side.&lt;/p&gt;
&lt;p&gt;HTML5, Javascript and CSS3 now form a popular multi-device development technology for client-side applications. Frameworks and game engines are constantly being developped. The popularity of the platform comes from the simplicity of deployement and the fact that it's based on standard technologies of the Web. Mobile devices have now good support of those technologies. The &lt;em&gt;write once, run anywhere&lt;/em&gt; slogan is now (slowly) becoming true.&lt;/p&gt;
&lt;p&gt;There's no reason why scientific applications should not benefit from this platform. The eventuality of joining Python and the Web could enable the creation of rich scientific applications, with ergonomic and portable HTML-based user interfaces backed by the powerful scientific Python ecosystem. Those applications would run in the browser, so deployement would become trivial compared to installing a Python distribution. Besides, they could run directly on tablets and smartphones. I think there would be a huge demand for this.&lt;/p&gt;
&lt;h3&gt;Web technologies&lt;/h3&gt;
&lt;p&gt;Web technologies are being more and more mature and powerful. Even if the Javascript language is sometimes unappreciated, it is becoming quite efficient on latest browsers, notably thanks to dynamic compilation techniques (V8, SpiderMonkey, Chakra...).&lt;/p&gt;
&lt;p&gt;Native C code can now be ported to Javascript thanks to &lt;a href="http://emscripten.org/"&gt;emscripten&lt;/a&gt; and &lt;a href="http://asmjs.org/"&gt;asm.js&lt;/a&gt;. Emscripten, based on &lt;a href="http://llvm.org/"&gt;LLVM&lt;/a&gt;, can convert C code to a subset of Javascript: asm.js, which is a kind of intermediate-level "assembly language" in Javascript. One can now execute Javascript code with performance close to native code. High performance is really coming to the browser.&lt;/p&gt;
&lt;p&gt;Very recently, &lt;a href="https://01.org/blogs/tlcounts/2014/bringing-simd-javascript"&gt;Intel, Mozilla and Google announced that SIMD instructions where coming to Chrome and Firefox&lt;/a&gt;, and to emscripten as well.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.khronos.org/webcl/"&gt;WebCL&lt;/a&gt; is still a draft, but it should eventually bring OpenCL to the browser. General purpose massively parallel computing on multicore CPUs and GPUs in the (desktop or mobile) browser is becoming a reality.&lt;/p&gt;
&lt;p&gt;Finally, &lt;a href="http://www.khronos.org/webgl/"&gt;WebGL&lt;/a&gt; will interest big data visualization libraries: this technology gives direct access to OpenGL ES from the browser. WebGL support on mobile devices is still scarce, but it should hopefully improve in the future.&lt;/p&gt;
&lt;p&gt;As an aside, see this &lt;a href="http://superconductor.github.io/superconductor/"&gt;promising project&lt;/a&gt; in Javascript that combines WebGL and WebCL for big data visualization in the browser.&lt;/p&gt;
&lt;p&gt;So we see that the pieces of the puzzle are being put together to enable high-performance computing and visualization in the browser. We are close to get everything we need to bring scientific Python to the browser. The last challenge is the language barrier itself.&lt;/p&gt;
&lt;h2&gt;How it's coming&lt;/h2&gt;
&lt;p&gt;So, how could scientific Python come to the browser? Here are a few ideas. Some of them may not be reasonable. I have probably omitted interesting alternative ideas. And I've no idea about which approach could effectively succeed. I hope people more clever than me will eventually find out.&lt;/p&gt;
&lt;h3&gt;Python in the Cloud&lt;/h3&gt;
&lt;p&gt;The "easiest" solution is probably a &lt;em&gt;cloud&lt;/em&gt; approach. Run Python in the cloud, and make it accessible from browser-based applications. I think this is one of the most reasonable approaches in the short and medium term. Many services already offer this technology: &lt;a href="https://wakari.io/"&gt;Wakari&lt;/a&gt;, &lt;a href="http://www.picloud.com/"&gt;PiCloud&lt;/a&gt;, &lt;a href="https://www.pythonanywhere.com/"&gt;PythonAnywhere&lt;/a&gt;, &lt;a href="http://star.mit.edu/cluster/"&gt;StarCluster&lt;/a&gt;, and others. The main drawbacks are the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A live Internet connection is required.&lt;/li&gt;
&lt;li&gt;You might get high latency depending on your connection, which can be detrimental to real-time interactivity.&lt;/li&gt;
&lt;li&gt;Those services may sometimes be expensive (you need a cloud infrastructure!).&lt;/li&gt;
&lt;li&gt;You don't really "own" your code and your data.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The cloud approach is probably the best for heavy workflows, highly intensive computations, and huge amounts of data. For reasonably light computations, or small to medium amounts of data, purely offline self-contained solutions may be interesting alternatives.&lt;/p&gt;
&lt;h3&gt;A Python interpreter in the browser&lt;/h3&gt;
&lt;p&gt;An idea is to write a Python interpreter in Javascript. This can be done manually (&lt;a href="http://www.brython.info/"&gt;Brython&lt;/a&gt;, &lt;a href="http://www.skulpt.org/"&gt;skulpt&lt;/a&gt;) or automatically (&lt;a href="http://repl.it/languages"&gt;repl.it&lt;/a&gt;). Performance is generally not optimal, because you end up with Python code being interpreted by a Javascript library that is itself interpreted by the browser.&lt;/p&gt;
&lt;p&gt;There are also Javascript libraries that parse Python code and translate it to Javascript (&lt;a href="https://github.com/PythonJS/PythonJS"&gt;PythonJS&lt;/a&gt;, &lt;a href="http://pyjs.org/"&gt;pyjs&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Although impressive, these projects generally do not guarantee 100% of the language syntax nor 100% modules in the Python standard library. And they don't have support for scientific Python modules like NumPy, SciPy, etc. The main challenge with those libraries is that they include C and even FORTRAN code.&lt;/p&gt;
&lt;p&gt;Note that we could also consider translators from Python to languages like &lt;a href="http://coffeescript.org/"&gt;CoffeeScript&lt;/a&gt;, that transcompile in return to Javascript.&lt;/p&gt;
&lt;h3&gt;A Python JIT compiler in the browser&lt;/h3&gt;
&lt;p&gt;There's an ongoing project called &lt;a href="http://www.rfk.id.au/blog/entry/pypy-js-first-steps/"&gt;PyPy.js&lt;/a&gt; that aims at bringing PyPy's JIT Python compiler to Javascript with LLVM and emscripten. There's probably just &lt;a href="http://www.rfk.id.au/"&gt;&lt;em&gt;one&lt;/em&gt; guy&lt;/a&gt; on the entire Earth who has the required degree of programming wizardry to achieve this project. I hope he'll be successful eventually. The end-result would be impressive: write Python code, and JIT-compile it &lt;em&gt;in the browser&lt;/em&gt; to asm.js with PyPy and emscripten. &lt;a href="http://www.rfk.id.au/blog/entry/pypy-js-poc-jit/"&gt;Performance appears to be promising&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;NumPy in the browser&lt;/h3&gt;
&lt;p&gt;All the solutions mentionned above do not tackle a major challenge: how to bring NumPy and the rest of the scientific Python stack to the browser?&lt;/p&gt;
&lt;p&gt;A large part of those libraries is written in C or FORTRAN, and make API calls to CPython. Bringing these entire projects as they are now to the browser seems extremely hard to me. Emscripten and asm.js might help, but to what extent I'm not sure.&lt;/p&gt;
&lt;p&gt;An alternative would be to rewrite from scratch part of the core functionality of NumPy. The major missing piece is the multidimensional array data structure: the &lt;code&gt;ndarray&lt;/code&gt;, and vectorized computations. &lt;a href="https://github.com/mikolalysenko"&gt;Mikola Lysenko&lt;/a&gt; has a few projects in this spirit: &lt;a href="https://github.com/mikolalysenko/ndarray"&gt;&lt;code&gt;ndarray&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://github.com/mikolalysenko/cwise"&gt;&lt;code&gt;cwise&lt;/code&gt;&lt;/a&gt;, and others. This work may be a starting point for bringing core NumPy-like functionality to the browser.&lt;/p&gt;
&lt;p&gt;These projects could be combined with asm.js, SIMD.js or WebCL to achieve high performance.&lt;/p&gt;
&lt;p&gt;There's also a line of work related to JIT compilation of NumPy computations: &lt;a href="http://numba.pydata.org/"&gt;Numba&lt;/a&gt; and &lt;a href="http://blaze.pydata.org/"&gt;Blaze&lt;/a&gt;, conducted by &lt;a href="http://continuum.io/"&gt;Continuum Analytics&lt;/a&gt;. Those projects are based on LLVM: they can parse Python code and emit LLVM bytecode that can be compiled to assembly languages for nearly optimal performance. There might be some work to do there to compile Python code to optimized Javascript/asm.js.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I think there's a whole body of evidence showing that scientific Python will eventually come to the browser. How, I don't know, but I can definitely see several promising approaches.&lt;/p&gt;
&lt;p&gt;We'll probably make baby steps at first. For instance, executing simple NumPy-based pure functions from Python to Javascript.&lt;/p&gt;
&lt;p&gt;The IPython notebook will provide the perfect platform for these experiments. In particular, the interactive API in IPython 2.0+ could be extended to support Javascript callback functions instead of Python functions. Right now, the &lt;code&gt;@interact&lt;/code&gt; function decorator allows you to generate a set of widgets to control the input arguments of a function. This is a wonderful idea in my opinion, because it's fundamentally &lt;em&gt;functional&lt;/em&gt;. Converting such decorated Python function to Javascript would directly enable purely offline interactive widgets with the existing infrastructure.&lt;/p&gt;
&lt;p&gt;There's some really exciting and challenging work down the road, and I can't wait to see what the community will bring to life.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>Back from our first Vispy code camp at ESRF</title><link href="https://cyrille.rossant.net/back-from-our-first-vispy-code-camp-at-esrf/" rel="alternate"></link><published>2014-02-23T00:00:00+01:00</published><updated>2014-02-23T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2014-02-23:/back-from-our-first-vispy-code-camp-at-esrf/</id><summary type="html">&lt;p&gt;We had our first official &lt;a href="https://github.com/vispy/vispy/wiki/Vispy-code-camp-@ESRF"&gt;Vispy Code Camp&lt;/a&gt; this week. I and the other core developers of Vispy were kindly invited by the &lt;a href="http://www.esrf.eu"&gt;European Synchrotron Radiation Facility&lt;/a&gt;. We presented our young library to software engineers from the ESRF and other European synchrotron facilities. It was also the occasion for us …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We had our first official &lt;a href="https://github.com/vispy/vispy/wiki/Vispy-code-camp-@ESRF"&gt;Vispy Code Camp&lt;/a&gt; this week. I and the other core developers of Vispy were kindly invited by the &lt;a href="http://www.esrf.eu"&gt;European Synchrotron Radiation Facility&lt;/a&gt;. We presented our young library to software engineers from the ESRF and other European synchrotron facilities. It was also the occasion for us to make a gentle introduction to modern OpenGL, as many attendees didn't have experience in real-time GPU rendering. We discovered various scientific use cases in need of high-bandwidth, low-latency real-time visualization of big data.&lt;/p&gt;


&lt;p&gt;This was also the very first time we all gathered to work entirely on the project. We made productive use of our time together, discussing code architecture and design during most of the days and evenings. In particular, we had a close look to &lt;a href="http://luke.campagnola.me/"&gt;Luke Campagnola&lt;/a&gt;'s amazing work realized during the weeks before the meeting. Luke managed to digest all our prior discussions about the core layers of Vispy (visuals, transforms, scene graph, shader composition). He designed a very solid and promising system that does not sacrifice speed for flexibility. We also discussed many other aspects of the library and the project. Here is a summary.&lt;/p&gt;
&lt;h2&gt;Abstraction levels for interactive visualization&lt;/h2&gt;
&lt;p&gt;The core idea of Vispy is to offer different abstraction layers for high-performance interactive visualization. There is a huge gap between what a scientist wants to display (in terms of data and plots), and the OpenGL API. This is no different to the gap between a high-level language (such as Python or Haskell) and assembly code. Computer science is fundamentally based on this idea. In terms of high-performance interactive visualization, we think that the gap has yet to be filled.&lt;/p&gt;
&lt;p&gt;Interactive visualization deals with visualization on the one hand, and interactivity on the other hand. What are convenient abstraction levels for these two ideas? This is probably an open question in general. With Vispy, we'll be offering one among many possible solutions. Importantly, we will also design modular building blocks for epxerimenting different types of abstractions.&lt;/p&gt;
&lt;p&gt;As far as visualization is concerned, we plan to design:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;vispy.gloo&lt;/strong&gt;: an object-oriented interface to the core features of modern OpenGL&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vispy.visuals&lt;/strong&gt;: an object-oriented reactive interface for various 2D and 3D visuals&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vispy.shaders&lt;/strong&gt;: an architecture for modular GLSL shaders&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vispy.transform&lt;/strong&gt;: a flexible system for handling various linear and non-linear coordinate systems (Cartesian, polar, log, geographical map projections...), with support for GPU acceleration when needed&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vispy.scenegraph&lt;/strong&gt;: a flexible and efficient scene graph that is designed with big data in mind&lt;/li&gt;
&lt;li&gt;high-level plotting interfaces&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is obviously a tremendous amount of work down the line, but we start to have a good idea about how we'll organise these modules. Hopefully, we'll be able to reach a critical mass of code and contributors required for the realization of this project.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://iihm.imag.fr/blanch/"&gt;Renaud Blanch&lt;/a&gt; from UJF suggested that we start thinking about something similar for &lt;em&gt;interactivity&lt;/em&gt;. Typically, user interactivity is implemented at the lowest level possible: mouse movements, key strokes, etc. Higher-level abstraction systems may allow end-users to design interactive visualizations in a more intuitive way. There happens to be a whole range of research about this topic (human-machine interfaces).&lt;/p&gt;
&lt;h2&gt;Object-oriented OpenGL&lt;/h2&gt;
&lt;p&gt;Vispy.gloo is the main module implemented at this time. It is supporting our whole visualization stack. We discussed some relatively minor changes suggested by &lt;a href="http://www.loria.fr/~rougier/"&gt;Nicolas Rougier&lt;/a&gt; in order to make the interface even simpler and cleaner. This object-oriented interface is already extremely convenient for us and other OpenGL developers. In effect, it allows us to focus on the &lt;em&gt;what&lt;/em&gt; instead of the &lt;em&gt;how&lt;/em&gt;. We define vertex buffers, textures, variables, we write the shaders in GLSL, and we render the OpenGL programs. All that with a Pythonic interface.&lt;/p&gt;
&lt;h2&gt;Visuals&lt;/h2&gt;
&lt;p&gt;The visuals, transforms, modular shaders, and scene graph, are very much work in progress right now. We discussed these layers extensively during the code camp.&lt;/p&gt;
&lt;p&gt;The visuals layer is one abstraction level above &lt;em&gt;vispy.gloo&lt;/em&gt;. A &lt;strong&gt;visual&lt;/strong&gt; is an object appearing on the scene. At this level, we start to get closer to the user's mind. Vispy will eventually come with a library of common visuals: polylines, geometric 2D shapes, 3D meshes, Bézier curves, surfaces, etc. Those visuals will be extendable. Importantly, users will be able to write their own visuals for complex use cases. They will have to learn the basis of modern OpenGL, and notably GLSL. We plan to provide very solid documentation on this subject. That being said, the core ideas are relatively simple.&lt;/p&gt;
&lt;p&gt;Visuals will come with a reactive object-oriented interface: properties of a visual may be updated by changing instance attributes in Python. The according OpenGL commands would be automatically called under the hood.&lt;/p&gt;
&lt;p&gt;Using a small subset of the SVG specification for common shapes may also be an interesting idea.&lt;/p&gt;
&lt;h2&gt;Linear and non-linear transformations&lt;/h2&gt;
&lt;p&gt;With transformations, we allow visual objects to be organized in different coordinate systems. We tried to base this module on the mathematical notion of bijective function. After all, transformations are merely more than the mathematical composition of direct and inverse functions. Linear transformations can be expressed as matrix multiplications, but we don't enforce this in order to support non-linear transformations out of the box.&lt;/p&gt;
&lt;h2&gt;Modular shaders&lt;/h2&gt;
&lt;p&gt;Offering the possibility to write and organize modular shaders is one of the main challenges of the project. GLSL is a pretty low-level language, describing how &lt;em&gt;vertices&lt;/em&gt; and &lt;em&gt;fragments&lt;/em&gt; (i.e. pixels) are processed on the massively parallel GPU architecture. Shaders can become quite complex in real-world use cases. Yet, there are many recurring patterns in shaders. By allowing users to design shaders from compact building blocks, we drastically simplify the task of creating complex extendable visuals (DRY principle). We also need these features internally for the transforms.&lt;/p&gt;
&lt;p&gt;Luke came up with a pretty amazing modular system that seems to encompass all our use cases. The amount of programming wizardry involved is quite stunning. Nicolas pointed out that we were basically creating a new language on top of GLSL along with a dynamic compiler to GLSL. Although many details remain to be worked out, I think we have here a brilliant system that will prove vastly useful for the whole project.&lt;/p&gt;
&lt;h2&gt;Scene graph&lt;/h2&gt;
&lt;p&gt;With the visuals, the transforms, and the modular shader, we have everything we need to build a flexible and efficient GPU-aware scene graph. The idea of the scene graph is very classic: there is a hierarchy of visual objects that are linked by specific transforms. Imagine, for example, a scientific interactive figure with multiple subplots (grid layout). There are multiple coordinate systems involved. For maximum performance, transforms may happen on the CPU or the GPU depending on the use cases. For instance, &lt;em&gt;static&lt;/em&gt; transforms may be computed and cached once on the CPU, whereas it may be more efficient to perform &lt;em&gt;dynamic&lt;/em&gt; transforms on the GPU.&lt;/p&gt;
&lt;h2&gt;High-level interfaces&lt;/h2&gt;
&lt;p&gt;The layers described above constitute the internals of Vispy, and most users won't be aware of them. Eventually, we'll need to implement high-level interfaces for scientific plotting. Even if we could implement a brand new interface, it will be safer to implement existing high-level APIs.&lt;/p&gt;
&lt;p&gt;We talked a bit about the different possibilities, starting with the MATLAB/matplotlib.pyplot interface. Although this interface is admitedly clunky, many scientists are used to it. We could either reimplement the most important functions, or find a way to leverage the existing implementation in matplotlib. One interesting direction is &lt;a href="https://github.com/mpld3"&gt;Jake Vanderplas' current work&lt;/a&gt; on an exporter for matplotlib figures. The idea is to export a plot in a language-independent representation, so that it can be easily displayed with another backend (such as Vispy).&lt;/p&gt;
&lt;p&gt;Of course, there are alternative interfaces and plotting libraries that we could take inspiration from: seaborn, vincent/vega, bokeh, plot.ly, etc. Even if we start thinking about these issues now, we're currently focusing on the core layers, keeping in mind plotting use-cases.&lt;/p&gt;
&lt;h2&gt;Vispy in the browser&lt;/h2&gt;
&lt;p&gt;A longing feature is the ability to run Vispy in the browser. The main use case is the IPython notebook. I've thought a lot about the different ways to achieve this. We discussed many of these ways during the code camp, and I think we made some progress.&lt;/p&gt;
&lt;p&gt;First, it should be relatively easy to implement an online backend. A Python server would stream OpenGL commands straight to the browser through WebSockets. This would enable interactive visualizations embedded in live IPython notebooks.&lt;/p&gt;
&lt;p&gt;In parallel, an &lt;em&gt;offline backend&lt;/em&gt; would be even more interesting, but highly challenging. The idea is to compile a visualization written in Python to a standalone HTML/Javascript interactive document.&lt;/p&gt;
&lt;p&gt;After exploring multiple ideas, I'm now thinking that the cleanest way of bringing Vispy to the browser would be to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allow serialization of visuals, entities, transforms, scene graphs, interactivity.&lt;/li&gt;
&lt;li&gt;Implement an interpreter in Javascript for displaying serialized visualizations.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This represents a significant amount of work, notably the first part. But we can do it progressively. The interpreter would be much less complex than Vispy itself, mainly because Python would still be responsible for the most complex part, that is, initialization of the scene with user-provided code.&lt;/p&gt;
&lt;h2&gt;Desktop and ES OpenGL&lt;/h2&gt;
&lt;p&gt;An issue we discussed a lot relates to the different flavors of OpenGL. We currently limit the set of features to OpenGL ES 2.0. This light implementation of OpenGL works on desktop and mobile devices, as well as in the browser. Having a single implementation makes it easier to share code between different devices and platforms. However, OpenGL ES 2.0 lacks a few interesting features that &lt;em&gt;do&lt;/em&gt; exist on many desktop systems. We have yet to find a convenient system for enabling explicitly non-ES features.&lt;/p&gt;
&lt;h2&gt;OpenGL wrapper, ANGLE&lt;/h2&gt;
&lt;p&gt;Almar Klein has been busy in the train implementing his own OpenGL ES wrapper in Python with ctypes, thereby bypassing PyOpenGL. He also succeeded in using &lt;a href="http://code.google.com/p/angleproject/"&gt;ANGLE&lt;/a&gt; on Windows with this wrapper, bringing modern OpenGL to most Windows users. ANGLE automatically translates OpenGL API calls to DirectX. This is quite an useful feature for those Windows users who only have the default OpenGL 1.1 implementation in Windows. This will considerably simplify the distribution of OpenGL-based applications to Windows users.&lt;/p&gt;
&lt;h2&gt;Image registration for continuous integration&lt;/h2&gt;
&lt;p&gt;Eric Larson has set up a continuous integration system for Vispy with Travis CI. He also did some great work improving our testing suite. However, we have yet to check the bitmap output of rendering tests. A difficulty lies in the fact that different OpenGL implementations do not result in pixel-perfect results. We started some preliminary work to have a look at the discrepancies between images generated by various implementations.&lt;/p&gt;
&lt;h2&gt;Installation and library dependencies&lt;/h2&gt;
&lt;p&gt;Even if Vispy is still a pure Python library for now (yet depending on NumPy and PyOpenGL), this might change in the future. In specific instances, we may need to implement complex algorithms in C or Cython. This will complicate the installation, except if we find a way to achieve graceful degradation in the absence of a C compiler or external dependencies. In particular, it seems that SciPy is quite a heavy dependency, and we should avoid relying on it if possible.&lt;/p&gt;
&lt;h2&gt;OpenCL/OpenGL interoperability&lt;/h2&gt;
&lt;p&gt;Jérôme Kieffer and Armando Solé from ESRF were interested in combining OpenGL and OpenCL with Vispy. The idea is to allocate a single buffer on the GPU for both visualization and computing. For example, one can create an OpenGL texture, and perform general-purpose computations on this buffer from an OpenCL kernel. This is quite efficient since there is no copy whatsoever between the CPU and GPU.&lt;/p&gt;
&lt;p&gt;After fighting against driver and OS-specific bugs of various kinds with OpenCL, we finally managed to enable OpenGL-OpenCL interoperability with Vispy. We have yet to do detailed performance benchmarks with various backends and OpenGL wrappers. We're also working on encapsulating boilerplate code in a clean Pythonic API.&lt;/p&gt;
&lt;h2&gt;Out-of-memory visualization with HDF5&lt;/h2&gt;
&lt;p&gt;I presented a few demos implementing out-of-memory visualization of HDF5 files with Galry. We have yet to port those to Vispy, but there shouldn't be any particular difficulty in the process. Armando shared with us his long expertise in optimizing HDF5 data access. There happens to be many tricks and techniques to get the most performance out of HDF5 in Python.&lt;/p&gt;
&lt;h2&gt;A molecular viewer with true impostors&lt;/h2&gt;
&lt;p&gt;The code camp was also the occasion for some of the participants to implement demos in modern OpenGL, using our object-oriented interface vispy.gloo.&lt;/p&gt;
&lt;p&gt;Gaël Goret implemented an interactive 3D viewer of molecules with vispy.gloo. This viewer is extremely efficient: Nicolas suggested to use &lt;a href="http://http.developer.nvidia.com/GPUGems3/gpugems3_ch21.html"&gt;true impostors&lt;/a&gt;. This smart technique consists in using a tiny number of vertices (or even one) per molecule, instead of rendering spheres with complex meshes. Realistic 3D rendering is achieved with a ray-casting algorithm implemented in the fragment shader. Be sure to &lt;a href="https://github.com/vispy/codecamp-esrf-2014/tree/master/gg"&gt;check out the demo here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Wrap-up&lt;/h2&gt;
&lt;p&gt;This was a highly productive meeting, and we're all quite excited with what's coming. We're starting to overcome most conceptual challenges. Code is being written, discussed, tested. More and more people with various areas of expertise are willing to contribute.&lt;/p&gt;
&lt;p&gt;We're also producing more and more documentation materials (when will we see a Vispy book?). This is a fundamental aspect of the project. Indeed, our goal is not only to build a &lt;em&gt;library&lt;/em&gt;, but also a &lt;em&gt;knowledge base&lt;/em&gt;. Scientists are generally not exposed to &lt;em&gt;modern&lt;/em&gt; OpenGL, although this is a decade-old subject (generally the expertise domain of game developers). The high complexity of OpenGL is probably an important reason why OpenGL is still not widespread in scientific visualization. Vispy hides most of this complexity, offering simple and clean interfaces that specifically target scientific visualization. We really want to bring OpenGL to scientists.&lt;/p&gt;
&lt;p&gt;So, that's a wrap. We're deeply grateful to the ESRF staff for their support, and particularly Jérôme and Armando who decided to invite all of us. This was a fantastic opportunity for the project, and we hope we'll be able to organize more events like this in the future. In the meantime, the development continues!&lt;/p&gt;
&lt;p&gt;PS: the ESRF Data Analysis Unit is recruiting an OpenGL/OpenCL/Python expert for high-performance interactive visualization of big scientific data. &lt;a href="http://esrf.profilsearch.com/recrute/fo_annonce_voir.php?id=300"&gt;Be sure to check out the announcement&lt;/a&gt;, and pass the word around if you know potentially interested people!&lt;/p&gt;</content><category term="misc"></category><category term="python"></category><category term="dataviz"></category></entry><entry><title>What's wrong with scientific Python?</title><link href="https://cyrille.rossant.net/whats-wrong-with-scientific-python/" rel="alternate"></link><published>2014-01-15T00:00:00+01:00</published><updated>2014-01-15T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2014-01-15:/whats-wrong-with-scientific-python/</id><summary type="html">&lt;p&gt;tl;dr: Although not perfect, Python is today one of the best platforms for scientific computing. It's getting even better everyday thanks to the amazing work of a vibrant and growing community. &lt;a href="https://cyrille.rossant.net/why-using-python-for-scientific-computing/"&gt;I reviewed Python's strengths in a previous post&lt;/a&gt;. Here, I cover the more sensitive issue of its weaknesses …&lt;/p&gt;</summary><content type="html">&lt;p&gt;tl;dr: Although not perfect, Python is today one of the best platforms for scientific computing. It's getting even better everyday thanks to the amazing work of a vibrant and growing community. &lt;a href="https://cyrille.rossant.net/why-using-python-for-scientific-computing/"&gt;I reviewed Python's strengths in a previous post&lt;/a&gt;. Here, I cover the more sensitive issue of its weaknesses.&lt;/p&gt;


&lt;p&gt;Don't get me wrong. I love Python. I use it everyday. I think that, as of today, it is nothing less than one of the best platforms for high-performance scientific computing and data science. Not only among other competing open-source languages like R or Scilab; to me, it even outclasses commercial products like Matlab.&lt;/p&gt;
&lt;p&gt;That being said, nobody's perfect. While Python is mostly an excellent platform, it has some weaknesses. Sadly, those may prevent many people from jumping from Matlab &amp;amp; co to Python. I'd like to review them here. Note that these are my own opinions and many might disagree.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt; (24/01/2014): this updated version contains a few clarifications and additions compared to the original version from 15/01/2014. See also in the comments a &lt;a href="https://cyrille.rossant.net/whats-wrong-with-scientific-python/#comment-1603524572"&gt;very good summary and perspective by Konrad Hinsen&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;A good general-purpose language, but not that good for scientific computing&lt;/h2&gt;
&lt;p&gt;Python has been around for more than twenty years. It was originally, and has always been, a general-purpose language. It is actually one of its greatest strengths compared to domain-specific languages designed primarily for scientific computing. For example, Matlab is really good with matrices, but not with other data structures. Many statisticians like R's syntax, because it appears to do well what it is meant to do (statistics), but that's basically it.&lt;/p&gt;
&lt;p&gt;Today, if Python supports the data structures we often use in scientific computing, that's thanks to NumPy. Whereas operations like indexing and slicing are quite natural (they translate to standard Python syntax), basic matrix manipulations like concatenations or reshaping feel a bit clunky. I think that's more a limitation of the language than a limitation of NumPy. I imagine that many Matlab users trying to move to Python feel a bit disoriented because of this.&lt;/p&gt;
&lt;h2&gt;NumPy has a few weaknesses&lt;/h2&gt;
&lt;p&gt;A few things in NumPy are slightly odd and often confuse beginners. Off the top of my head:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;To concatenate arrays with, say, &lt;code&gt;hstack&lt;/code&gt;, you end up using double parentheses: &lt;code&gt;hstack((a, b))&lt;/code&gt;. How are you explaining this to beginners?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fancy indexing is slow: &lt;code&gt;x[indices]&lt;/code&gt;, where &lt;code&gt;indices&lt;/code&gt; is an arbitrary array of integers, can be up to &lt;em&gt;four times&lt;/em&gt; slower than Matlab. Now, if you use &lt;a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.take.html"&gt;&lt;code&gt;take()&lt;/code&gt;&lt;/a&gt;, you can achieve Matlab's speed. If you don't know &lt;a href="https://cyrille.rossant.net/numpy-performance-tricks/"&gt;this trick&lt;/a&gt; (and why would you, if you're a Matlab user considering switching to Python?), you might just think that Python is &lt;em&gt;four times&lt;/em&gt; slower than Matlab (this very situation actually happened to a colleague). Ouch...&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let's create a matrix full of zeros: &lt;code&gt;x = zeros((10, 10))&lt;/code&gt;. Now a random matrix: &lt;code&gt;x = rand(10, 10)&lt;/code&gt;. First case: you &lt;em&gt;need&lt;/em&gt; double parentheses or you get an error. Second case, you &lt;em&gt;need&lt;/em&gt; single parentheses or you get an error. &lt;em&gt;Why?!&lt;/em&gt; &lt;strong&gt;Update&lt;/strong&gt;: someone pointed out in the comments that there's a really good reason for that: the &lt;code&gt;rand(10, 10)&lt;/code&gt; function is a Matlab-friendly shortcut for &lt;code&gt;numpy.random.random_sample((10, 10))&lt;/code&gt;. This little-known function &lt;em&gt;is&lt;/em&gt; consistent with the rest of the NumPy API! This brings an additional point I'll tackle below (about Python trying to be Matlab).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'm sure we can find several other oddities. Now, I concede that these are all pretty minor things. NumPy remains an exceptionally useful library that has a huge importance in scientific computing.&lt;/p&gt;
&lt;p&gt;It should be noted that &lt;a href="http://continuum.io/"&gt;Continuum Analytics&lt;/a&gt; is already working on the next generation of NumPy: &lt;a href="http://blaze.pydata.org/"&gt;Blaze&lt;/a&gt;, that looks fantastic. This is a brand new library, not just a new version of NumPy. I don't think that the NumPy project itself is going to evolve a lot in the future, and I expect a lot more from Blaze.&lt;/p&gt;
&lt;h2&gt;Python is trying to be Matlab&lt;/h2&gt;
&lt;p&gt;(addition to the original version)&lt;/p&gt;
&lt;p&gt;More precisely, the Python scientific stack (notably NumPy, SciPy, matplotlib...) tries to mimic some of the functionality and API of Matlab. This is actually not a bad idea: regular Matlab users have a chance to move to Python more easily. However, mimicking part of Matlab also means mimicking part of its weaknesses, including unpleasant or inconsistent API. The example of the Matlab shortcut &lt;code&gt;rand(10, 10)&lt;/code&gt; being much more used than the original NumPy function &lt;code&gt;numpy.random.random_sample((10, 10))&lt;/code&gt; is interesting.&lt;/p&gt;
&lt;p&gt;Think also about the habit that many Python users (and potentially ex-Matlab users like me!) have taken, which consists in putting &lt;code&gt;from pylab import *&lt;/code&gt; at the top of a script, or running IPython in &lt;code&gt;%pylab&lt;/code&gt; mode. I've done that for years (not anymore). The IPython core developers are desperately trying to prevent people from doing that now. The core of Matlab has no notion of namespaces: all function names are defined in a global, huge namespace. This is obviously not how Python is working, so the &lt;code&gt;pylab&lt;/code&gt; mode imports everything in the interactive namespace. I understand that it makes life easier to people coming from Matlab, but that's really not a good habit to take.&lt;/p&gt;
&lt;p&gt;This is a double-edged sword: Python needs to depart from Matlab's weaknesses, but it should also attract Matlab users with a very similar API. I'm not really sure what the best answer to this is.&lt;/p&gt;
&lt;h2&gt;CPython is slow&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/CPython"&gt;CPython&lt;/a&gt; is the mainstream implementation of the Python language. Being written in C, it can easily talk to rock-solid libraries that have been developed over the course of decades. CPython itself is a solid piece of software.&lt;/p&gt;
&lt;p&gt;The problem is, it is not always very fast. Tight loops in particular tend to be slow. Even a &lt;a href="http://stackoverflow.com/a/8097669"&gt;trivial loop&lt;/a&gt; that does nothing wastes &lt;em&gt;many&lt;/em&gt; CPU cycles in dynamic type checking, function calls, etc. This is why NumPy exists: matrix computations can be vectorized in C to make much better use of CPU cycles.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://cython.org/"&gt;Cython&lt;/a&gt; is a popular solution, but I admit it sometimes feels a bit clunky. Mixing Python and C in some sort of bastard language seems more like a temporary hack to get things done than a long-term solution.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Just-in-time_compilation"&gt;Just-in-time (JIT) compilation&lt;/a&gt; is one possibility to overcome this issue. &lt;a href="http://pypy.org/"&gt;PyPy&lt;/a&gt; uses this technique for general Python code, achieving &lt;a href="http://speed.pypy.org/"&gt;impressive speed-ups&lt;/a&gt;. However, it seems like supporting NumPy and SciPy in PyPy is particularly difficult. There are &lt;a href="http://pypy.org/numpydonate.html"&gt;some work&lt;/a&gt; in this direction but I'm not sure they will succeed in the foreseeable future.&lt;/p&gt;
&lt;p&gt;A related project is &lt;a href="http://numba.pydata.org/"&gt;Numba&lt;/a&gt;, by Continuum Analytics. This project is closely tied to Blaze. Its goal is to implement a JIT compiler specifically adapted to the kind of vectorized computations we have in scientific computing. It is also NumPy-aware. Numba is a very promising project that may overcome the most severe limitations of CPython in the context of scientific computing.&lt;/p&gt;
&lt;h2&gt;CPython does not like parallel computing&lt;/h2&gt;
&lt;p&gt;Another big issue in Python is its weak support of multicore processors. Once again, this limitation comes from CPython. The &lt;a href="https://wiki.python.org/moin/GlobalInterpreterLock"&gt;Global Interpreter Lock (GIL)&lt;/a&gt; is a mechanism in CPython that simplifies drastically memory management. It works by preventing threads, in a multithreaded Python interpreter, to run simultaneously. In other words, with CPython, you are stuck with one core per Python process.&lt;/p&gt;
&lt;p&gt;There are some ways to run code in parallel with Python, but they are not particularly convenient. One can &lt;a href="http://docs.cython.org/src/userguide/external_C_code.html"&gt;bypass the GIL&lt;/a&gt; with Cython or with C code, for example. Alternatively, one can simply use multiple processes. But &lt;a href="http://docs.python.org/2/library/multiprocessing.html"&gt;multiprocessing&lt;/a&gt; is tedious and heavyweight in general, particularly on Python.&lt;/p&gt;
&lt;p&gt;NumPy can run some specific types of computations (like matrix products) on multiple cores, thanks to libraries like &lt;a href="http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms"&gt;BLAS&lt;/a&gt;. Blaze, the successor of NumPy, should support parallel computing (on CPU or GPU) out of the box.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;. Some people have rightly pointed out that many, many solutions exist to do high-quality and efficient parallel computing in Python (see also &lt;a href="http://aron.ahmadia.net/"&gt;Aron Ahmadia&lt;/a&gt;'s comment below). These solutions notably include: &lt;a href="http://mpi4py.scipy.org/"&gt;mpi4py&lt;/a&gt;, &lt;a href="https://code.google.com/p/petsc4py/"&gt;petsc4py&lt;/a&gt;, &lt;a href="http://ipython.org/ipython-doc/dev/parallel/"&gt;IPython.parallel&lt;/a&gt; (which contains truly awesome stuff), &lt;a href="http://pythonhosted.org/joblib/"&gt;joblib&lt;/a&gt;, among many others. Just look at &lt;a href="https://wiki.python.org/moin/ParallelProcessing"&gt;this list&lt;/a&gt;. Some of these solutions are extremely powerful but may not be so easy to use, others are much simpler and already quite useful for &lt;a href="http://en.wikipedia.org/wiki/Embarrassingly_parallel"&gt;embarrassingly parallel&lt;/a&gt; tasks (notably joblib).&lt;/p&gt;
&lt;p&gt;IPython's parallel computing features have a particularity here: not only are they deeply easy to used, they are &lt;em&gt;also&lt;/em&gt; extremely powerful, notably when used with MPI. The learning curve that some might encounter comes more from MPI than IPython, in my opinion.&lt;/p&gt;
&lt;p&gt;The very fact that so many people (&lt;a href="https://github.com/rossant/playdoh"&gt;including myself&lt;/a&gt;!) tried to improve the parallel computing capabilities of the Python platform &lt;em&gt;is precisely the point I wanted to make&lt;/em&gt;. At its core, (C)Python is not well adapted to parallel computing. If it were, we wouldn't see so many people attempting to fix it...&lt;/p&gt;
&lt;p&gt;More generally, this also shows that Python's native weaknesses &lt;em&gt;can&lt;/em&gt; be fixed. And they &lt;em&gt;are&lt;/em&gt;. They are even fixed so well that the very claim "Python does not like parallel computing" may hurt people's feelings (sorry). Some of the solutions mentioned above are so well-established that they actually seem to &lt;em&gt;belong&lt;/em&gt; to Python. But I think that's forgetting the native limitations CPython.&lt;/p&gt;
&lt;h2&gt;Lack of scalable visualization tools&lt;/h2&gt;
&lt;p&gt;Python currently lacks a good interactive visualization tool that scales to huge datasets (tens of millions of points). Admitedly, there aren't that many libraries in other languages either. But &lt;a href="http://vispy.org/"&gt;we're working on it&lt;/a&gt; (shameless self-promotion).&lt;/p&gt;
&lt;h2&gt;Python 2 versus Python 3&lt;/h2&gt;
&lt;p&gt;This is a tough one. The vast majority of Pythonista scientists use an &lt;em&gt;obsolete&lt;/em&gt; version: the 2.x branch. The maintained version (the 3.x branch) has been there for years. The problem is: it is not &lt;a href="http://docs.python.org/3.0/whatsnew/3.0.html"&gt;backward-compatible&lt;/a&gt;. Even the absolute simplest thing in Python 2 (&lt;code&gt;print "Hello world!"&lt;/code&gt;) is &lt;em&gt;broken&lt;/em&gt; in Python 3.&lt;/p&gt;
&lt;p&gt;The Python core developers have presented Python 3 as a &lt;a href="https://wiki.python.org/moin/Python2orPython3"&gt;&lt;em&gt;new&lt;/em&gt; language&lt;/a&gt; that fixes many weaknesses of Python 2. This very claim might have frightened many people. What's more, some respected &lt;a href="http://lucumr.pocoo.org/2014/1/5/unicode-in-2-and-3/"&gt;Python developers&lt;/a&gt; are not that satisfied with the changes brought by Python 3. The situation looks really bad.&lt;/p&gt;
&lt;p&gt;Fortunately, things tend to become slightly better with time. We now have a &lt;a href="http://docs.python.org/2/library/2to3.html"&gt;few&lt;/a&gt; ways to release packages working seamlessly in &lt;em&gt;both&lt;/em&gt; branches, or even to have a &lt;a href="http://pythonhosted.org/six/"&gt;single code base&lt;/a&gt; for both branches. Those slightly hackish techniques are now becoming standard. Releasing Python 2-only or Python 3-only new libraries is considered as bad practice. I think it will take a &lt;em&gt;while&lt;/em&gt; before people just use Python 3 and forget Python 2 altogether.&lt;/p&gt;
&lt;p&gt;As far as scientific packages is concerned, I would say that, as of today, we're good. The vast majority of scientific libraries are compatible with Python 2 &lt;em&gt;and&lt;/em&gt; Python 3. A Pythonista scientist can choose to work either with Python 2 or Python 3.&lt;/p&gt;
&lt;p&gt;Of course, as time passes, using Python 3 instead of Python 2 for day-to-day work is more and more recommended. I have yet to do it, though. I guess we're all a bit refractory to change. More importantly, most people (including me) don't see much to be gained by making the switch. The benefit–cost ratio is probably still too weak. Non-scientist users (like Web developers) have probably more reasons to switch, be it only for Unicode support.&lt;/p&gt;
&lt;h2&gt;Package fragmentation&lt;/h2&gt;
&lt;p&gt;That's the problem of distributed, open-source, self-organizing large projects like scientific Python. New packages are being developed in parallel. They get more mature, they get users. Then they make small, minor API changes here and there. Then package A v3 works with package B v7 but not v6. Or not v8. You start to get complicated dependencies between the packages you use in your software. Because the Python packaging system is so broken (see next paragraph), your users complain again and again.&lt;/p&gt;
&lt;p&gt;I think this is hardly preventable with a young ecosystem like scientific Python. Hopefully things will become better with time.&lt;/p&gt;
&lt;h2&gt;The packaging system in Python&lt;/h2&gt;
&lt;p&gt;This is another tough one, probably even tougher than Python 3. In layman's terms (might be a bit simplistic): packaging refers to the problem of letting other people use your Python library or program. You develop your software on a configuration A, and you want to share it with people on configurations B, C, and D. A configuration refers to a combination of an operating system (Windows? Unix? Linux? OS X? 32-bit or 64-bit?), a version of Python (2.x? 3.x? 32-bit or 64-bit?), the versions of your 47 Python dependencies, among others.&lt;/p&gt;
&lt;p&gt;Solutions exist. They are all &lt;em&gt;terrible&lt;/em&gt;. I won't go into the details. &lt;a href="http://lucumr.pocoo.org/2012/6/22/hate-hate-hate-everywhere/"&gt;Others&lt;/a&gt; &lt;a href="http://python-packaging-user-guide.readthedocs.org/en/latest/"&gt;have&lt;/a&gt; &lt;a href="http://python-notes.boredomandlaziness.org/en/latest/pep_ideas/core_packaging_api.html"&gt;done&lt;/a&gt; &lt;a href="http://www.aosabook.org/en/packaging.html"&gt;it&lt;/a&gt; better than I could.&lt;/p&gt;
&lt;p&gt;It's even worse when it comes to Python programs with GUIs that you need to distribute to non-technical users (been there). You can't expect them to have a Python distribution, so you need to somehow &lt;a href="https://cyrille.rossant.net/create-a-standalone-windows-installer-for-your-python-application/"&gt;ship Python with your program&lt;/a&gt;. In my experience, it can be a nightmare. I have yet to find a good cross-platform solution that &lt;em&gt;just works&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Once again, things are slowly getting better. The official solutions are improving. Also, Continuum Analytics appears to be doing some &lt;a href="https://binstar.org/"&gt;really&lt;/a&gt; &lt;a href="http://technicaldiscovery.blogspot.fr/2013/12/why-i-promote-conda.html"&gt;good&lt;/a&gt; job in this respect, with their own conda/binstar system.&lt;/p&gt;
&lt;h2&gt;A glance at the future&lt;/h2&gt;
&lt;p&gt;I hope this post did not sound too much like a rant. It is not. I'm pretty happy with Python. I'm &lt;a href="http://klusta-team.github.io/"&gt;developing and maintaining software in Python&lt;/a&gt;. I even wrote &lt;a href="https://ipython-books.github.io/minibook/"&gt;a book on scientific Python&lt;/a&gt;! For sure, I don't plan to leave this platform anytime soon. And, in any case, what I would leave it for? I don't think there is a better alternative as of today.&lt;/p&gt;
&lt;p&gt;Things could be better. They always can. And, they &lt;em&gt;are&lt;/em&gt; getting better. I'm quite confident that scientific Python is going to be stronger and stronger in the years to come.&lt;/p&gt;
&lt;p&gt;Will Python be the best open platform for scientific computing in 5 years? I'm quite sure it will. In 10 years? 15 years? Not so sure.&lt;/p&gt;
&lt;p&gt;What will be the state of scientific computing in 10 years? Nobody can predict the future, but it's fun to try (even if we're totally wrong).&lt;/p&gt;
&lt;p&gt;In 10 years, Python will probably still be around. However, maybe will it have been beaten by something else. I don't know what this something else is going to be. Maybe &lt;a href="http://julialang.org"&gt;Julia&lt;/a&gt;, maybe something else. Maybe &lt;a href="http://blogs.perl.org/users/joel_berger/2014/01/on-the-relative-readability-of-perl-and-python.html"&gt;Perl&lt;/a&gt; (just kidding).&lt;/p&gt;
&lt;p&gt;This hypothetic language will be high-level, readable, easy to learn like Python, probably dynamic, maybe (partly) functional. But it won't have the limitations of CPython. It will be fast. &lt;a href="http://www.evanmiller.org/why-im-betting-on-julia.html"&gt;&lt;em&gt;Just&lt;/em&gt; fast&lt;/a&gt;. Loops will be fast. It may implement a (&lt;a href="http://en.wikipedia.org/wiki/LLVM"&gt;LLVM&lt;/a&gt;-based?) JIT compiler. It will fully embrace parallel and heterogeneous architectures. It will be as good as Python, without its weaknesses. Or maybe I'm wrong and Python 5 (incompatible with Python 4) is going to be the winner.&lt;/p&gt;
&lt;p&gt;Before I conclude, let me mention &lt;a href="http://ipython.org/"&gt;IPython&lt;/a&gt;. In 10 years, maybe will Python be stronger than ever. Or maybe will it have been replaced by another language. In any case, however, I think that IPython will be there for good. Maybe not IPython itself. But its legacy. The &lt;a href="http://ipython.org/_static/sloangrant/sloan-grant.html"&gt;open, reproducible science paradigm&lt;/a&gt;. The idea of a &lt;a href="http://blog.fperez.org/2012/01/ipython-notebook-historical.html"&gt;notebook for scientific computing&lt;/a&gt;. Maybe even the &lt;a href="http://andrew.gibiansky.com/blog/ipython/ipython-kernels/"&gt;very architecture of the notebook&lt;/a&gt; (including its &lt;a href="http://ipython.org/ipython-doc/stable/interactive/notebook.html"&gt;JSON-based file format&lt;/a&gt;), which is actually &lt;em&gt;already&lt;/em&gt; language-agnostic. Contrary to what its name suggests, IPython is not &lt;em&gt;that&lt;/em&gt; tied to Python. Yes, it is entirely written in Python. But still, I think it is more than just a nice interactive thing on top of Python (I mostly think about the notebook, obviously).&lt;/p&gt;
&lt;p&gt;So, what now? Should &lt;em&gt;you&lt;/em&gt; switch to Python? If you're happy with your existing platform, if you're happy to pay thousands of dollars when alternative open-source solutions exist, or if you're scared by the current weaknesses of Python, please don't change a thing.&lt;/p&gt;
&lt;p&gt;But if you &lt;em&gt;do&lt;/em&gt; want to change, if you are well aware of Python's limitations, if you are ready to face up to them (because solutions &lt;em&gt;do&lt;/em&gt; exist), if you are willing to discover an amazing and vibrant platform, then take the plunge.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>Why use Python for scientific computing?</title><link href="https://cyrille.rossant.net/why-using-python-for-scientific-computing/" rel="alternate"></link><published>2013-07-01T00:00:00+02:00</published><updated>2013-07-01T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2013-07-01:/why-using-python-for-scientific-computing/</id><summary type="html">&lt;p&gt;Why use Python for scientific computing? This is a legitimate question. For us, regular Python users, using Python is so natural that we sometimes forget that this choice is not obvious for everyone. Matlab is very widely used in some communities (e.g. experimental biologists) and choosing a different platform …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Why use Python for scientific computing? This is a legitimate question. For us, regular Python users, using Python is so natural that we sometimes forget that this choice is not obvious for everyone. Matlab is very widely used in some communities (e.g. experimental biologists) and choosing a different platform requires extensive proselytism. We need to find the right words to convince people that Python is really the future for scientific computing.&lt;/p&gt;


&lt;p&gt;&lt;a href="http://blog.fperez.org/2013/07/in-memoriam-john-d-hunter-iii-1968-2012.html"&gt;Citing&lt;/a&gt; &lt;a href="http://fperez.org/"&gt;Fernando Perez&lt;/a&gt;, creator of &lt;a href="http://ipython.org"&gt;IPython&lt;/a&gt;: &lt;em&gt;"I am absolutely convinced that in a few decades, historians of science will describe the period we are in right now as one of deep and significant transformations to the very structure of science. And in that process, the rise of free openly available tools plays a central role."&lt;/em&gt; I couldn't agree more. But being convinced is merely enough, and we need to be aware of objective facts supporting the idea that Python is just the best platform for scientific computing.&lt;/p&gt;
&lt;p&gt;Several people have written about why they chose Python over Matlab:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://sites.google.com/site/pythonforscientists/python-vs-matlab"&gt;Almar Klein: Python vs
    Matlab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stevetjoa.com/305/"&gt;Steve Tjoa: I used Matlab. Now I use
    Python.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://phillipmfeldman.org/Python/Advantages_of_Python_Over_Matlab.html"&gt;Philippe Feldman: Eight Advantages of Python Over
    Matlab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://vnoel.wordpress.com/2008/05/03/bye-matlab-hello-python-thanks-sage/"&gt;Vincent Noël: Bye Matlab, hello Python, thanks
    Sage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.stat.washington.edu/~hoytak/blog/whypython.html"&gt;Hoyt Koepke: 10 Reasons Python Rocks for Research (And a Few
    Reasons it
    Doesn’t)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I also found this &lt;a href="https://github.com/nipy/nipy/blob/master/doc/faq/why.rst"&gt;short text&lt;/a&gt; in the documentation of &lt;a href="http://nipy.org/"&gt;nipy&lt;/a&gt;, a neuroimaging Python library. I reproduce it here as is.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The choice of programming language has many scientific and practical consequences. Matlab is an example of a high-level language. Languages are considered high level if they are able to express a large amount of functionality per line of code; other examples of high level languages are Python, Perl, Octave, R and IDL. In contrast, C is a low-level language. Low level languages can achieve higher execution speed, but at the cost of code that is considerably more difficult to read. C++ and Java occupy the middle ground sharing the advantages and the disadvantages of both levels.&lt;/p&gt;
&lt;p&gt;Low level languages are a particularly ill-suited for exploratory scientific computing, because they present a high barrier to access by scientists that are not specialist programmers. Low-level code is difficult to read and write, which slows development ([Prechelt2000ECS], [boehm1981], [Walston1977MPM]) and makes it more difficult to understand the implementation of analysis algorithms. Ultimately this makes it less likely that scientists will use these languages for development, as their time for learning a new language or code base is at a premium. Low level languages do not usually offer an interactive command line, making data exploration much more rigid. Finally, applications written in low level languages tend to have more bugs, as bugs per line of code is approximately constant across many languages [brooks78].&lt;/p&gt;
&lt;p&gt;In contrast, interpreted, high-level languages tend to have easy-to-read syntax and the native ability to interact with data structures and objects with a wide range of built-in functionality. High level code is designed to be closer to the level of the ideas we are trying to implement, so the developer spends more time thinking about what the code does rather than how to write it. This is particularly important as it is researchers and scientists who will serve as the main developers of scientific analysis software. The fast development time of high-level programs makes it much easier to test new ideas with prototypes. Their interactive nature allows researchers flexible ways to explore their data.&lt;/p&gt;
&lt;p&gt;SPM is written in Matlab, which is a high-level language specialized for matrix algebra. Matlab code can be quick to develop and is relatively easy to read. However, Matlab is not suitable as a basis for a large-scale common development environment. The language is proprietary and the source code is not available, so researchers do not have access to core algorithms making bugs in the core very difficult to find and fix. Many scientific developers prefer to write code that can be freely used on any computer and avoid proprietary languages. Matlab has structural deficiencies for large projects: it lacks scalability and is poor at managing complex data structures needed for neuroimaging research. While it has the ability to integrate with other languages (e.g., C/C++ and FORTRAN) this feature is quite impoverished. Furthermore, its memory handling is weak and it lacks pointers - a major problem for dealing with the very large data structures that are often needed in neuroimaging. Matlab is also a poor choice for many applications such as system tasks, database programming, web interaction, and parallel computing. Finally, Matlab has weak GUI tools, which are crucial to researchers for productive interactions with their data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Globally, the main arguments are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python is free and open source, whereas Matlab is a closed-source
    commercial product.&lt;/li&gt;
&lt;li&gt;The Python &lt;em&gt;language&lt;/em&gt; is just far better that Matlab's awkward
    language.&lt;/li&gt;
&lt;li&gt;Python integrates better with other languages (e.g. C/C++).&lt;/li&gt;
&lt;li&gt;Python includes natively an impressive number of general-purpose or
    more specialized libraries, and yet more external libraries are
    being developed by Python enthusiasts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And, of course, nearly anything that is possible in Matlab is possible in Python, whereas the converse is not true.&lt;/p&gt;
&lt;p&gt;Now, a downside of Python compared to Matlab is that is just more complicated to install. For example, on Windows, a Matlab user can just install the software, click on the icon, and a full graphical IDE opens. In Python, there are some integrated scientific distributions with graphical IDEs but they are less convenient than Matlab. Using IPython involves either a command-line interface or a web interface (the notebook). And installing external libraries can be a pain (it almost always involves the command-line interface, which terrifies many Windows users). I think that's the main real problem that prevents Python from widespread adoption in the Matlab community.&lt;/p&gt;
&lt;p&gt;Yet, I'm pretty sure that Python will eventually become the platform of reference for scientific computing.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>Start an IPython notebook server in Windows Explorer</title><link href="https://cyrille.rossant.net/start-an-ipython-notebook-server-in-windows-explorer/" rel="alternate"></link><published>2013-06-30T00:00:00+02:00</published><updated>2013-06-30T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2013-06-30:/start-an-ipython-notebook-server-in-windows-explorer/</id><summary type="html">&lt;p&gt;When one starts using the IPython notebook seriously, there is often the need to open a server in the current directory to open or create a new notebook. Whereas this is straightforward on Unix systems (e.g. &lt;code&gt;ipython notebook --pylab inline&lt;/code&gt;) since users typically use mainly the command-line, it is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When one starts using the IPython notebook seriously, there is often the need to open a server in the current directory to open or create a new notebook. Whereas this is straightforward on Unix systems (e.g. &lt;code&gt;ipython notebook --pylab inline&lt;/code&gt;) since users typically use mainly the command-line, it is a bit more cumbersome from the graphical Windows Explorer. One needs to open a console, go in the current directory, type the command, open the browser, and go to &lt;code&gt;http://127.0.0.1:8888&lt;/code&gt; (unless the browser automatically launches).&lt;/p&gt;
&lt;p&gt;Here is a simple method to simplify the process. It is based on the great &lt;a href="http://www.autohotkey.com/"&gt;AutoHotKey&lt;/a&gt; tool which lets one automate repetitive tasks with e.g. keyboard shortcuts.&lt;/p&gt;


&lt;p&gt;Here is a script launching an IPython notebook server in the current active window:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;#SingleInstance&lt;/span&gt; &lt;span class="n"&gt;Force&lt;/span&gt;
&lt;span class="nb"&gt;#NoTrayIcon&lt;/span&gt;

&lt;span class="nb"&gt;SetTitleMatchMode&lt;/span&gt; &lt;span class="n"&gt;RegEx&lt;/span&gt;&lt;span class="c1"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;; Press CTRL+I in a Windows Explorer window to launch a IPython notebook server&lt;/span&gt;
&lt;span class="c1"&gt;; in the current folder.&lt;/span&gt;
&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;; Get the current path.&lt;/span&gt;
&lt;span class="nb"&gt;Send&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;; Backup the current clipboard.&lt;/span&gt;
&lt;span class="n"&gt;ClipSaved&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="nv"&gt;ClipboardAll&lt;/span&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;; Copy and save the current path.&lt;/span&gt;
&lt;span class="nb"&gt;Send&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;
&lt;span class="nb"&gt;ClipWait&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;%Clipboard%&lt;/span&gt;&lt;span class="c1"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;; Restore the clipboard.&lt;/span&gt;
&lt;span class="nv"&gt;Clipboard&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="n"&gt;ClipSaved&lt;/span&gt;
&lt;span class="n"&gt;ClipSaved&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="c1"&gt; ; Free the memory in case the clipboard was very large.&lt;/span&gt;
&lt;span class="c1"&gt;; Now, run the IPython notebook server.&lt;/span&gt;
&lt;span class="nb"&gt;RunWait&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ipython&lt;/span&gt; &lt;span class="n"&gt;notebook&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;pylab&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;notebook&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dir&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;%x%&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min&lt;/span&gt;
&lt;span class="nb"&gt;return&lt;/span&gt;&lt;span class="c1"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;; Press CTRL+ALT+P to kill all Python processes.&lt;/span&gt;
&lt;span class="o"&gt;^!&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;
&lt;span class="nb"&gt;Run&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;taskkill&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;im&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exe&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min&lt;/span&gt;
&lt;span class="nb"&gt;return&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Save this script in a &lt;code&gt;ipynb.ahk&lt;/code&gt; script and double-click on it. Then, pressing &lt;code&gt;CTRL+I&lt;/code&gt; launches an IPython notebook server in the current directory of the active window.&lt;/p&gt;
&lt;p&gt;Also, &lt;code&gt;CTRL+ALT+P&lt;/code&gt; kills all Python processes, which can be used to stop the server. The &lt;code&gt;CTRL+C&lt;/code&gt; command in the notebook server does not seem to work well on Windows.&lt;/p&gt;
&lt;p&gt;Finally, you can put this AutoHotKey script in your Startup Windows folder so that this shortcut is available at any time.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>Create a standalone Windows installer for your Python application</title><link href="https://cyrille.rossant.net/create-a-standalone-windows-installer-for-your-python-application/" rel="alternate"></link><published>2013-06-12T00:00:00+02:00</published><updated>2013-06-12T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2013-06-12:/create-a-standalone-windows-installer-for-your-python-application/</id><summary type="html">&lt;p&gt;I am developing &lt;a href="https://github.com/klusta-team/klustaviewa"&gt;a scientific application in Python with a graphical user interface in Qt&lt;/a&gt;. Some end-users use OS X or Linux, but most of them are Windows users who are not familiar with Python or with a command-line interface. It is notoriously difficult to distribute Python applications to end-users …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I am developing &lt;a href="https://github.com/klusta-team/klustaviewa"&gt;a scientific application in Python with a graphical user interface in Qt&lt;/a&gt;. Some end-users use OS X or Linux, but most of them are Windows users who are not familiar with Python or with a command-line interface. It is notoriously difficult to distribute Python applications to end-users who are not programmers, and it's a common criticism that is made against Python.&lt;/p&gt;


&lt;p&gt;I thought for a long time that there was nothing that could be done about that. But I recently wanted to find a solution. A complicated installation process can really be a barrier to entry for regular Windows users. So I've been looking for days for the right way to create a full standalone installer that installs everything (Python, external packages, and the software) along with icons on the desktop and the Start menu. I tried different approaches and none was satisfying at first. In particular, I tried to combine multiple installers for Python and the numerous external packages (NumPy, Matplotlib, PyQt, etc., coming from &lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/"&gt;Chris Gohlke's webpage&lt;/a&gt;) into a single installer. It looked like something difficult to do, especially when the installers are &lt;code&gt;.exe&lt;/code&gt; files and not &lt;code&gt;.msi&lt;/code&gt; files. I tried to use some script to launch all installers successively and have the Next buttons pressed automatically, but it was not working very well and it was a bit of a mess.&lt;/p&gt;
&lt;p&gt;I finally found a solution that I find quite satisfying. I haven't found this solution clearly explained anywhere on the Web, so I'm sharing it here. The goal is to distribute any Python application (possibly with a GUI) as a single-file &lt;code&gt;.exe&lt;/code&gt; installer. No dependencies, no prerequisites, just a regular &lt;code&gt;setup.exe&lt;/code&gt; file that installs everything, including a full standalone, isolated Python distribution, into &lt;code&gt;C:\Program Files\MyApp\&lt;/code&gt; like a regular program. The end-user does not even need to know that the software is written in Python.&lt;/p&gt;
&lt;p&gt;This solution can be summarized in two words: &lt;strong&gt;WinPython&lt;/strong&gt; and &lt;strong&gt;Inno Setup&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://code.google.com/p/winpython/"&gt;WinPython&lt;/a&gt; is a free scientific Python distribution for Windows that is portable, meaning that it is completely isolated from the rest of the system. WinPython can be installed in a folder, which can be moved anywhere, even on an USB stick, remaining entirely functional. WinPython is bundled with a lot of existing Python packages, but the huge advantage is that it includes graphical and command-line utilities to install/uninstall any Python package easily (from a zip or Windows binary installer generated by distutils).&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.jrsoftware.org/isinfo.php"&gt;Inno Setup&lt;/a&gt; is a free software for creating Windows installers. Building an installer requires to write a plain text script that contains the instructions about what to install and where. It has a lot of features, including desktop and start menu shortcuts, post-install scripts, etc. A wizard allows one to get started quickly and easily.&lt;/p&gt;
&lt;p&gt;Here is a summary of what you need to do to create an installer for your Python application. First, create a folder with a WinPython distribution including all your Python dependencies, and your own Python package as well. Second, create an installer that will just copy this folder somewhere on the end-user hard drive, along with shortcuts to run your application. Then, you can customize the installation process as you wish.&lt;/p&gt;
&lt;h3&gt;Step 1: customize your WinPython distribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Create a folder named &lt;code&gt;MyApplication&lt;/code&gt; somewhere on your development machine. This folder will be copied to &lt;code&gt;C:\Program Files\MyApplication&lt;/code&gt; by the installer.&lt;/li&gt;
&lt;li&gt;Download and install WinPython into, say, &lt;code&gt;MyApplication\WinPython-64bit-2.7.5.0&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;WinPython contains a GUI that lets you install/uninstall Python packages. There are a lot of packages built in, but you can remove those that you don't need for your application. You can also add new Python packages by dragging zip or exe installers (created with distutils) into the GUI.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Step 2: create the installer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install Inno Setup.&lt;/li&gt;
&lt;li&gt;Use the wizard to create a new installer file (it is just a &lt;code&gt;.iss&lt;/code&gt; text file).&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tell the wizard to copy your folder &lt;code&gt;MyApplication&lt;/code&gt; to &lt;code&gt;C:\Program Files\MyApplication&lt;/code&gt;. The ISS code for this looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[Files]&lt;/span&gt;
&lt;span class="na"&gt;Source: &amp;quot;D:\Dev\MyApplication&amp;quot;; DestDir: &amp;quot;{app}&amp;quot;; Flags: ignoreversion recursesubdirs createallsubdirs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note the &lt;code&gt;{app}&lt;/code&gt; variable which contains the user application path. &lt;a href="http://www.jrsoftware.org/ishelp/index.php?topic=consts"&gt;See the list of Inno Setup constants here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Step 3: create the shortcuts&lt;/h3&gt;
&lt;p&gt;Create some shortcuts. Here is the ISS code to create a shorcut in the Start menu launching a Python GUI application:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[Icons]&lt;/span&gt;
&lt;span class="na"&gt;Name: &amp;quot;{group}\Application&amp;quot;; Filename: &amp;quot;{app}\WinPython-64bit-2.7.5.0\python-2.7.5.amd64\pythonw.exe&amp;quot;; WorkingDir: &amp;quot;{app}&amp;quot;; Parameters: &amp;quot;&amp;quot;&amp;quot;{app}\WinPython-64bit-2.7.5.0\python-2.7.5.amd64\Lib\site-packages\myapplication\scripts\runmyapp.py&amp;quot;&amp;quot;&amp;quot;; IconFilename: &amp;quot;{app}\favicon.ico&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This code snippet assumes that the Python script running your application is in &lt;code&gt;myapplication\scripts\runmyapp.py&lt;/code&gt;. You could also have this script somewhere directly in your application folder and not necessarily in your Python package. You can also specify an icon as a &lt;code&gt;.ico&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;You can create shortcuts on the desktop too. &lt;a href="http://www.jrsoftware.org/ishelp/topic_iconssection.htm"&gt;See more details here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Step 4: customize the installation process&lt;/h3&gt;
&lt;p&gt;Inno Setup allows you to customize the installation process as you wish. Together with Python scripts, you can really achieve anything. For instance, here is how you can run a Python script at the end of the installation process.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[Run]&lt;/span&gt;
&lt;span class="na"&gt;Filename: &amp;quot;{app}\WinPython-64bit-2.7.5.0\python-2.7.5.amd64\python.exe&amp;quot;; WorkingDir: &amp;quot;{app}&amp;quot;; Parameters: &amp;quot;&amp;quot;&amp;quot;{app}\postinstall.py&amp;quot;&amp;quot;&amp;quot;; Flags: runhidden&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here are a few directives that you can use to customize some aspects of the installation wizard (icon, images, colors...):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[Setup]&lt;/span&gt;
&lt;span class="na"&gt;SetupIconFile&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;D:\Dev\myapp\favicon.ico&lt;/span&gt;
&lt;span class="na"&gt;WizardImageFile&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;wizard.bmp&lt;/span&gt;
&lt;span class="na"&gt;WizardImageStretch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;no&lt;/span&gt;
&lt;span class="na"&gt;WizardSmallImageFile&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;wizard-small.bmp&lt;/span&gt;
&lt;span class="na"&gt;WizardImageBackColor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;$ffffff&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Python code to install packages&lt;/h3&gt;
&lt;p&gt;You can create Python scripts that the user runs by clicking on an icon (see the &lt;code&gt;[Icons]&lt;/code&gt; section above). You can for instance create a small utility that updates automatically your application by checking the last installer version on a server, and downloading and executing it automatically. Here is some Python code snippet that installs or updates a Python package in the user's WinPython distribution, from a zip or a Windows package created with distutils.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;winpython&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;wppm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;utils&lt;/span&gt;

&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;dist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;wppm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Distribution&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prefix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;package&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;wppm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Package&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pathtoexefile&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;dist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;install&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;package&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Unable to install the package.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;This solution may not be adapted to everyone. But I think it is best for regular Windows users who are used to do everything with the mouse and who are scared by command line interfaces. It allows any Python developer to create and distribute a graphical application as easily as for a more standard C++ program. I imagine that games for Windows could be written with Python and be easily distributed like this. &lt;a href="http://kivy.org/"&gt;Kivy&lt;/a&gt;, a Python library used in media applications and games, uses a similar technique as far as I know.&lt;/p&gt;
&lt;p&gt;Finally, do take the time to &lt;a href="http://www.jrsoftware.org/ishelp/"&gt;browse Inno Setup's documentation&lt;/a&gt;. It is clear and well organized. And take a look to WinPython, it is nice and powerful, even if the documentation could be better. Actually I may start using it as my day-to-day Python distribution.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>Vélib' Open Data</title><link href="https://cyrille.rossant.net/velib-open-data/" rel="alternate"></link><published>2013-05-05T00:00:00+02:00</published><updated>2013-05-05T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2013-05-05:/velib-open-data/</id><summary type="html">&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/V%C3%A9lib%27"&gt;Vélib'&lt;/a&gt;, the public bicycle
sharing system in Paris. I've written a short &lt;a href="http://nbviewer.ipython.org/5520933"&gt;IPython
notebook&lt;/a&gt; to play with some of the
data, and to illustrate how easy it is to use Python for browsing and
analyzing public data sets. Here is an image representing the stations
in Paris, with the marker …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/V%C3%A9lib%27"&gt;Vélib'&lt;/a&gt;, the public bicycle
sharing system in Paris. I've written a short &lt;a href="http://nbviewer.ipython.org/5520933"&gt;IPython
notebook&lt;/a&gt; to play with some of the
data, and to illustrate how easy it is to use Python for browsing and
analyzing public data sets. Here is an image representing the stations
in Paris, with the marker size proportional to the number of bike stands
in each station, and the color indicating how many available stands
there are. The Seine is easily recognizable, and the fact that most
stations near the river are full might be linked to the fact that this
data has been obtained on a sunny Sunday of May...&lt;/p&gt;
&lt;p&gt;&lt;img alt="Vélib open data, Paris" src="/images/velib.png" /&gt;&lt;/p&gt;
</content><category term="misc"></category><category term="python"></category><category term="opendata"></category></entry><entry><title>IPython mini-book: Learning IPython for Interactive Computing and Data Visualization</title><link href="https://cyrille.rossant.net/ipython-mini-book/" rel="alternate"></link><published>2013-04-27T00:00:00+02:00</published><updated>2013-04-27T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2013-04-27:/ipython-mini-book/</id><summary type="html">&lt;p&gt;I'm glad to present my new book, &lt;a href="https://ipython-books.github.io/minibook/"&gt;Learning IPython for Interactive Computing and Data Visualization&lt;/a&gt;, Packt
Publishing.&lt;/p&gt;
&lt;p&gt;This book is a &lt;strong&gt;beginner-level introduction to IPython&lt;/strong&gt; for
interactive Python programming, high-performance numerical computing,
and data visualization. It assumes nothing more than familiarity with
Python. It targets developers, students, teachers, hobbyists who …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm glad to present my new book, &lt;a href="https://ipython-books.github.io/minibook/"&gt;Learning IPython for Interactive Computing and Data Visualization&lt;/a&gt;, Packt
Publishing.&lt;/p&gt;
&lt;p&gt;This book is a &lt;strong&gt;beginner-level introduction to IPython&lt;/strong&gt; for
interactive Python programming, high-performance numerical computing,
and data visualization. It assumes nothing more than familiarity with
Python. It targets developers, students, teachers, hobbyists who know
Python a bit, and who want to learn IPython for the extended console,
the Notebook, and for more advanced scientific applications.&lt;/p&gt;


&lt;p&gt;The book first introduces IPython for interactive Python and shell
programming. It shows how IPython can considerably improve the
productivity of a developer who creates, debugs, benchmarks and profiles
Python code.&lt;/p&gt;
&lt;p&gt;Then, the reader learns the very basics of vector computing, and
discovers how to load and analyze numerical and tabular data with NumPy
and Pandas. The book shows the interactive visualization capabilities of
the platform with Matplotlib, SciPy and PIL. It also contains a few
image processing examples.&lt;/p&gt;
&lt;p&gt;Some techniques to accelerate Python code are also demonstrated, using
either interactive parallel computing features from IPython (using MPI
or not), or Cython to compile a portion of the code in C for really
interesting speedups.&lt;/p&gt;
&lt;p&gt;Finally, the book shows how IPython can be customized for advanced uses,
notably with the creation of new extensions and magic commands.&lt;/p&gt;
&lt;p&gt;The code is stored in a &lt;a href="https://github.com/rossant/ipython-minibook"&gt;GitHub
repository&lt;/a&gt;. It contains
IPython notebooks with most examples from the book.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>The BRAIN initiative</title><link href="https://cyrille.rossant.net/the-brain-initiative/" rel="alternate"></link><published>2013-04-06T00:00:00+02:00</published><updated>2013-04-06T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2013-04-06:/the-brain-initiative/</id><summary type="html">&lt;p&gt;The &lt;a href="http://en.wikipedia.org/wiki/BRAIN_Initiative"&gt;&lt;em&gt;Brain Research through Advancing Innovative Neurotechnologies&lt;/em&gt;&lt;/a&gt; initiative has been &lt;a href="http://www.whitehouse.gov/the-press-office/2013/04/02/fact-sheet-brain-initiative"&gt;officially unveiled on April 2, 2013 by the President Obama&lt;/a&gt;. There had been quite excitement and interrogations in the few weeks before &lt;a href="http://www.nytimes.com/2013/02/18/science/project-seeks-to-build-map-of-human-brain.html?pagewanted=all&amp;amp;_r=0"&gt;as the President had mentioned a large-scale research project about the brain&lt;/a&gt; in his &lt;a href="http://www.nytimes.com/2013/02/13/us/politics/obamas-2013-state-of-the-union-address.html"&gt;State of the Union …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;The &lt;a href="http://en.wikipedia.org/wiki/BRAIN_Initiative"&gt;&lt;em&gt;Brain Research through Advancing Innovative Neurotechnologies&lt;/em&gt;&lt;/a&gt; initiative has been &lt;a href="http://www.whitehouse.gov/the-press-office/2013/04/02/fact-sheet-brain-initiative"&gt;officially unveiled on April 2, 2013 by the President Obama&lt;/a&gt;. There had been quite excitement and interrogations in the few weeks before &lt;a href="http://www.nytimes.com/2013/02/18/science/project-seeks-to-build-map-of-human-brain.html?pagewanted=all&amp;amp;_r=0"&gt;as the President had mentioned a large-scale research project about the brain&lt;/a&gt; in his &lt;a href="http://www.nytimes.com/2013/02/13/us/politics/obamas-2013-state-of-the-union-address.html"&gt;State of the Union&lt;/a&gt;. Very few details were given before the official announcement, and it was reported that this would be a decade-long, multi-billion dollars project seeking to &lt;em&gt;map the (eventually human) brain's activity by recording every single spike from every single neuron&lt;/em&gt;. When presented like that, this project's goals did not seem more realistic than the EU-funded &lt;a href="http://en.wikipedia.org/wiki/Human_Brain_Project_(EU)"&gt;Human Brain Project&lt;/a&gt; which aims at simulating the human brain at all spatiotemporal levels within ten years.&lt;/p&gt;


&lt;p&gt;But these goals are merely slogans used to justify the cost of these multi billion dollars projects to taxpayers and politicians. The actual objectives are less ambitious and more realistic, and important progress may be achieved even if the brain is not entirely "solved" in a decade. There have been &lt;a href="http://www.whitehouse.gov/infographics/brain-initiative"&gt;slightly more details about the BRAIN initiative&lt;/a&gt; during the announcement. It will initially be a $100 million investment in 2014 funded by the DARPA, NIH and NSF and a few private institutions including the &lt;a href="http://en.wikipedia.org/wiki/Allen_Institute_for_Brain_Science"&gt;Allen Institute for Brain Science&lt;/a&gt;. The goal is not to "map" entirely the human brain in a decade, which would have been ridiculous, but more realistically to spur the development of innovative technologies for large-scale recordings in the brain. Simple organisms will be considered at first, with recordings in humans coming much later.&lt;/p&gt;
&lt;p&gt;The fact that this project only concerns the experimental tools, and not more theoretical investigations like the &lt;em&gt;neural code&lt;/em&gt;, is quite interesting. The &lt;a href="http://en.wikipedia.org/wiki/Neural_coding"&gt;neural code&lt;/a&gt; has never been more mysterious. It is not an overstatement to say that we don't have any idea about how neurons encode and process the information, or how cognitive states emerge from the interactions between billions of neurons. There are some theories of course, but they're all somewhat basic and speculative as we don't have the actual tools to test them properly. There's no way we can progress in our understanding about the brain with the sole development of mathematical theories. We need experimental tools to test our theories, and that's precisely what the BRAIN initiative is about. Even if this project has to last ten years, its goal will eventually be a first small step in the scientific odyssey of the brain exploration. &lt;em&gt;This&lt;/em&gt; adventure is not the adventure of the decade, but the adventure of the century.&lt;/p&gt;
&lt;p&gt;Experimental tools do exist already. Tools like the MRI, EEG, MEG... record the average activity of large assemblies of neurons. Multielectrode arrays, optical imaging techniques... record the individual activity of tens of hundreds of neurons. But there's currently a lack of tools to observe tens of thousands of neurons individually (about the size of a cortical column). That's the order of magnitude the BRAIN initiative targets, and it will require innovative approaches.&lt;/p&gt;
&lt;p&gt;The example of the retina is particularly interesting. &lt;a href="http://www.sciencedirect.com/science/article/pii/0165027094900302"&gt;Multi-electrode recordings in the retina&lt;/a&gt; led to the possibility to record from several neurons simultaneously. &lt;a href="http://www.nature.com/nature/journal/v440/n7087/abs/nature04701.html"&gt;Pairwise correlations have been observed&lt;/a&gt;, and it has been shown that they almost completely capture the population activity in small networks of a few tens of neurons. A model assuming the independence between the neurons fails completely in describing the collective behavior of the network. This is an important result as it suggests the important role of precise synchronization in a neuronal network, and it wouldn't have been possible without the existence of these multi-electrode arrays. But further technological achievements led to the possibility to record from more neurons: in a larger network with about 100 neurons, &lt;a href="http://www.pnas.org/content/108/23/9679.short"&gt;it has been shown&lt;/a&gt; that pairwise correlations &lt;em&gt;are no longer enough&lt;/em&gt; and that one needs to take higher-order correlations into account with a sparse coding assumption. This example illustrates how successive technological achievements help us refine our models about how the brain works.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.guardian.co.uk/commentisfree/2013/apr/02/president-obama-brain-mapping-project-not-ideal"&gt;Some argue&lt;/a&gt; that technological developments always need to follow the theoretical concepts rather than the other way around, so that the BRAIN initiative is fundamentally flawed. I find it simplistic to think that there's a unidirectional link between technology and theory. Both need to evolve in parallel. Technology can yield conceptual progress, as the example of the retina shows. But technological advances can also be influenced by conceptual discoveries. There's no reason to discard completely one of those links.&lt;/p&gt;
&lt;p&gt;Whereas the project puts the emphasis on the experimental tools, the data-related aspects will also be crucial. Huge amounts of data will be generated when these tools become available, and we will need enough computing power to handle them. It's not a surprise that Google, Microsoft and Qualcomm were represented in an early project meeting in January at Caltech. For example, very large silicon probes for in vivo multichannel extracellular recordings are being developed. They will contain hundreds of microelectrodes, each recording at 20 kHz at least. That's hundreds of gigabytes per recording hour. &lt;a href="http://www.scholarpedia.org/article/Spike_sorting"&gt;Spike sorting algorithms&lt;/a&gt;, used to extract single-unit spiking activity from raw data, will have to scale to these huge data sets. We may expect to record from thousands of neurons with these probes.&lt;/p&gt;
&lt;p&gt;Other tools that were mentioned include nanoprobes and DNA-based recording units. Using DNA tapes to record spike trains seem very futuristic to me!&lt;/p&gt;
&lt;p&gt;&lt;a href="http://sciencehouse.wordpress.com/2013/02/26/brain-activity-map/"&gt;Some are skeptical about the necessity to record individual neurons to understand the brain&lt;/a&gt;, as it is a complex system that is "more than its parts". They make the analogy with gases: statistical mechanics work with a statistical approach, where there is no need to know the exact state of every single molecule. But a brain is really not a gas! I'm not sure that gases think and exhibit behaviors as complex as human thoughts. The analogy has its limits. Neurons are much more complex than molecules in a gas, and are much more tightly connected. Connections are not only local. There are multiscale spatiotemporal structures in the brain. Multiple layers, cortical columns, a wide variety of neuron types, short-term and long-term memory through synaptic plasticity, modulation by hormones and glial cells, etc. Neuronal wiring is not totaly random. Complex computations occur at different levels: micro-circuits, cortical columns, cortical areas, etc. There is definitely something to learn by recording the activity of thousands of neurons. Of course, statistical approaches are also relevant, but they need to be adapted. And this requires adapted experimental tools.&lt;/p&gt;
&lt;p&gt;There have been other criticisms. Will money be cut from existing projects to fund this new initiative? Even if the President Obama compared it to the Apollo program, BRAIN's goal is more vague than &lt;a href="http://en.wikipedia.org/wiki/Apollo_program"&gt;"landing a man on the Moon and returning him safely to the Earth"&lt;/a&gt;. How can we assess if the goal has been achieved in ten years? Also, are large-scale projects adapted to such fundamental and complex problems? Aren't independent projects conducted by different labs in the world more adapted? Maybe, but sometimes a big project like this can strongly boost scientific progress in some domain. Especially when there's a strong emphasis on &lt;em&gt;technological&lt;/em&gt; achievements, where funding needs to reach a critical mass to trigger innovative technologies. Also, a flagship project like this can really reach the public, inspire young generations and bring them to science.&lt;/p&gt;
&lt;p&gt;In the end, I am reasonably enthusiastic about this project, even if the details have yet to be sorted out. A team of scientists, &lt;a href="http://www.wired.com/wiredscience/2013/04/newsome/"&gt;including William Newsome&lt;/a&gt;, has the mission to develop a precise multi-year scientific plan in the following months. These are interesting times for neuroscience.&lt;/p&gt;</content><category term="misc"></category><category term="neuroscience"></category></entry><entry><title>Hardware-accelerated interactive data visualization in Python</title><link href="https://cyrille.rossant.net/hardware-accelerated-interactive-data-visualization-in-python/" rel="alternate"></link><published>2013-04-04T00:00:00+02:00</published><updated>2013-04-04T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2013-04-04:/hardware-accelerated-interactive-data-visualization-in-python/</id><summary type="html">&lt;p&gt;There have been several interesting discussions recently about the future of visualization in Python. &lt;a href="http://jakevdp.github.com/"&gt;Jake Vanderplas&lt;/a&gt; wrote a &lt;a href="http://jakevdp.github.com/blog/2013/03/23/matplotlib-and-the-future-of-visualization-in-python/"&gt;detailled post about the current state-of-the-art of visualization software in Python&lt;/a&gt;.
&lt;a href="http://mdboom.github.com"&gt;Michael Droettboom&lt;/a&gt;, one of the Matplotlib's core developers, consequently wrote about &lt;a href="http://mdboom.github.com/blog/2013/03/25/matplotlib-lessons-learned/"&gt;the future challenges Matplotlib will need to tackle&lt;/a&gt;. Matplotlib has …&lt;/p&gt;</summary><content type="html">&lt;p&gt;There have been several interesting discussions recently about the future of visualization in Python. &lt;a href="http://jakevdp.github.com/"&gt;Jake Vanderplas&lt;/a&gt; wrote a &lt;a href="http://jakevdp.github.com/blog/2013/03/23/matplotlib-and-the-future-of-visualization-in-python/"&gt;detailled post about the current state-of-the-art of visualization software in Python&lt;/a&gt;.
&lt;a href="http://mdboom.github.com"&gt;Michael Droettboom&lt;/a&gt;, one of the Matplotlib's core developers, consequently wrote about &lt;a href="http://mdboom.github.com/blog/2013/03/25/matplotlib-lessons-learned/"&gt;the future challenges Matplotlib will need to tackle&lt;/a&gt;. Matplotlib has been designed more than ten years ago, and now needs to embrace modern trends including web frontends, high-level R-style plotting interfaces, hardware-accelerated visualization, etc.&lt;/p&gt;


&lt;p&gt;One trend that I find particularly interesting concerns hardware acceleration. Standard &lt;a href="http://en.wikipedia.org/wiki/Graphics_processing_unit"&gt;graphics cards&lt;/a&gt; are now extremely powerful and are routinely used in 2D or 3D video games, web browsers, user interfaces. Mobile devices such as smartphones, tablets, and even the &lt;a href="http://en.wikipedia.org/wiki/Raspberry_Pi"&gt;Raspberry Pi&lt;/a&gt; include a decent graphical processing unit (GPU). There is no reason why hardware-acceleration should be absent in scientific visualization, where there is a really pressing need to display huge data sets. Graphics cards are now the most powerful computing units in a computer, and they are specifically adapted to fast visualization.&lt;/p&gt;
&lt;p&gt;Hardware-accelerated visualization is not always relevant. It is slightly less portable than a pure software implementation. It requires the graphics card drivers to be up-to-date, which is not always the case on non-technical users' computers. And it is not always necessary, as plots with a reasonable amount of data can still be smoothly displayed without using the graphics card at all.  In fact, a clear distinction needs to be made between &lt;em&gt;plotting&lt;/em&gt; and &lt;em&gt;interactive visualization&lt;/em&gt;. In the former, the emphasis is on the generation of high-quality static plots ready for publication, that represent some short and precise summary of the data. In the latter, the objective is to let the user take a look to the raw data, find out what the interesting statistics can be and if there are unexpected patterns. This step comes before the generation of publication-ready plots, and would much more benefit from hardware acceleration than for common plotting. Existing plotting libraries typically do not make the distinction between these two use cases.&lt;/p&gt;
&lt;h2&gt;Software&lt;/h2&gt;
&lt;p&gt;Hardware-accelerated visualization software is still a work in progress. As far as Python is concerned, libraries include: &lt;a href="http://rossant.github.com/galry"&gt;Galry&lt;/a&gt;, which I started a few months ago, &lt;a href="https://code.google.com/p/glumpy/"&gt;Glumpy&lt;/a&gt;, &lt;a href="https://code.google.com/p/visvis/"&gt;Visvis&lt;/a&gt;, &lt;a href="http://www.pyqtgraph.org/"&gt;PyQtGraph&lt;/a&gt; which has support for hardware-accelerated 3D visualization. All these libraries use OpenGL for hardware acceleration. Let's also mention &lt;a href="http://code.enthought.com/projects/mayavi/"&gt;Mayavi&lt;/a&gt; which is specifically designed for 3D rendering.&lt;/p&gt;
&lt;p&gt;I started Galry because I needed to plot very large data sets containing more than ten million points, and no existing library could support such large data. One may wonder why someone would need to plot more than ten million points whereas screens have merely a few million pixels. The answer is simple: to visualize large datasets &lt;em&gt;interactively&lt;/em&gt;. For instance, displaying an outline of the whole dataset, before zooming in on the regions of interest. Huge datasets are not rare today: a one-hour long signal sampled at 20 kHz represents already 72 million points (example of an intracellular recording). This gets worse with multi-channel data, like in &lt;a href="http://en.wikipedia.org/wiki/Multielectrode_array"&gt;multi-electrode extracellular recordings&lt;/a&gt;. There can be tens and even hundreds of signals in parallel (for example with recordings in the retina). These are typical cases where the graphics card can really be helpful for visualization.&lt;/p&gt;
&lt;h3&gt;Example: multi-channel recordings viewer&lt;/h3&gt;
&lt;p&gt;In fact I recently wrote a small prototype with Galry for quick visualization of multi-channel recordings. The data is assumed to be stored in an HDF5 file, which can weigh several gigabytes. Such a large file can merely reside in system memory, even less in graphics memory, so it needs to be dynamically fetched as one navigates within the plot. Reading data from the disk occurs in an external thread so that the interface is not frozen. When zooming out, the signals are automatically and dynamically undersampled. These techniques enable fast and smooth interactive visualization of huge datasets.&lt;/p&gt;
&lt;p&gt;&lt;embed width="640" height="480" src="http://www.youtube.com/v/arSLMooNfHY" /&gt;&lt;/p&gt;
&lt;h2&gt;Web-based interactive visualization&lt;/h2&gt;
&lt;p&gt;Another interesting direction concerns web browser frontends. We spend more and more time in the browser in general. The success of the IPython notebook shows that interactive computing can seamlessly happen in the browser. There are excellent web-based visualization libraries out there, like &lt;a href="http://d3js.org/"&gt;D3&lt;/a&gt; or &lt;a href="http://mrdoob.github.com/three.js/"&gt;threeJS&lt;/a&gt;. The &lt;a href="http://en.wikipedia.org/wiki/WebGL"&gt;WebGL standard&lt;/a&gt;, although young, brings native, plugin-free hardware-acceleration graphics in the browser via OpenGL ES 2.0. It is supported in most recent browsers. Even &lt;a href="http://withinwindows.com/within-windows/2013/3/30/blues-clues-how-to-enable-webgl-in-internet-explorer-11"&gt;Internet Explorer might support it in the future&lt;/a&gt;. So the technology exists for bringing high performance interactive data visualization to the browser. There is definitely some work to do here.&lt;/p&gt;
&lt;p&gt;In Python, web-based interactive visualization could be done in two ways. In the first, &lt;a href="http://mdboom.github.com/blog/2012/10/11/matplotlib-in-the-browser-its-coming/"&gt;VNC-like approach&lt;/a&gt;, user actions are captured by Javascript, transferred to Python which generates a static visualization and returns it back to the browser as a compressed image. In the second approach, the actual visualization happens entirely in the browser. The first approach is probably more generic and simpler to implement, whereas the latter could be useful for static notebooks or webpages. In a data sharing perspective, having a pure HTML/Javascript interactive visualization that does not require a Python backend engine would be quite relevant. Both approaches are complementary.&lt;/p&gt;
&lt;h2&gt;The future&lt;/h2&gt;
&lt;p&gt;In summary, the technology for hardware-accelerated interactive visualization in Python and in the browser is there. Different Python libraries have been developed independently, have different code bases, offer different programming interfaces and are not mutually compatible. For these reasons, the developers of these libraries are currently working on a &lt;a href="https://github.com/pyvis/pyvis"&gt;new project&lt;/a&gt; that has the goal to allow more sharing of code between these libraries, and to provide interfaces to OpenGL at different levels of abstraction and generality. The long-term goal for this project is to offer a single library for high-performance visualization, be it 2D or 3D, for scientific purposes or not, etc. But for now, we're focusing on building high-quality modules operating at different levels of abstraction, from low-level OpenGL to high-level plotting and interaction commands. We'll start with the low-level blocks, so that we can rewrite our different libraries on top of them.&lt;/p&gt;
&lt;p&gt;That's an ambitious and difficult project that will take time, but the core technology and code is already there. The hard part is to create a coherent, flexible and high-quality architecture for supporting different levels of abstraction in a seamless and efficient way. I'm confident that we'll come up with a solid piece of software at some point. And of course, if you're interested, you're welcome to contribute.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category><category term="dataviz"></category><category term="gpu"></category></entry><entry><title>Playing with Ruzzle in Python</title><link href="https://cyrille.rossant.net/playing-with-ruzzle-in-python/" rel="alternate"></link><published>2013-02-12T00:00:00+01:00</published><updated>2013-02-12T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2013-02-12:/playing-with-ruzzle-in-python/</id><summary type="html">&lt;p&gt;Ruzzle is becoming a popular game on smartphones and tablets. Inspired by
Boggle, it consists in finding as many words as possible in a grid of 4x4
letters. Here I'll show how one can easily generate and resolve grids
automatically in Python.&lt;/p&gt;


&lt;h2&gt;Generating grids&lt;/h2&gt;
&lt;p&gt;A grid is a &lt;span class="math"&gt;\(N \times …&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Ruzzle is becoming a popular game on smartphones and tablets. Inspired by
Boggle, it consists in finding as many words as possible in a grid of 4x4
letters. Here I'll show how one can easily generate and resolve grids
automatically in Python.&lt;/p&gt;


&lt;h2&gt;Generating grids&lt;/h2&gt;
&lt;p&gt;A grid is a &lt;span class="math"&gt;\(N \times M\)&lt;/span&gt; matrix of letters (&lt;span class="math"&gt;\(N=M=4\)&lt;/span&gt; here). The letters are randomly
sampled according to some probability distribution. We'll see how we can
generate grids with a reasonably good number of possible words.&lt;/p&gt;
&lt;h3&gt;Sampling letters&lt;/h3&gt;
&lt;p&gt;The easiest way of sampling letters is to use a uniform distribution over
the alphabet. However, uncommon letters will appear as frequently as the most
common letters, which will yield awkward grids with very few existing words.
What we can do is take the frequency of letters across all existing words in
a given language, and sample letters according to this distribution.
The frequency list can be found on Wikipedia for example
(&lt;a href="http://en.wikipedia.org/wiki/Letter_frequency"&gt;here for English&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;I created two text files, one with the list of all letters by decreasing
order of frequency, one with the list of frequencies for each letter.
These files can be easily opened with Numy's &lt;code&gt;loadtxt&lt;/code&gt;. Then, to sample
letters according to this distribution, we can use the following code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;frequencies_cum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cumsum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frequencies&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;digitize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;frequencies_cum&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;grid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;letters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dig&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here, &lt;code&gt;letters&lt;/code&gt; is a 26-long vector with the letters,
&lt;code&gt;frequencies&lt;/code&gt; is a 26-long vector with the letter frequencies,
&lt;code&gt;count&lt;/code&gt; is the number of letters
to sample, and &lt;code&gt;rows&lt;/code&gt; and &lt;code&gt;columns&lt;/code&gt; are the number of rows and columns in
the grid. The idea is to partition the interval &lt;span class="math"&gt;\([0,1]\)&lt;/span&gt; into 26 boxes,
each box size being equal to the corresponding letter's frequency. By
sampling uniform values in &lt;span class="math"&gt;\([0,1]\)&lt;/span&gt; and getting the corresponding boxes
in which they appear, we
obtain random values between 0 and 25 that correspond to random letters
respecting the frequencies. Mathematically, this method is called
&lt;a href="http://en.wikipedia.org/wiki/Inverse_transform_sampling"&gt;&lt;em&gt;inverse transform sampling&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;cumsum&lt;/code&gt; function yields the cumulative probability distribution,
and &lt;code&gt;digitize&lt;/code&gt; represents the inverse function. The &lt;code&gt;dig&lt;/code&gt; variable contains
random integer indices between 0 and 25, and finally &lt;code&gt;grid&lt;/code&gt; is a Numpy array
with the random letters.&lt;/p&gt;
&lt;p&gt;It would be possible to extend this generation method by taking second-order
statistics into account (i.e. the frequency of each &lt;em&gt;pair&lt;/em&gt; of successive
letters across all words) and generating the grid by taking these second-order
correlations into account. However this would be much more complicated and
probably overkill for small grids!&lt;/p&gt;
&lt;h3&gt;Using the IPython notebook&lt;/h3&gt;
&lt;p&gt;Now, we can define a simple Python class for generating a grid and displaying a
nice representation in the IPython notebook. The principle is to
create a &lt;code&gt;_repr_html_&lt;/code&gt; method for the class so that a HTML table is displayed
in the notebook. Here is an example of such a class:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Grid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;
        &lt;span class="c1"&gt;# generating the grid&lt;/span&gt;
        &lt;span class="n"&gt;frequencies_cum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cumsum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frequencies&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;dig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;digitize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;frequencies_cum&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;letters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dig&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_repr_html_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;style_td&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;        width: 50px;&lt;/span&gt;
&lt;span class="s2"&gt;        height: 50px;&lt;/span&gt;
&lt;span class="s2"&gt;        font-size: 24pt;&lt;/span&gt;
&lt;span class="s2"&gt;        text-align: center;&lt;/span&gt;
&lt;span class="s2"&gt;        vertical-align: middle;&lt;/span&gt;
&lt;span class="s2"&gt;        text-transform: uppercase;&lt;/span&gt;
&lt;span class="s2"&gt;        font-weight: bold;&lt;/span&gt;
&lt;span class="s2"&gt;        background: #eee;&lt;/span&gt;
&lt;span class="s2"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;table&amp;gt;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;tr&amp;gt;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;td style=&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{0:s}&lt;/span&gt;&lt;span class="s1"&gt;&amp;quot;&amp;gt;&lt;/span&gt;&lt;span class="si"&gt;{1:s}&lt;/span&gt;&lt;span class="s1"&gt;&amp;lt;/td&amp;gt;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                    &lt;span class="n"&gt;style_td&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;/tr&amp;gt;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;/table&amp;gt;&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;__init__&lt;/code&gt; constructor just contains the grid generation code we described
above. The interesting part is in the &lt;code&gt;_repr_html_&lt;/code&gt; method. We define a HTML
table, some basic CSS styles and we return the code. Then, in the IPython
notebook, displaying a grid is a simple as this:&lt;/p&gt;
&lt;p&gt;The
&lt;a href="http://ipython.org/ipython-doc/dev/api/generated/IPython.core.formatters.html"&gt;rich display feature&lt;/a&gt;
can also be used to display SVG, PNG, JPEG, LaTeX
or JSON representations. In the future, there will be the possibility to
write custom Javascript extensions, and we can expect to have
rich representations using libraries such as D3, ThreeJS, WebGL, etc.
I can't even imagine the incredibly cool stuff we're going to see in
the notebook in the months and years to come.&lt;/p&gt;
&lt;h2&gt;Solving grids&lt;/h2&gt;
&lt;p&gt;Now that we generated grids, how about solving them? I won't describe how
to implement the game in Python, but rather how to code a robot that solves
a grid automatically.&lt;/p&gt;
&lt;h3&gt;Using a dictionary&lt;/h3&gt;
&lt;p&gt;The first step is to find a dictionary with the list of all possible words
in a given language. For the French language,
&lt;a href="http://www.pallier.org/ressources/dicofr/dicofr.html"&gt;I found this dictionary with 336,531 words&lt;/a&gt;.
It's a few megabytes large. I had to get rid of the accents, and I used the
following code snippet
(&lt;a href="http://stackoverflow.com/questions/517923/what-is-the-best-way-to-remove-accents-in-a-python-unicode-string"&gt;found here&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;unicodedata&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;dictionary_accents.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;dictionary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;dictionary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;unicode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;utf8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dictionary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;unicodedata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;normalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;NFKD&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ascii&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;dictionary.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, the dictionary can be simply loaded in Python using Numpy's &lt;code&gt;loadtxt&lt;/code&gt;
function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;dictionary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;loadtxt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;dictionary.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Using an efficient data structure for the dictionary&lt;/h3&gt;
&lt;p&gt;We're going to write an algorithm that automatically resolves a grid by finding
all possible words according to the dictionary. It's a computationally
intensive task, even for small grids, since there's a combinatorial explosion.
Using naive algorithms and data structures won't work for 4x4 grids. Therefore
I'll detail the easiest techniques that allow to solve a 4x4 grid
instantaneously (a few tens of milliseconds on an old laptop).&lt;/p&gt;
&lt;p&gt;The algorithm will work by starting from any letter, and recursively going
through all neighbors in the grid, checking at each iteration that the
current word exists in the dictionary. The number of paths is huge, and the
dictionary is several hundreds of thousands of words long. Searching each word
in the dictionary by looking for every existing word individually is largely
infeasible. A possibility is to use a more efficient data structure than
just a linear list of possible words.&lt;/p&gt;
&lt;p&gt;The data structure I chose is a &lt;a href="http://en.wikipedia.org/wiki/Trie"&gt;trie&lt;/a&gt;.
It is a
tree-like data structure that is particularly adapted here. Indeed, it offers
a very efficient way of checking if one word appears in the dictionary,
or &lt;em&gt;if it's the prefix of at least one existing word&lt;/em&gt;. The latter point is
crucial, because it allows to know in advance when an exploratory path is
condemned, i.e. when no other word can be found by appending letters to the
current word. In this case the solving algorithm will backtrack and try
other paths directly.&lt;/p&gt;
&lt;p&gt;In this tree, the root corresponds to the empty string,
every internal node corresponds to a prefix, and every leaf
corresponds to an existing word in the dictionary.&lt;/p&gt;
&lt;p&gt;&lt;img alt="A trie" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/be/Trie_example.svg/200px-Trie_example.svg.png" /&gt;&lt;/p&gt;
&lt;p&gt;I found a
&lt;a href="http://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python"&gt;code snippet on StackOverflow&lt;/a&gt;
implementing a trie in Python. It is particularly simple, because a structure
with nested Python dictionaries is perfectly adapted for tries.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;_end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;_end_&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;make_trie&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;current_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;letter&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;current_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;current_dict&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setdefault&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;letter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{})&lt;/span&gt;
        &lt;span class="n"&gt;current_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;current_dict&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setdefault&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_end&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_end&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This function takes a list of words as an argument, and converts it into
a trie. To get all words starting with &lt;code&gt;sta&lt;/code&gt;, we just use
&lt;code&gt;trie['s']['t']['a']&lt;/code&gt;. Now, here is the function to efficiently check
if a word is in the dictionary:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;in_trie&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trie&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;current_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;trie&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;letter&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;letter&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;current_dict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;current_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;current_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;letter&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;_end&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;current_dict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This function explores the tree following the letters in the word, and
returns &lt;code&gt;True&lt;/code&gt; if it ends on a leaf.&lt;/p&gt;
&lt;p&gt;Here is the function to check is a string is a prefix to at least one word
in the dictionary:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;prefix_in_trie&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trie&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;current_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;trie&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;letter&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;letter&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;current_dict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;current_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;current_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;letter&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Solving algorithm&lt;/h3&gt;
&lt;p&gt;Now, here is the solving algorithm. We first start from any letter in the grid.
Then, we check if 1) the current word is in the dictionary and 2) whether
the path is not condemned, i.e. there are other words to find on this current
path. If everything's ok, we go through all neighbors of the current position
and we apply &lt;em&gt;recursively&lt;/em&gt; the same function on the expanded paths.
The exploration corresponds to a
&lt;a href="http://en.wikipedia.org/wiki/Depth-first_search"&gt;depth-first search in a graph&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We use several data structures. First, &lt;code&gt;words&lt;/code&gt; is the list of all words
found so far, initially empty. The current path is stored in a list &lt;code&gt;positions&lt;/code&gt;
containing a list of tuples &lt;code&gt;(i,j)&lt;/code&gt;. It allows us
to avoid crossings in the paths, i.e. we can't explore an already visited
position in a given path.&lt;/p&gt;
&lt;p&gt;Here is the code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_word&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;positions&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Get the word corresponding to a path (list of positions).&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;positions&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;neighbors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;explore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;positions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# process current word&lt;/span&gt;
    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_word&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;positions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# check if the word is in the dictionary&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;in_trie&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trie&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# stop if this path is condemned, i.e. no more word possible&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;prefix_in_trie&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trie&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;
    &lt;span class="c1"&gt;# go through all neighbors of the last position&lt;/span&gt;
    &lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;positions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;neighbor&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;neighbors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;npos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;neighbor&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;neighbor&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="c1"&gt;# check if the neighbor is admissible&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;npos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;npos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;npos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;npos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;# avoid self-intersections&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;npos&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;positions&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="c1"&gt;# we create a copy of the list positions instead of&lt;/span&gt;
                &lt;span class="c1"&gt;# updating the same list!&lt;/span&gt;
                &lt;span class="n"&gt;npositions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;positions&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;npos&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="c1"&gt;# explore the new path&lt;/span&gt;
                &lt;span class="n"&gt;explore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;npositions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;find_words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Return all possible words in a grid.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;explore&lt;/span&gt;&lt;span class="p"&gt;([(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# sort words by decreasing order of length&lt;/span&gt;
    &lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;cmp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;))[::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This algorithm appears to be sufficiently performant on 4x4 grids thanks
to our efficient trie data structure. A naive implementation with a Numpy
array for the dictionary takes several minutes instead of a few tens of
milliseconds with the trie.&lt;/p&gt;
&lt;p&gt;As an example, here is the list of words found on the grid shown above
(in French):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;barbue, reacs, ruera, barbu, cabus, ubacs, scare, jura, jure, reac, crue, crus, urus, abus, ruer, bacs, busc, bure, brus, cuba, cura, cure, cabs, guru, grue, ubac, suca, surs, rea, eau, cru, ure, are, rue, rua, rus, bar, bac, bus, bue, bru, cab, car, gus, suc, sur, ra, re, eu, cl, au, ru, bu, ca, us, su.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Finally, the full code, including the dictionary,
&lt;a href=""&gt;can be downloaded here&lt;/a&gt;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>NumPy performance tricks</title><link href="https://cyrille.rossant.net/numpy-performance-tricks/" rel="alternate"></link><published>2013-01-27T00:00:00+01:00</published><updated>2013-01-27T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2013-01-27:/numpy-performance-tricks/</id><summary type="html">&lt;p&gt;I've been using NumPy for nearly five years, but I'm still learning
performance tricks. The reason is that I currently need to deal with
very large arrays (hundreds of millions of elements) and the performance
of my code started to be disappointing. Then, through extensive
line-by-line profiling, I discovered some …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been using NumPy for nearly five years, but I'm still learning
performance tricks. The reason is that I currently need to deal with
very large arrays (hundreds of millions of elements) and the performance
of my code started to be disappointing. Then, through extensive
line-by-line profiling, I discovered some subtleties that explain why
some seemingly harmless lines of code can actually lead to major
bottlenecks. Very often, a small trick allows to significantly improve
the performance. Here is what I've learnt. These tips are intended to
regular Numpy users rather than pure beginners.&lt;/p&gt;


&lt;p&gt;&lt;a href="https://ipython-books.github.io/featured-01.html"&gt;&lt;strong&gt;A new version of this post can be found here.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>Twelve Tips about Starting a New Open-Source Project</title><link href="https://cyrille.rossant.net/twelve-tips-about-starting-a-new-open-source-project/" rel="alternate"></link><published>2012-12-01T00:00:00+01:00</published><updated>2012-12-01T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-12-01:/twelve-tips-about-starting-a-new-open-source-project/</id><summary type="html">&lt;p&gt;Here are some tips targeting developers who want to create an open-source
project. They reflect my personal opinion and may not be all adapted to
every situation.&lt;/p&gt;


&lt;h2&gt;Meet a need&lt;/h2&gt;
&lt;p&gt;So, you want to create a new &lt;a href="http://en.wikipedia.org/wiki/Open_source"&gt;open-source project&lt;/a&gt;? That's a good idea, but you need to understand very early …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here are some tips targeting developers who want to create an open-source
project. They reflect my personal opinion and may not be all adapted to
every situation.&lt;/p&gt;


&lt;h2&gt;Meet a need&lt;/h2&gt;
&lt;p&gt;So, you want to create a new &lt;a href="http://en.wikipedia.org/wiki/Open_source"&gt;open-source project&lt;/a&gt;? That's a good idea, but you need to understand very early why you want to do that. "Because it's fun"is not always a sufficient answer. Well, you can always learn by writing some software that will only be used by yourself and which will give you some experience, but at some point, you'll want your stuff to be used by other people.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;So, what is new about your project?&lt;/li&gt;
&lt;li&gt;Why do you need to create a new project instead of using or improving existing
    projects?&lt;/li&gt;
&lt;li&gt;What does it offer that is not brought by other projects?&lt;/li&gt;
&lt;li&gt;Why would people be interested in your project?&lt;/li&gt;
&lt;li&gt;Who are you targetting? Other developers with a new programming library,
    consumers, etc.?&lt;/li&gt;
&lt;li&gt;Are you confident that you'll be able to devote to that project an
    important part of your time for the next few months or years?&lt;/li&gt;
&lt;li&gt;Do you have sufficient experience and knowledge to be able to write your very
    own software?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Creating a software or a library is a tough but rewarding task. And it can be fun! You just need to think carefully about your project before you write a single line of code.&lt;/p&gt;
&lt;h2&gt;Be an expert in your language&lt;/h2&gt;
&lt;p&gt;So, you've chosen the programming language you'll be using for your project. Do you consider yourself as an expert in that language? Needless to say that you should already be experienced enough in the tools you'll be using. You'll need to know about all aspects of your language. If you're using &lt;a href="http://en.wikipedia.org/wiki/Object-oriented_programming"&gt;object-oriented programming&lt;/a&gt;, make sure you know about all its subtleties.&lt;/p&gt;
&lt;p&gt;For example, I've recently started a project using &lt;a href="http://en.wikipedia.org/wiki/Python_(programming_language)"&gt;Python&lt;/a&gt; and &lt;a href="http://en.wikipedia.org/wiki/OpenGL"&gt;OpenGL&lt;/a&gt;. Whereas at the time I started this project, I considered myself sufficiently aknowledged about Python, I clearly was not about OpenGL. So, I learnt OpenGL while I was developing my software. At some point, I realized I could use newer techniques that were much more powerful. More importantly, &lt;a href="https://cyrille.rossant.net/shaders-opengl/"&gt;the techniques I was using then were in fact totally obsolete&lt;/a&gt;. My sources of documentation were simply completely outdated. I had to make important changes in my code in order to use the newer techniques. Had I be sufficiently aware about OpenGL before, I could have made the right decisions early on.&lt;/p&gt;
&lt;h2&gt;Write only in English&lt;/h2&gt;
&lt;p&gt;This advice only concerns non-English native speakers. I see many students in programming write code in some weird mixed language between their native language and English. There will always be some words in English in the code, be it only because of the English keywords in any programming language. I can understand the fact that someone is attached to their mother tongue, but the programming world is international. You can &lt;em&gt;never&lt;/em&gt; be absolutely sure that some code you're writing today for yourself will never be used by someone else in the future. And that someone may not speak your language. How would you explain to that Chinese intern that he needs to learn Polish just to understand your comments in the code?&lt;/p&gt;
&lt;p&gt;Of course, the same advice holds even stronger for any documentation you'd
write. If you're not fluent enough in English, take lessons (and I should too).&lt;/p&gt;
&lt;h2&gt;Be an expert in your version control system&lt;/h2&gt;
&lt;p&gt;Using a &lt;a href="http://en.wikipedia.org/wiki/Revision_control"&gt;version control system&lt;/a&gt; for any programming project is so natural and obvious that I don't even consider that as an advice... You don't even need to subscribe to an online service at first, you can just install a local &lt;a href="http://en.wikipedia.org/wiki/Distributed_revision_control"&gt;distributed version system&lt;/a&gt; such as &lt;a href="http://en.wikipedia.org/wiki/Git_(software)"&gt;git&lt;/a&gt; or &lt;a href="http://en.wikipedia.org/wiki/Mercurial"&gt;mercurial&lt;/a&gt; on your computer. Of course, at some point you'll want to host your code online, it's just so much more practical and secure. It's also nearly imperative when you work with different computers.&lt;/p&gt;
&lt;p&gt;If you want your code to be both private and hosted online, you'll need to pay if you use &lt;a href="https://github.com/"&gt;Github&lt;/a&gt;. However, &lt;a href="http://sourceforge.net"&gt;Sourceforge&lt;/a&gt; should let you do that for free.&lt;/p&gt;
&lt;p&gt;Anyway, the point is that you need to understand most workings of your version control system of choice. If you're not familiar enough with it, take the time and learn it. It's important. It's the backbone of your code.&lt;/p&gt;
&lt;p&gt;Now, I should really follow this advice myself and go learn git for good.&lt;/p&gt;
&lt;h2&gt;Programming is easy, designing is harder&lt;/h2&gt;
&lt;p&gt;Programming is easy. At least, it can be (especially with Python!). &lt;a href="http://briggs.net.nz/snake-wrangling-for-kids.html"&gt;Children can learn the most basic aspects&lt;/a&gt;. Some languages are harder for sure. And the code can also be intrinsically involved sometimes, for example with concurrent and parallel programming.&lt;/p&gt;
&lt;p&gt;My point is that programming is not necessarily the hard part. &lt;em&gt;Designing&lt;/em&gt; is the tough one. Thinking about &lt;a href="http://en.wikipedia.org/wiki/Software_design"&gt;the perfect architecture&lt;/a&gt; for your code is, at least in my own experience, much, much harder than just "spewing out" code. Thinking about a coherent way of organizing your code into loosely-coupled modules, making your code simultaneously readable, flexible and efficient, designing a streamlined programming interface, these are the real challenges.&lt;/p&gt;
&lt;p&gt;Unfortunately, I don't have any concrete advice about how to achieve that. I know that many people are using some formal methods for finding the prefect architecture, involving horrid swearwords such as &lt;a href="http://en.wikipedia.org/wiki/Unified_Modeling_Language"&gt;"UML"&lt;/a&gt; and scary schematics with many boxes and arrows all over the place. I've never had the chance to learn that in school, and I've naturally been developing a more &lt;em&gt;instinctive&lt;/em&gt; (who said bogus?) way of thinking about the big picture.&lt;/p&gt;
&lt;p&gt;&lt;img alt="UML" src="http://upload.wikimedia.org/wikipedia/commons/8/81/UML_Diagrams.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Take the time to think about the code you're writing. Is it &lt;a href="http://en.wikipedia.org/wiki/Code_smell"&gt;smelling good&lt;/a&gt;? If not, think again and &lt;a href="http://en.wikipedia.org/wiki/Refactoring"&gt;refactor&lt;/a&gt;. Is your code design rigid or flexible? Are you doing it the right way? Being constantly critical about your own code allows you to deal with &lt;a href="http://en.wikipedia.org/wiki/Anti-pattern"&gt;badly designed code&lt;/a&gt; early on.&lt;/p&gt;
&lt;h2&gt;Don't spare the doc&lt;/h2&gt;
&lt;p&gt;Are you immortal and do you have an infallible memory? If not, you should document everything you do for your project. Document all your functions, with the details about the arguments and the returned variables (&lt;a href="http://en.wikipedia.org/wiki/Docstring"&gt;docstrings&lt;/a&gt;). Comment your code when it's unclear. Maintain separate documents about the global architecture of your code, about any decision you've made.&lt;/p&gt;
&lt;p&gt;Trucks run fast. You may not be alive tomorrow. It would be a shame if your project disappeared with you, wouldn't it? Make sure you're not the only one to understand how your code works. Someone reading all your documentation should be able to maintain and extend your code without your help.&lt;/p&gt;
&lt;h2&gt;Don't spare the unit tests&lt;/h2&gt;
&lt;p&gt;I know that &lt;a href="http://en.wikipedia.org/wiki/Unit_testing"&gt;unit tests&lt;/a&gt; are important. Yet, I'm always lazy when it comes to writing them. I often prefer to test things manually. That's a &lt;em&gt;terrible&lt;/em&gt; idea. Spending hours writing automated unit tests takes in the end far less time than testing everything yourself as soon as you make a change in your code.&lt;/p&gt;
&lt;p&gt;A non-trivial software or library is a complex thing. It contains thousands of lines of code that are all related (well, they shouldn't be &lt;em&gt;too&lt;/em&gt; interdependent if you have a good global code architecture). Fixing a bug somewhere can create a new bug somewhere else in the code more often than you'd thought (butterfly effect). That's the fundamental issue of &lt;a href="http://en.wikipedia.org/wiki/Non-regression_testing"&gt;&lt;em&gt;non-regression&lt;/em&gt;&lt;/a&gt;. As you go along the development of your project, you want things to work &lt;em&gt;better&lt;/em&gt; with time, not &lt;em&gt;worse&lt;/em&gt;. When you fix a bug, you don't want it to reappear months later as you change some seamingly unrelated code.&lt;/p&gt;
&lt;p&gt;The only way to be sure that this doesn't happen is to write automated unit tests. Writing unit tests is a real investment. It takes time initially, time that does not apparently make your software more functional. However, it does make it more reliable. And it can save you hours of debugging in the future.&lt;/p&gt;
&lt;p&gt;Sometimes, the type of your software is not particularly well adapted to automated unit tests. It may rely on external web services, databases, or worse, it can contain a graphical part (or a graphical user interface).&lt;/p&gt;
&lt;p&gt;For my visualization project, I thought for a long time that it was simply not possible to do automated tests. Yet, at some point, the code was becoming simply to large to allow me to test everything manually. So I had to take the time thinking about some way to write unit tests for the rendering engine. I found a solution, not a perfect one, but sufficient to let me know when things that worked before don't work anymore. For every rendering feature, I write a small script that uses it to draw the exact same white square at the center of the screen. Then, the rendered figure is temporarily saved into a PNG file, which is then automatically compared to a reference image. If the two images are different, the test fails.&lt;/p&gt;
&lt;p&gt;It took me maybe one hour or two to make that work, but it proved extremely useful. For the week or two I've been using these tests, I've been able to find several bugs that were introduced by new, apparently unrelated features. I've then been able to fix them immediately.&lt;/p&gt;
&lt;p&gt;You should write unit tests sooner rather than later.&lt;/p&gt;
&lt;h2&gt;Profile and optimize&lt;/h2&gt;
&lt;p&gt;Code readibility is more important than &lt;a href="http://en.wikipedia.org/wiki/Program_optimization"&gt;premature optimization&lt;/a&gt;. Yet, no one uses slow software or libraries. Make sure you &lt;a href="https://cyrille.rossant.net/profiling-and-optimizing-python-code/"&gt;profile and optimize&lt;/a&gt; your code regularly. When you code, think about design and readibility first, but do not overlook performance either, especially if you're in a time critical section (e.g. in a loop). When you code in a &lt;a href="http://en.wikipedia.org/wiki/Garbage_collection_(computer_science)"&gt;garbage-collected&lt;/a&gt; language like Python or .NET, make sure you don't create many temporary objects on the &lt;a href="http://en.wikipedia.org/wiki/Dynamic_memory_allocation"&gt;heap&lt;/a&gt; when you don't absolutely need them. Relatedly, use native structures instead of custom types as much as you can.&lt;/p&gt;
&lt;h2&gt;Don't overlook code quality&lt;/h2&gt;
&lt;p&gt;Make sure you're writing good code. Good not only in the design and architecture, but also just nice looking code. If your programming language has widely used &lt;a href="http://en.wikipedia.org/wiki/Coding_conventions"&gt;guidelines&lt;/a&gt;, read them carefully and use them. For example, Python has &lt;a href="http://www.python.org/dev/peps/pep-0008/"&gt;PEP8&lt;/a&gt;. If there are tools for your language that automatically check the quality of your code, use them. Use spaces, indentation, and comments to structure your code and make it more readable. Code should not be something hidden behind a fancy GUI that comes with your software, it is &lt;em&gt;part&lt;/em&gt; of your software and it's something you should be proud of. If you'd be ashamed to show your code to some other programmer, then you should seriously consider improving it.&lt;/p&gt;
&lt;h2&gt;Do some marketing&lt;/h2&gt;
&lt;p&gt;Do you want other people to use your software? If so, you should go find them, because they won't go find you. Target your audience. Check out mailing lists, groups, blogs where your audience hang around, and do some marketing. Prepare screenshots or videos if your software has any graphical part. Using Twitter is also a good idea. Be humble and open to the criticisms.&lt;/p&gt;
&lt;h2&gt;Get other people involved&lt;/h2&gt;
&lt;p&gt;If you want your software to be widely used and if it is an ambitious project, you'd better find other developers willing to work closely with you. An open-source project is all the more likely to be a long term project than there are people involved in it. Find good collaborators and help them understand all aspects of it. Alternatively, they can work on a specific and independent part (e.g. an external module or plug-in). If you're really serious about your project, you should have a long-term plan and consider its perpetuation after you move on to other projects.&lt;/p&gt;
&lt;h2&gt;Have fun&lt;/h2&gt;
&lt;p&gt;Finally, the whole point of open source development is to have fun (well, maybe not the whole point, but it's an important factor). You should be in love with your language and passionate about programming in general. Do you like sport more than programming? If so, just turn off your computer and do what you like.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Have fun!" src="http://1.bp.blogspot.com/-85-oqQ7DBX4/T4wNBbg8kdI/AAAAAAAAABw/pCpdCT2jfDw/s1600/wisbase-1.jpg" /&gt;&lt;/p&gt;</content><category term="misc"></category></entry><entry><title>Galry's Story, or the quest of multi-million plots</title><link href="https://cyrille.rossant.net/galrys-story-or-the-quest-of-multi-million-plots/" rel="alternate"></link><published>2012-11-30T00:00:00+01:00</published><updated>2012-11-30T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-11-30:/galrys-story-or-the-quest-of-multi-million-plots/</id><summary type="html">&lt;p&gt;About a month ago,
&lt;a href="/introducing-galry/"&gt;I announced here the availability&lt;/a&gt;
of a
&lt;a href="http://rossant.github.com/galry/"&gt;new experimental high performance visualization package in Python&lt;/a&gt;
that I'm developing as part of my current research project.
It has significantly evolved since then, but it is still experimental.
Moreover, the interface is still not ready for a 0 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;About a month ago,
&lt;a href="/introducing-galry/"&gt;I announced here the availability&lt;/a&gt;
of a
&lt;a href="http://rossant.github.com/galry/"&gt;new experimental high performance visualization package in Python&lt;/a&gt;
that I'm developing as part of my current research project.
It has significantly evolved since then, but it is still experimental.
Moreover, the interface is still not ready for a 0.1 release. I also need to do
much more tests on various systems and graphics cards. In this post I'll
talk about how the idea of writing a new visualization package came up in the
first place. I'll also describe the new features that are coming to the
library.&lt;/p&gt;


&lt;p&gt;After my announcement,
I was pleased to see that there were a lot of people interested in
this project. There were more than 500 unique visits since then, which is
not that impressive but still much more than what I'd have thought!
That's probably because I wasn't the only one
to note that it was simply &lt;em&gt;not possible&lt;/em&gt; to plot huge datasets in
Python.
&lt;a href="http://matplotlib.org"&gt;Matplotlib&lt;/a&gt;,
probably the most popular plotting library in Python,
crashes before displaying a multi-million dataset (at least that's what I could
experience on my machine), or when it works, the navigation is severly limited
by an extremely low framerate.&lt;/p&gt;
&lt;p&gt;All other plotting libraries I could find had the same issue.
The Matlab plotting library appears to be a bit more efficient than
matplotlib when it comes to multi-millions datasets, and it may be one of the
reasons why many people still prefer to use Matlab rather than Python.&lt;/p&gt;
&lt;p&gt;I think many people are doing just fine with matplotlib because they simply
don't work with very large datasets. But that may be going to change, with
"&lt;em&gt;&lt;a href="http://en.wikipedia.org/wiki/Big_data"&gt;big data&lt;/a&gt;&lt;/em&gt;"
becoming a more and more popular &lt;em&gt;buzz word&lt;/em&gt;.
In bioinformatics, the mass of data becoming available is simply crazy.
There's the whole field of bioimaging of course, but even apparently harmless
time-dependent signals can become quite large.
Imagine, for example, a
neurophysiological recording with an extracellular
&lt;a href="http://en.wikipedia.org/wiki/Multielectrode_array"&gt;multi-electrode array&lt;/a&gt; with
250 channels,
each channel sampling a signal at 16 bits and 20 kHz (this is close to a real
example). That's 10 MB of data &lt;em&gt;per second&lt;/em&gt; (5 million points),
more than 30 GB per hour (18 billion points) !
A modern hard drive can store that, but processing such a big file is simply
not straightforward: it even doesn't fit in system memory (at least on
most today's computers), and even less in graphics memory. Yet, is it too much
to ask to just plot these data?&lt;/p&gt;
&lt;p&gt;The typical way of processing this is to take chunks of data, either in space
or in time. But when it comes to visualization, it's hardly possible to
plot even &lt;em&gt;a single second&lt;/em&gt; across all channels, since that's already 5
million points!&lt;/p&gt;
&lt;p&gt;One could argue that a modern screen does not contain much more than 2 million
pixels, and about 2000 only horizontally. But the whole point of interactive
navigation (zooming and panning) is to be able to plot the whole signal at
first, and zoom-in in real time on regions of interest.&lt;/p&gt;
&lt;p&gt;I could not find any Python library that would allow me to do that. Outside
Python, I am not aware of such a software either. That's precisely why I
decided to try a new approach, which is to use the graphics card for
the whole rendering process in the most efficient possible way. I realized that
the only way I could achieve the highest performance possible on a given
piece of hardware was to
go as low-level as I could with Python. Using a great and light Python wrapper
around
&lt;a href="http://en.wikipedia.org/wiki/OpenGL"&gt;OpenGL&lt;/a&gt;
(not unexpectingly called
&lt;a href="http://pyopengl.sourceforge.net"&gt;PyOpenGL&lt;/a&gt;) seemed like a natural choice.
Initial proof-of-concept experiments with PyOpenGL suggested that it appeared
to be like a viable method.&lt;/p&gt;
&lt;p&gt;That's how Galry was born earlier this year.&lt;/p&gt;
&lt;h2&gt;Here come shaders&lt;/h2&gt;
&lt;p&gt;The library has evolved a lot since then. I had to go through multiple
improvements and refactoring sessions as I was using Galry for my research
project. In addition, I also had to learn OpenGL in parallel. That was not
an excellent idea, since I realized several times that I was doing it wrong.
In particular, I was using at first a totally obsolete way of rendering points,
which
was to use the
&lt;a href="http://en.wikipedia.org/wiki/Shader"&gt;fixed function pipeline&lt;/a&gt;.
When I discovered that
&lt;a href="/shaders-opengl/"&gt;the modern
way of using OpenGL was to use customizable shaders&lt;/a&gt;
, I had to go through
a consequent rewriting of the whole rendering engine. I could have spared
me this rewriting if I was aware of that point beforehand.&lt;/p&gt;
&lt;p&gt;But it was in the end a very good decision, since programmable shaders are just
infinitely more powerful than the fixed function pipeline, and make
a whole new bunch of things possible with the package. Not only was I able
to considerably improve the rendering part in my research project, but I
realized that the same code could be used to do much more than just
plotting. Here are a few examples of what I was able to do with the new
"shader-aware"
interface: GPU-based image filtering, GPU-based particle system, GPU-based
fractal viewer, 3D rendering, dynamic graph rendering (CPU-based for now), etc.
These are all actual working examples in the Galry repository. I suppose this
package could also be used to write small video games!&lt;/p&gt;
&lt;p&gt;The following video shows a demo of the graph example. This example
incorporates many of the rendering techniques currently implemented in Galry:
point sprites (a single texture attached to many points), lines,
buffer references (the nodes and edges are rendered using the exact same
memory buffer on the GPU, which contains the node positions),
indexed rendering (the edges are
rendered using indices targetting the corresponding nodes, always stored in
the same buffer),
real-time buffer updating (the positions are updated on the CPU and
transferred on the GPU at every frame). GPU-based rendering may also be
possible but it's not straightforward, since the shaders need to access
the other shaders' information, and also modify dynamically the
position. I might investigate this some time. Another solution is to use
&lt;a href="http://en.wikipedia.org/wiki/OpenCL"&gt;OpenCL&lt;/a&gt;,
but it requires to have an OpenCL installation (it can work even if
&lt;a href="/pyopencl-on-windows-without-a-gpu/"&gt;an OpenCL-capable GPU is not available, in which case the OpenCL kernels
are executed on the CPU&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;embed src="http://www.youtube.com/v/MLW3i-_yQ-k" /&gt;&lt;/p&gt;
&lt;h2&gt;About OpenGL&lt;/h2&gt;
&lt;p&gt;Another thing I discovered a bit late was that OpenGL is a fragmented library:
there are multiple versions, a lot of different extensions, some being
specific to a hardware vendor, and a lot of deprecated features.
There's also a specific version of OpenGL for mobile platforms (such as the
IPhone and the IPad), called
&lt;a href="http://en.wikipedia.org/wiki/OpenGL_ES"&gt;OpenGL ES&lt;/a&gt;, which is based on OpenGL but which
is still different. In particular, a lot of deprecated features in OpenGL are
simply unavailable in OpenGL ES. Also, the
&lt;a href="http://en.wikipedia.org/wiki/GLSL"&gt;shading language (GLSL)&lt;/a&gt; is not the
same between OpenGL and OpenGL ES. There's a loose correspondence between the
two but the
version numbers do not match at all. And, by the way, the GLSL language version
does not match the corresponding OpenGL version... except for later versions!
Really confusing.&lt;/p&gt;
&lt;p&gt;The OpenGL ES story is important for Galry, because apparently OpenGL ES
is sometimes used in
&lt;a href="http://en.wikipedia.org/wiki/VirtualBox"&gt;VirtualBox&lt;/a&gt;
for hardware-acceleration, and it might also be
useful
in the future for a potential mobile version of Galry. In addition, OpenGL ES
also forms the basis of
&lt;a href="http://en.wikipedia.org/wiki/WebGL"&gt;WebGL&lt;/a&gt;, enabling access to OpenGL in the browser.
I'll talk about that below, but the point is that in order to have
compatibility between multiple versions of OpenGL, I had to redesign again an
important part of the rendering process (by using a small template system for
dynamic shader code generation depending on the GLSL version).&lt;/p&gt;
&lt;p&gt;Also, whereas the shading language is quite nice and easy to use, I find the
host OpenGL API unintuitive and sometimes obscure. The Galry programming
interface is right there to hide those details to the developer.&lt;/p&gt;
&lt;p&gt;In brief, I find certain aspects of OpenGL a bit messy, but the advantages and
the power of the library are definitely worth it.&lt;/p&gt;
&lt;h2&gt;About writing multi-platform software&lt;/h2&gt;
&lt;p&gt;Python is great for multi-platform software. Choosing Python for a new project
means that one has the best chance of having a single code base for all
operating systems out there. In theory, that's the same story for OpenGL,
since it's a widely used open standard. In practice, it's much more difficult
due to the fragmentation of the OpenGL versions and drivers across different
systems and graphics card manufacturers. Writing a multi-platform system means
that all supported systems need to be tested, and that's not particularly easy
to do in practice: there are a large number of combinations of systems
(Windows, different Linux distributions, Mac OSX, either 32 bits
and 64 bits), of graphics card drivers, versions of Python/PyOpenGL/Qt, etc.&lt;/p&gt;
&lt;h2&gt;High-level interface&lt;/h2&gt;
&lt;p&gt;In the current experimental version of Galry, the low-level API is the
only interface I've been working on, since it's really what I need for my
project. However, I do plan to write a basic matplotlib-like high-level
interface in the near future.
At some point, I even considered integrating Galry's code into
a matplotlib GL backend, which is apparently something that several people
&lt;a href="http://code.google.com/p/glumpy/"&gt;have
been trying to do for quite some time&lt;/a&gt;.
However, as far as I understand, this
is very much non-trivial due to the internal architecture of matplotlib. The
backend handles the rendering process and is asked to redraw everything at
each frame during interactive navigation. However, high performance is
achieved in Galry by loading data at initialization time only, and updating
the transformation at every frame so that the GPU can apply it on the data.
The backend does not appear to have access to that transformation, so I can't
see how an efficient GL renderer could be written in the current architecture.
But I'm pretty sure that somebody will manage to make that happen eventually.&lt;/p&gt;
&lt;p&gt;In the meantime, I will probably write a high-level interface from scratch,
without using matplotlib at all. The goal is to replace
&lt;code&gt;import matplotlib.pyplot as plt&lt;/code&gt; by something like &lt;code&gt;import galry.plot as plt&lt;/code&gt;
at the top of a script to use Galry instead of matplotlib. At first, I'll
probably only implement the most common functions such as
&lt;code&gt;plot&lt;/code&gt;, &lt;code&gt;imshow&lt;/code&gt;, etc. That would already be very useful.&lt;/p&gt;
&lt;h2&gt;Galry in the browser&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://fperez.org/"&gt;Fernando Perez&lt;/a&gt;, the author of
&lt;a href="http://ipython.org"&gt;IPython&lt;/a&gt;, suggested to integrate Galry in the
&lt;a href="http://ipython.org/ipython-doc/dev/interactive/htmlnotebook.html"&gt;IPython notebook&lt;/a&gt;.
The notebook is a relatively new feature that allows to
write (I)Python code in &lt;em&gt;cells&lt;/em&gt; within an HTML page, and output the result
below. That's quite similar to what Mathematica or Maple offer. The whole
interactive session
can then be saved as a
&lt;a href="http://en.wikipedia.org/wiki/JSON"&gt;JSON&lt;/a&gt; file. It brings reproducibility and
coherent structure in interactive computing. Headers, text, and even
static images with matplotlib can be integrated in a notebook. Blog posts,
courses, even technical books are being written with this.&lt;/p&gt;
&lt;p&gt;I personally heard about the notebook some time ago, but I'd never tried it
because
I was a bit reluctant to use Python in a &lt;em&gt;browser&lt;/em&gt; instead of a console. After
Fernando's suggestion, I tried to use the notebook and I quickly understood why
so many people
are very enthusiastic about it. It's because it changes the very way we do
exploratory research with numerical experiments. In a classical workflow, one
would use a Python script to write some computational process, and use
the interactive console to execute it, explore the model in the parameter
space, etc. It works, but it can be terrible for reproducibility: there's
no way one can recover the exact set of parameters and code that corresponds
to figure &lt;code&gt;test34_old_newnewbis.png&lt;/code&gt;. Many people are dealing with this
problem, me included. I'm quite ashamed by the file structure of most of
my past research projects' code, and I'll try to use the notebook in the future
to try being more organized than before.&lt;/p&gt;
&lt;p&gt;The idea of integrating Galry in the notebook comes from the
&lt;a href="http://blog.fperez.org/2012/11/back-from-pycon-canada-2012.html"&gt;work that has
been done during a Python conference earlier this month&lt;/a&gt;, with the integration
of a 3D molecular visualization toolkit in the notebook using WebGL. WebGL
is a standard specification derived from OpenGL that aims at bringing OpenGL
rendering to
the browser, through the HTML5 &lt;code&gt;&amp;lt;canvas&amp;gt;&lt;/code&gt; element. It is still an ongoing
project that may still take months or years to complete. Currently, it is only
supported by the latest versions of modern browsers such as Chrome or Firefox
(no IE of course). But it's an exciting technology that has a huge
potential.&lt;/p&gt;
&lt;p&gt;So I thought it would be quite a good idea and I gave it a try: I managed to
implement a proof-of-concept in only one day, by looking at the code that
had been done during the conference.&lt;/p&gt;
&lt;p&gt;&lt;embed src="http://www.youtube.com/v/taN4TobRS-E" /&gt;&lt;/p&gt;
&lt;p&gt;Then, I was able to see what would need to
be done in the code's architecture to make that integration smooth and
flexible. The solution I chose was to separate completely the scene definition
(what to plot exactly, with all parameters, data, colors, shading code, etc.)
with the actual GL rendering code. The scene can be serialized in JSON and
transmitted to a Javascript/WebGL renderer. I had to rewrite a portion of the
Python renderer in Javascript, which turned out to be less painful than what
I thought.&lt;/p&gt;
&lt;p&gt;Finally, the WebGL renderer can in fact be used as a completely standalone
Javascript library, without any reference to Python. This may allow
interesting scenarios, such as the conversion of a plotting script in
Python using a matplotlib-like high-level interface,
into standalone HTML/Javascript code that enables interactive visualization of
that plot in the browser.&lt;/p&gt;
&lt;h2&gt;About performance&lt;/h2&gt;
&lt;p&gt;The major objective of Galry is, by far, performance. I found that PyOpenGL can
be very fast at the important condition of using it correctly. In particular,
data transfer from system memory to graphics memory should be made only when
necessary. Also,
the number of calls to OpenGL commands should be minimal in the rendering
phase.&lt;/p&gt;
&lt;p&gt;The first point means that data should be uploaded on the GPU at initialization
time, and should stay on the GPU as long as possible. When zooming in, the GPU
should handle the whole transformation on the same memory buffer. This ensures
that the GPU is used optimally. In Matplotlib, as far as I know, everything
is rendered again at each frame, which explains why the performance is not
very good. And the CPU does the rendering in this case, not the GPU.&lt;/p&gt;
&lt;p&gt;The second point is also crucial. When plotting a large number of individual
points, or a single curve, it is possible to call a single OpenGL rendering
command, so that the Python overhead is negligible compared to the actual
GPU rendering phase. But when it comes to a plot containing a large number of
individual curves, using a Python loop is highly inefficient, especially when
every call renders a small curve. The best solution I could find is to use
&lt;a href="http://www.opengl.org/sdk/docs/man/xhtml/glMultiDrawArrays.xml"&gt;&lt;em&gt;glMultiDrawArrays&lt;/em&gt;&lt;/a&gt;
or
&lt;a href="http://www.opengl.org/sdk/docs/man/xhtml/glMultiDrawElements.xml"&gt;&lt;em&gt;glMultiDrawElements&lt;/em&gt;&lt;/a&gt;,
which render several primitives
with a single memory buffer and a single command. Even if this function is
implemented internally as a loop by the driver, it will still be much faster
than a Python loop, since there isn't the cost of interpretation.&lt;/p&gt;
&lt;p&gt;With this technique, I am able to plot 100 curves with 1 million points each
at ~15 FPS with a recent graphics card. That's 1.5 &lt;em&gt;billion&lt;/em&gt; points per second!
Such performance is directly related to the incredible power of modern GPUs,
which is literally mind blowing.&lt;/p&gt;
&lt;p&gt;Yet, I think there's still some room for improvement by using dynamic
undersampling techniques. But that is for the future...&lt;/p&gt;</content><category term="misc"></category><category term="dataviz"></category></entry><entry><title>The Power of Shaders in Real-Time Graphics Programming</title><link href="https://cyrille.rossant.net/shaders-opengl/" rel="alternate"></link><published>2012-11-05T00:00:00+01:00</published><updated>2012-11-05T00:00:00+01:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-11-05:/shaders-opengl/</id><summary type="html">&lt;p&gt;I've been programming in
&lt;a href="http://en.wikipedia.org/wiki/OpenGL"&gt;OpenGL&lt;/a&gt;
for a few months. Like a lot of programmers,
I learnt the language by myself, thanks to various tutorials, books or e-books
on the subject. One couldn't say there's a lack of resources on this
20-years old language since it's so widely used throughout the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been programming in
&lt;a href="http://en.wikipedia.org/wiki/OpenGL"&gt;OpenGL&lt;/a&gt;
for a few months. Like a lot of programmers,
I learnt the language by myself, thanks to various tutorials, books or e-books
on the subject. One couldn't say there's a lack of resources on this
20-years old language since it's so widely used throughout the world. Yet,
I was surprised to discover a few weeks ago that the &lt;strong&gt;vast majority of what
I learnt has been obsolete for almost a decade&lt;/strong&gt;. The reason is that too many
textbooks and tutorials on the Internet about OpenGL refer to a deprecated
way of programming and which relates to the &lt;strong&gt;fixed-function pipeline&lt;/strong&gt;.
The modern way of programming in OpenGL is to use the &lt;strong&gt;programmable pipeline
through shaders&lt;/strong&gt;. The
&lt;a href="http://www.arcsynthesis.org/gltut/"&gt;free e-book&lt;/a&gt; by
Jason McKesson is a very good
resource for learning modern OpenGL programming using the programmable
pipeline.&lt;/p&gt;


&lt;h2&gt;The graphics pipeline&lt;/h2&gt;
&lt;p&gt;I'll try to explain what this is all about in simple terms, assuming no
prior knowledge in graphics programming. Since graphics cards exist, the way
rendering is done in a computer can be seen as a
&lt;a href="http://en.wikipedia.org/wiki/Graphics_pipeline"&gt;pipeline&lt;/a&gt;.
At the top, there's
data that enters in the graphics card memory. At the bottom, there's the pixels
on the screen. The role of the graphics card is, and has always been, to
transform the data into pixels. The reason why this is complicated is that
most of the time, the graphics card needs to render 3D data on a 2D screen.
Indeed, graphics cards have been created primarily to allow real-time
rendering in 3D video games. So, first, the 3D data describing the game
world and characters enter into the graphics card memory.
Then, the graphics card transforms the data into a 2D scene that corresponds
to the projection of the world onto a virtual camera. In a first-person game,
like an FPS for instance, this camera corresponds to the eye of the main
character.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/3D_projection"&gt;Projecting a 3D world to a 2D camera&lt;/a&gt;
is not mathematically complicated,
and only involves basic linear algebra. However, it can be expensive in terms
of computing power, since the number of mathematical operations to perform
at every frame increases with the scene complexity. More details in the game
implies a higher number of points, therefore a higher number of operations.
Those operations constitute a highly parallel problem, since in general, the
same mathematical operation is performed on all points (for instance,
when the camera moves, the same linear transformation is applied on all
points). The power of graphics cards comes precisely from their highly parallel
architecture which lets them compute this kind of linear transformation
in a very efficient way.&lt;/p&gt;
&lt;p&gt;So, coming back to the rendering pipeline, the transformation of the data
involves &lt;strong&gt;linear transformations&lt;/strong&gt; to get the 2D positions of the points on the
camera, then
&lt;a href="http://en.wikipedia.org/wiki/Rasterization"&gt;&lt;strong&gt;rasterization&lt;/strong&gt;&lt;/a&gt;
to transform primitives (made up by vertices) into
colored pixels. In addition, an important aspect of 3D rendering has to do with
&lt;strong&gt;lighting&lt;/strong&gt;,
which plays an essential role in the realistic aspect of the scene. Real-time
realistic lighting is a complicated subject. There's also the issue of
textures, reflections, etc.
So over the years, graphics cards
programming has become increasingly complicated in order to account for more
and more complex and realistic rendering algorithms.&lt;/p&gt;
&lt;h2&gt;The advent of programmable shaders&lt;/h2&gt;
&lt;p&gt;Then, an alternative approach has been to bring flexibility in this pipeline
process, by giving the programmer the possibility to customize this
rendering pipeline. Instead of having fixed, hard-coded rendering algorithms,
the programmer had the possibility to write small programs in a low-level
language called a
&lt;a href="http://en.wikipedia.org/wiki/Shader"&gt;&lt;strong&gt;shading language&lt;/strong&gt;&lt;/a&gt;.
A shader program is executed
independently and in parallel over all vertices or pixels, and transforms
them in order to implement custom rendering algorithms. This new technique
has allowed for real-time special effects that would not have been possible
before.&lt;/p&gt;
&lt;p&gt;Several types of shaders exist, the most common ones are the vertex shader and
the fragment shader. The &lt;strong&gt;vertex shader is executed once per vertex&lt;/strong&gt; and can
transform its position. Applications include any special effect that requires
independent transformation of vertices that would not be possible globally
(e.g. cloth simulation, hair movements, morphing, particle system rendering,
special lighting effects, etc.).&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;fragment shader is executed once per pixel&lt;/strong&gt; and can transform its
final color. Applications include everything related to textures, lighting,
reflections, etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shaders are extremely powerful, for they give the programmer
full control of the graphics card to make them do what they do best:
real-time rendering&lt;/strong&gt;. The deep reason why they are so powerful is that shaders
execute on the GPU in a fully parallel way, so they exploit the
&lt;a href="http://en.wikipedia.org/wiki/Graphics_processing_unit"&gt;parallel architecture of graphics card&lt;/a&gt;
in the most efficient possible way. The hundreds
or thousands of cores all execute simultaneously the same little programs
that transform the megabytes or gigabytes of data stored in GPU memory into
millions of pixels on the screen. And the precise algorithms are up to the
programmer rather than the graphics card manufacturer.&lt;/p&gt;
&lt;p&gt;In the early times of programmable pipeline rendering, shaders were written
in an assembly language, making them highly difficult to write, design, read,
and debug. Then, more readable languages have been designed, such as
&lt;a href="http://en.wikipedia.org/wiki/GLSL"&gt;GLSL&lt;/a&gt; (OpenGL),
&lt;a href="http://en.wikipedia.org/wiki/HLSL"&gt;HLSL&lt;/a&gt; (DirectX),
or
&lt;a href="http://en.wikipedia.org/wiki/Cg_(programming_language)"&gt;Cg&lt;/a&gt; (Nvidia).
These languages look very much like C, even if they target
very different architectures than those of typical central processing units.
The simple and widespread syntax has made shader programming a potential
reality for most graphics programmers.&lt;/p&gt;
&lt;p&gt;Today, shaders are widely used in virtually all 3D video games. Yet, very few
OpenGL resources address them. Instead, tutorials and lessons explain how
to use the fixed-function pipeline to perform transform and lighting on the
GPU, without precising that this way of doing has been obsolete for nearly 10
years! Now, even old graphics cards fully support programmable shaders,
so I can't see good reasons not to use them. They are just so powerful,
easy to program and they allow for a thorough understanding of how modern
graphics cards work, and how to use their extreme computational power to their
full extent.&lt;/p&gt;
&lt;h2&gt;Concrete example of shaders in OpenGL&lt;/h2&gt;
&lt;p&gt;I will now give an example of using shaders in PyOpenGL, by
extending
&lt;a href="/2d-graphics-rendering-tutorial-with-pyopengl/"&gt;my previous tutorial on PyOpenGL&lt;/a&gt;.
In OpenGL, shaders are
written in
&lt;a href="http://en.wikipedia.org/wiki/GLSL"&gt;GLSL&lt;/a&gt;.
Several versions of GLSL exist, and the version supported
by the GPU depends on the version of OpenGL implemented in the graphics
card drivers. I will assume that OpenGL 3.30 is supported.&lt;/p&gt;
&lt;p&gt;First, when using shaders, it may be a good idea to get rid of all code related
to the fixed-function pipeline. It is now completely deprecated, yet almost
all tutorials do not mention that. For example, here is a non-exhaustive list
of deprecated OpenGL functions:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;glColorPointer, glVertexPointer, glEnableClientState, glLoadIdentity,
glLoadMatrix, glMultMatrix, glOrtho*, glPopMatrix, glRotate*, glScale*,
glTranslate*, glMaterial*, glLight*...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The details can be found in
&lt;a href="http://www.opengl.org/registry/"&gt;the official specifications&lt;/a&gt;.
It means that all functions related to transformations, lighting, texturing,
etc. are deprecated and should rather be implemented in vertex and fragment
shaders. Concerning matrix transformations, it means that matrices
need to be passed to the vertex shader through
&lt;a href="http://www.opengl.org/wiki/Uniform_(GLSL)"&gt;uniform variables&lt;/a&gt;, and then
be explicitely multiplied to the position vector (which are attribute
variables). Similarly for lighting and texturing.&lt;/p&gt;
&lt;h3&gt;Example description&lt;/h3&gt;
&lt;p&gt;In this simple example, a null sampled function (&lt;span class="math"&gt;\(x \in [-1, 1], y = 0\)&lt;/span&gt;) is
loaded on the GPU as an attribute variable named &lt;code&gt;position&lt;/code&gt;. An
&lt;a href="http://www.opengl.org/wiki/Type_Qualifier_(GLSL)"&gt;attribute variable&lt;/a&gt;
is an array of scalars or vectors (of dimension 2, 3 or 4) that
is loaded on the GPU as a
&lt;a href="http://www.opengl.org/wiki/Vertex_Buffer_Object#Vertex_Buffer_Object"&gt;vertex buffer object&lt;/a&gt;.
It has a name, a type
and a location. The location is an integer that should be unique within
a shader program. Here, &lt;code&gt;position&lt;/code&gt; is an attribute of type vec2 and location 0.
It contains the coordinates of the vertices. There are &lt;span class="math"&gt;\(N\)&lt;/span&gt; vertices, so
&lt;span class="math"&gt;\(N\)&lt;/span&gt; vectors with vertex coordinates, and &lt;span class="math"&gt;\(N\)&lt;/span&gt; executions of the vertex shader.
Each thread takes one vec2 position as an input, and returns the final
position in the special variable &lt;code&gt;gl_Position&lt;/code&gt;. If linear transformations
need to be applied, one needs to multiply matrices with &lt;code&gt;position&lt;/code&gt; and assign
the result to &lt;code&gt;gl_Position&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Vertex shader&lt;/h3&gt;
&lt;p&gt;Here is the source code of the vertex shader in this example.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Vertex shader.&lt;/span&gt;
&lt;span class="n"&gt;VS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;#version 330&lt;/span&gt;
&lt;span class="s2"&gt;// Attribute variable that contains coordinates of the vertices.&lt;/span&gt;
&lt;span class="s2"&gt;layout(location = 0) in vec2 position;&lt;/span&gt;

&lt;span class="s2"&gt;// Main function, which needs to set `gl_Position`.&lt;/span&gt;
&lt;span class="s2"&gt;void main()&lt;/span&gt;
&lt;span class="s2"&gt;{&lt;/span&gt;
&lt;span class="s2"&gt;    // The final position is transformed from a null signal to a sinewave here.&lt;/span&gt;
&lt;span class="s2"&gt;    // We pass the position to gl_Position, by converting it into&lt;/span&gt;
&lt;span class="s2"&gt;    // a 4D vector. The last coordinate should be 0 when rendering 2D figures.&lt;/span&gt;
&lt;span class="s2"&gt;    gl_Position = vec4(position.x, .2 * sin(20 * position.x), 0., 1.);&lt;/span&gt;
&lt;span class="s2"&gt;}&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The code should be self-explanatory. The x coordinate of the position is
used to calculate the y coordinate (through a sinus function). We don't use
the y coordinate at all, so we could also have used an array of floats for
the position. The special variable
&lt;a href="http://www.opengl.org/sdk/docs/manglsl/xhtml/gl_Position.xml"&gt;&lt;code&gt;gl_Position&lt;/code&gt;&lt;/a&gt;
has four components,
the third is the third dimension (not used here since we render a 2D scene),
the latest is the fourth, homogeneous coordinate, that is not relevant in
2D rendering and should be fixed to 1.&lt;/p&gt;
&lt;h3&gt;Fragment shader&lt;/h3&gt;
&lt;p&gt;The fragment shader is executed once per primitive pixel. It takes possible
vertex shader outputs as inputs (none here) and returns the pixel color
as an output. The output color needs to be explicitely declared.
Usage of the special &lt;code&gt;gl_FragColor&lt;/code&gt; keyword is now deprecated, such as
a lot of other &lt;code&gt;gl_*&lt;/code&gt; variables in GLSL.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Fragment shader&lt;/span&gt;
&lt;span class="n"&gt;FS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;#version 330&lt;/span&gt;
&lt;span class="s2"&gt;// Output variable of the fragment shader, which is a 4D vector containing the&lt;/span&gt;
&lt;span class="s2"&gt;// RGBA components of the pixel color.&lt;/span&gt;
&lt;span class="s2"&gt;out vec4 out_color;&lt;/span&gt;

&lt;span class="s2"&gt;// Main fragment shader function.&lt;/span&gt;
&lt;span class="s2"&gt;void main()&lt;/span&gt;
&lt;span class="s2"&gt;{&lt;/span&gt;
&lt;span class="s2"&gt;    // We simply set the pixel color to yellow.&lt;/span&gt;
&lt;span class="s2"&gt;    out_color = vec4(1., 1., 0., 1.);&lt;/span&gt;
&lt;span class="s2"&gt;}&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Once again, the code should be clear enough. The &lt;code&gt;out_color&lt;/code&gt; variable contains
the red, green, blue and alpha components of the pixel final color. The
components are between 0 and 1. The alpha component is the transparency:
0 for completely transparent, 1 for completely opaque.&lt;/p&gt;
&lt;h3&gt;Compiling a shader&lt;/h3&gt;
&lt;p&gt;Once shader codes have been defined, shaders need to be compiled.
Here is a small Python function for compiling a vertex shader.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;OpenGL.GL&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;gl&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;compile_vertex_shader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Compile a vertex shader from source.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;vertex_shader&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glCreateShader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_VERTEX_SHADER&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glShaderSource&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glCompileShader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# check compilation error&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glGetShaderiv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_COMPILE_STATUS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;RuntimeError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glGetShaderInfoLog&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;vertex_shader&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Compilation involves the creation of a shader, the load of the source code,
and finally the compilation. Then, we check that no error happened during
the compilation, or we print the compilation error. This last step
is critical when debugging a PyOpenGL program using shaders, because otherwise
there is no way to know why the compilation failed.&lt;/p&gt;
&lt;p&gt;The function for compiling a fragment shader is pretty much the same (see the
full script at the end for the details).&lt;/p&gt;
&lt;h3&gt;Attaching shaders to a program&lt;/h3&gt;
&lt;p&gt;Once the vertex and fragment shaders have been compiled, they need to be
attached to a program, the latter being then linked.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;link_shader_program&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fragment_shader&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Create a shader program with from compiled shaders.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;program&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glCreateProgram&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glAttachShader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glAttachShader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fragment_shader&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glLinkProgram&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# check linking error&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glGetProgramiv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_LINK_STATUS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;RuntimeError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glGetProgramInfoLog&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;program&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We first create a program, then we attach the compiled shaders, and finally
we link the program. We also check that the linking was successful.&lt;/p&gt;
&lt;h3&gt;Using shaders&lt;/h3&gt;
&lt;p&gt;Finally, here is how to use shaders during the rendering process.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;paintGL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# vertices located in the buffer in position 0 contain 2 single&lt;/span&gt;
    &lt;span class="c1"&gt;# precision floating points as coordinates&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glEnableVertexAttribArray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glVertexAttribPointer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_FLOAT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_FALSE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# we use the compiled program&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glUseProgram&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# draw &amp;quot;count&amp;quot; points from the VBO&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glDrawArrays&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_LINE_STRIP&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We activate the buffers that need to pass data to the vertex shader,
then we use the program before calling the OpenGL rendering commands.&lt;/p&gt;
&lt;h3&gt;Full script&lt;/h3&gt;
&lt;p&gt;Finally, here is the full Python script that displays a sinewave function
using shaders. PyQt4 or PySide and PyOpenGL are necessary. If you use PySide,
you should simply replace &lt;code&gt;PyQt4&lt;/code&gt; by &lt;code&gt;PySide&lt;/code&gt; in the imports. The
&lt;code&gt;create_window&lt;/code&gt; function has already been explained
&lt;a href="/making-pyqt4-pyside-and-ipython-work-together/"&gt;in a previous post&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# PyQt4 imports&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PyQt4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;QtCore&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;QtOpenGL&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PyQt4.QtOpenGL&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;QGLWidget&lt;/span&gt;
&lt;span class="c1"&gt;# PyOpenGL imports&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;OpenGL.GL&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;gl&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;OpenGL.arrays.vbo&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;glvbo&lt;/span&gt;

&lt;span class="c1"&gt;# Window creation function.&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_window&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;window_class&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Create a Qt window in Python, or interactively in IPython with Qt GUI&lt;/span&gt;
&lt;span class="sd"&gt;    event loop integration:&lt;/span&gt;
&lt;span class="sd"&gt;        # in ~/.ipython/ipython_config.py&lt;/span&gt;
&lt;span class="sd"&gt;        c.TerminalIPythonApp.gui = &amp;#39;qt&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;        c.TerminalIPythonApp.pylab = &amp;#39;qt&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    See also:&lt;/span&gt;
&lt;span class="sd"&gt;        http://ipython.org/ipython-doc/dev/interactive/qtconsole.html#qt-and-the-qtconsole&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;app_created&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;QtCore&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QCoreApplication&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instance&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QApplication&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;app_created&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;references&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;window_class&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;references&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;app_created&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exec_&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;window&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;compile_vertex_shader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Compile a vertex shader from source.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;vertex_shader&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glCreateShader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_VERTEX_SHADER&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glShaderSource&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glCompileShader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# check compilation error&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glGetShaderiv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_COMPILE_STATUS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;RuntimeError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glGetShaderInfoLog&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;vertex_shader&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;compile_fragment_shader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Compile a fragment shader from source.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;fragment_shader&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glCreateShader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_FRAGMENT_SHADER&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glShaderSource&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fragment_shader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glCompileShader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fragment_shader&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# check compilation error&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glGetShaderiv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fragment_shader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_COMPILE_STATUS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;RuntimeError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glGetShaderInfoLog&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fragment_shader&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;fragment_shader&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;link_shader_program&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fragment_shader&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Create a shader program with from compiled shaders.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;program&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glCreateProgram&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glAttachShader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vertex_shader&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glAttachShader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fragment_shader&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glLinkProgram&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# check linking error&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glGetProgramiv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_LINK_STATUS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;RuntimeError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glGetProgramInfoLog&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;program&lt;/span&gt;

&lt;span class="c1"&gt;# Vertex shader&lt;/span&gt;
&lt;span class="n"&gt;VS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;#version 330&lt;/span&gt;
&lt;span class="s2"&gt;// Attribute variable that contains coordinates of the vertices.&lt;/span&gt;
&lt;span class="s2"&gt;layout(location = 0) in vec2 position;&lt;/span&gt;

&lt;span class="s2"&gt;// Main function, which needs to set `gl_Position`.&lt;/span&gt;
&lt;span class="s2"&gt;void main()&lt;/span&gt;
&lt;span class="s2"&gt;{&lt;/span&gt;
&lt;span class="s2"&gt;    // The final position is transformed from a null signal to a sinewave here.&lt;/span&gt;
&lt;span class="s2"&gt;    // We pass the position to gl_Position, by converting it into&lt;/span&gt;
&lt;span class="s2"&gt;    // a 4D vector. The last coordinate should be 0 when rendering 2D figures.&lt;/span&gt;
&lt;span class="s2"&gt;    gl_Position = vec4(position.x, .2 * sin(20 * position.x), 0., 1.);&lt;/span&gt;
&lt;span class="s2"&gt;}&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# Fragment shader&lt;/span&gt;
&lt;span class="n"&gt;FS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;#version 330&lt;/span&gt;
&lt;span class="s2"&gt;// Output variable of the fragment shader, which is a 4D vector containing the&lt;/span&gt;
&lt;span class="s2"&gt;// RGBA components of the pixel color.&lt;/span&gt;
&lt;span class="s2"&gt;out vec4 out_color;&lt;/span&gt;

&lt;span class="s2"&gt;// Main fragment shader function.&lt;/span&gt;
&lt;span class="s2"&gt;void main()&lt;/span&gt;
&lt;span class="s2"&gt;{&lt;/span&gt;
&lt;span class="s2"&gt;    // We simply set the pixel color to yellow.&lt;/span&gt;
&lt;span class="s2"&gt;    out_color = vec4(1., 1., 0., 1.);&lt;/span&gt;
&lt;span class="s2"&gt;}&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GLPlotWidget&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;QGLWidget&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# default window size&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;600&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;600&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initializeGL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Initialize OpenGL, VBOs, upload data on the GPU, etc.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# background color&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glClearColor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# create a Vertex Buffer Object with the specified data&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vbo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;glvbo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;VBO&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# compile the vertex shader&lt;/span&gt;
        &lt;span class="n"&gt;vs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;compile_vertex_shader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;VS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# compile the fragment shader&lt;/span&gt;
        &lt;span class="n"&gt;fs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;compile_fragment_shader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;FS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# compile the vertex shader&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shaders_program&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;link_shader_program&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;paintGL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Paint the scene.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# clear the buffer&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glClear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_COLOR_BUFFER_BIT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# bind the VBO&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vbo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;# tell OpenGL that the VBO contains an array of vertices&lt;/span&gt;
        &lt;span class="c1"&gt;# prepare the shader&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glEnableVertexAttribArray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# these vertices contain 2 single precision coordinates&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glVertexAttribPointer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_FLOAT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_FALSE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glUseProgram&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shaders_program&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# draw &amp;quot;count&amp;quot; points from the VBO&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glDrawArrays&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_LINE_STRIP&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;resizeGL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Called upon window resizing: reinitialize the viewport.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# update the window size&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;
        &lt;span class="c1"&gt;# paint within the whole window&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glViewport&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# import numpy for generating random data points&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

    &lt;span class="c1"&gt;# null signal&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="c1"&gt;# define a Qt window with an OpenGL widget inside it&lt;/span&gt;
    &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QMainWindow&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="c1"&gt;# initialize the GL widget&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GLPlotWidget&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
            &lt;span class="c1"&gt;# put the window at the screen position (100, 100)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setGeometry&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setCentralWidget&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# show the window&lt;/span&gt;
    &lt;span class="n"&gt;win&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_window&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;There is of course much more to say about shaders that what this deceptively
simple example has shown: how to implement linear transformations,
lighting, textures, etc.
&lt;a href="http://www.arcsynthesis.org/gltut/"&gt;This free ebook&lt;/a&gt; is an excellent
resource for modern OpenGL programming, since it directly addresses the
programmable pipeline instead of the deprecated fixed-function pipeline.
The latter remains supported only for the sake of backwards compatibility,
and should not be used at all.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="misc"></category><category term="gpu"></category><category term="dataviz"></category></entry><entry><title>Introducing Galry, a high-performance interactive 2D visualization Python package</title><link href="https://cyrille.rossant.net/introducing-galry/" rel="alternate"></link><published>2012-10-24T00:00:00+02:00</published><updated>2012-10-24T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-10-24:/introducing-galry/</id><summary type="html">&lt;p&gt;I'm releasing today the code of a first experimental version of 
&lt;a href="http://rossant.github.com/galry/"&gt;&lt;strong&gt;Galry, a high-performance interactive 2D visualization Python package&lt;/strong&gt;&lt;/a&gt;
that I'm creating as part of my current research project.&lt;/p&gt;


&lt;p&gt;The rationale of this package is to provide a highly flexible and optimized
way of visualizing large 2D datasets in Python …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm releasing today the code of a first experimental version of 
&lt;a href="http://rossant.github.com/galry/"&gt;&lt;strong&gt;Galry, a high-performance interactive 2D visualization Python package&lt;/strong&gt;&lt;/a&gt;
that I'm creating as part of my current research project.&lt;/p&gt;


&lt;p&gt;The rationale of this package is to provide a highly flexible and optimized
way of visualizing large 2D datasets in Python by using the full power of the
graphics card.
Most visualization packages in Python are either meant to generate high-quality
publication-ready figures (like 
&lt;a href="http://matplotlib.org/"&gt;matplotlib&lt;/a&gt;), 
or to offer 3D fast interactive 
visualization (like 
&lt;a href="http://code.enthought.com/projects/mayavi/"&gt;mayavi&lt;/a&gt;).
Existing 2D plotting packages do not generally offer an efficient way to 
interactively visualize large datasets (1, 10, even 100 million points). 
That's what Galry is aiming for, by 
using directly 
&lt;a href="http://en.wikipedia.org/wiki/OpenGL"&gt;OpenGL&lt;/a&gt; through a thin Python wrapper 
called 
&lt;a href="http://pyopengl.sourceforge.net/"&gt;PyOpenGL&lt;/a&gt;.
Galry should work on most platforms (Windows/MacOS/Linux).&lt;/p&gt;
&lt;p&gt;To give an idea of the performance of Galry on a recent hardware,
on a 2012 desktop computer with an high-end AMD graphics card, I can
navigate smoothly into a plot with &lt;strong&gt;50 million points&lt;/strong&gt; (~35 FPS in the 
current version), and almost smoothly with &lt;strong&gt;100 million points&lt;/strong&gt; (~15 FPS).&lt;/p&gt;
&lt;p&gt;Galry integrates smoothly with 
&lt;a href="http://ipython.org/"&gt;IPython&lt;/a&gt;
and 
&lt;a href="http://en.wikipedia.org/wiki/Qt_(framework)"&gt;Qt&lt;/a&gt;, 
through either 
&lt;a href="http://www.riverbankcomputing.co.uk/software/pyqt/intro"&gt;PyQt&lt;/a&gt; or 
&lt;a href="http://qt-project.org/wiki/PySide"&gt;PySide&lt;/a&gt;. &lt;/p&gt;
&lt;h2&gt;Demo&lt;/h2&gt;
&lt;p&gt;&lt;embed src="http://www.youtube.com/v/jYNJJ4O3pXo" /&gt;&lt;/p&gt;
&lt;h2&gt;Getting started&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/rossant/galry"&gt;The code is available on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Important note: Galry is still an experimental project with an unstable
programming interface that is likely to change at any time. Do not use it in
production yet.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Installation of Galry may not be straightforward depending on your specific
configuration. In particular, you need a recent enough version of OpenGL
(tested version: 3.3). Please don't hesitate to contact me if you have any
trouble installing or using the library.&lt;/p&gt;</content><category term="misc"></category><category term="python"></category><category term="dataviz"></category><category term="gpu"></category></entry><entry><title>Profiling and optimizing Python code</title><link href="https://cyrille.rossant.net/profiling-and-optimizing-python-code/" rel="alternate"></link><published>2012-10-10T00:00:00+02:00</published><updated>2012-10-10T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-10-10:/profiling-and-optimizing-python-code/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;Premature optimization is the root of all evil.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Donald_Knuth"&gt;&lt;em&gt;Donald Knuth&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There are two opposite directions a programmer can take when writing a piece
of software: coming up with an elegant software design or with an heavily 
optimized code. A good design leads to better readability and maintenance, 
often at the …&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;Premature optimization is the root of all evil.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Donald_Knuth"&gt;&lt;em&gt;Donald Knuth&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There are two opposite directions a programmer can take when writing a piece
of software: coming up with an elegant software design or with an heavily 
optimized code. A good design leads to better readability and maintenance, 
often at the expense of pure performance. Conversely, highly optimized code
tends to be more difficult to read, and can lead to bugs that are hard to
fix.&lt;/p&gt;


&lt;p&gt;It appears that of those two possible directions, &lt;a href="http://en.wikipedia.org/wiki/Program_optimization#When_to_optimize"&gt;design and code 
readability are more important &lt;em&gt;at first&lt;/em&gt; than premature
optimization&lt;/a&gt;. 
It might seem counterintuitive: why bother trying to write good code if the
code architecture needs to be changed later anyway due to bad performance?&lt;/p&gt;
&lt;p&gt;First, one needs to begin somewhere. After all, it is the normal life for
any software to be progressively improved over time. And it is much easier to
improve a well written code than a messy one filled up with hideous optimizing
tricks. Second, the performance may not be that bad. The only way to know is to
try with a first, well-written version. It may even not be necessary to 
optimize anything, if the performance is just &lt;em&gt;good enough&lt;/em&gt;.
Finally, and most importantly, knowing in advance which part of the code will 
require optimization is very often unpredictable.
That's something I surprisingly discovered only recently despite many years
of programming.&lt;/p&gt;
&lt;p&gt;Whenever your code is too slow, you can, at least at first, make some guesses.
Maybe that function, maybe this code snippet, is the
&lt;a href="http://en.wikipedia.org/wiki/Bottleneck_(engineering)#Engineering"&gt;bottleneck&lt;/a&gt;. 
This
algorithm may have a too large complexity, the hard drive may be too slow when
writing this file, allocating this amount of memory, binding this socket may 
take too much time, spawning this process may be the bottleneck, etc. In my
experience, whatever you best guess is, &lt;em&gt;you can be pretty confident that 
you'll be wrong&lt;/em&gt;. The vast majority of time, the actual bottleneck will be
completely unexpected, sometimes incredibly stupid, sometimes very subtle.&lt;/p&gt;
&lt;p&gt;The only way to know for sure is to 
&lt;a href="http://en.wikipedia.org/wiki/Profiling_(computer_programming)"&gt;&lt;em&gt;profile&lt;/em&gt;&lt;/a&gt;. 
With the right tools, profiling
code can be highly valuable. Whenever your code is becoming too slow, profile
and find the bottleneck, the small part of the code that is taking too long.
Very often, &lt;a href="http://en.wikipedia.org/wiki/Program_optimization#Bottlenecks"&gt;it is a small portion of the code that is responsible for 
most of the slow-down (Pareto 
principle)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I've never taken the time to play with the profiling tools in Python until
recently, and I want to share here what I've been using lately.&lt;/p&gt;
&lt;h2&gt;Profiling Python code&lt;/h2&gt;
&lt;p&gt;The &lt;a href="http://docs.python.org/library/"&gt;Python standard library&lt;/a&gt; contains the 
&lt;a href="http://docs.python.org/library/profile.html"&gt;&lt;code&gt;cProfile&lt;/code&gt;&lt;/a&gt; module for determining
the time that takes every Python function when running the code. The
&lt;code&gt;pstats&lt;/code&gt; module allows to read the profiling results. Third party profiling
libraries include in particular 
&lt;a href="http://packages.python.org/line_profiler/"&gt;&lt;code&gt;line_profiler&lt;/code&gt;&lt;/a&gt; 
for profiling code line after 
line, and 
&lt;a href="http://pypi.python.org/pypi/memory_profiler"&gt;&lt;code&gt;memory_profiler&lt;/code&gt;&lt;/a&gt; 
for profiling memory usage. All these tools are
very powerful and extremely useful when optimizing some code, but they might not
be very easy to use at first.&lt;/p&gt;
&lt;p&gt;So, how to profile Python code? First, prepare a Python script which executes
the code you want to profile. Ideally, this code should be deterministic
(e.g., use a fixed seed if you use a pseudorandom number generator, etc.).&lt;/p&gt;
&lt;p&gt;Then, use &lt;code&gt;cProfile&lt;/code&gt; to execute and profile this script. The &lt;code&gt;cProfile&lt;/code&gt; module
generates a binary file with all the information related to the profiling
session.
In order to convert this file into an human-readable format, one has to use the
&lt;code&gt;pstats&lt;/code&gt; module. I found the following solution convenient: I create a .bat file
with the following lines (this is for Windows):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;python -m cProfile -o prof script.py
python dumpprof.py &amp;gt; stats.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The first line profiles 'script.py' and saves the result in a 'prof' file.
The second line converts the 'prof' binary file into a text file.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;dumpprof.py&lt;/code&gt; file contains the following code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pstats&lt;/span&gt;
&lt;span class="n"&gt;pstats&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Stats&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;prof&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip_dirs&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort_stats&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;cumulative&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_stats&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You can take a look to the Python documentation to find all the options
in the
&lt;a href="http://docs.python.org/library/profile.html#pstats.Stats"&gt;&lt;code&gt;pstats&lt;/code&gt; module&lt;/a&gt;. 
When I launch the .bat file, the script is executed,
and I get a text file with the profiling result, that is, with the time 
each function took.&lt;/p&gt;
&lt;p&gt;Here is a toy example with the following script:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy.random&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;rdn&lt;/span&gt;

&lt;span class="c1"&gt;# uncomment for line_profiler&lt;/span&gt;
&lt;span class="c1"&gt;# @profile&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rdn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;An excerpt of the output of &lt;code&gt;cProfile&lt;/code&gt; on my laptop is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;10895 function calls (10706 primitive calls) in 0.472 CPU seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    1    0.000    0.000    0.474    0.474 {execfile}
    1    0.025    0.025    0.474    0.474 script.py:1(&amp;lt;module&amp;gt;)
    1    0.009    0.009    0.240    0.240 __init__.py:106(&amp;lt;module&amp;gt;)
    1    0.074    0.074    0.209    0.209 script.py:5(test)
    [...]
    1    0.000    0.000    0.126    0.126 fromnumeric.py:300(repeat)
    1    0.126    0.126    0.126    0.126 {method &amp;#39;repeat&amp;#39; of &amp;#39;numpy.ndarray&amp;#39; objects}
    [...]
    1    0.009    0.009    0.009    0.009 {method &amp;#39;randn&amp;#39; of &amp;#39;mtrand.RandomState&amp;#39; objects}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;test&lt;/code&gt; function took 209 ms, among which 126 were spent in the &lt;code&gt;repeat&lt;/code&gt;
function (allocating and copying large amounts of data takes time). But
we don't have directly the time that the square operation took.&lt;/p&gt;
&lt;p&gt;For this,
we can use &lt;code&gt;line_profiler&lt;/code&gt; to profile the code line by line. 
After installation (using 
&lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/"&gt;Christoph Gohlke website&lt;/a&gt;
on Windows), you can use the &lt;code&gt;kernprof.py&lt;/code&gt; module. I had to copy it from the
Python scripts directory (e.g. &lt;code&gt;C:\Python27\Scritps&lt;/code&gt;) to my script directory. 
Then, add the &lt;code&gt;@profile&lt;/code&gt; decorator to every function you want to profile line
by line. Finally, use the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;python -m kernprof -l -v script.py &amp;gt; statsline.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This executes the script and generates a text file with the line profiler
output. Here is the output on the toy example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Wrote profile results to script.py.lprof
Timer unit: 5.13284e-07 s

File: script.py
Function: test at line 4
Total time: 0.205144 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
     4                                           @profile
     5                                           def test():
     6         1        18069  18069.0      4.5      a = rdn.randn(100000)
     7         1       241293 241293.0     60.4      b = np.repeat(a, 100)
     8         1       140307 140307.0     35.1      c = b ** 2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The percentage of time and the actual time (in unit of
the Timer unit, about 0.5 microseconds here) spent on each line is given.
This line by line profiling can be extremely valuable when optimizing a
complex function.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;That's it for this quick introduction. In conclusion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do not try to optimize you code prematurely: always favor code readability 
    versus unnecessary optimization.&lt;/li&gt;
&lt;li&gt;Do not try to optimize unless you really need to: very often, &lt;em&gt;good enough&lt;/em&gt; 
    performance is better than over-optimization.  &lt;/li&gt;
&lt;li&gt;Always profile your code before optimizing it: you need to know exactly the
    portion of your code that needs to be optimized in priority.&lt;/li&gt;
&lt;li&gt;When encountering a bottleneck, do not guess where it's hiding: you'll 
    probably be wrong.&lt;/li&gt;
&lt;li&gt;In Python, you can profile your code thanks to the following tools:
    &lt;code&gt;cProfile&lt;/code&gt;, &lt;code&gt;line_profiler&lt;/code&gt; and &lt;code&gt;memory_profiler&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;p&gt;Related links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.doughellmann.com/PyMOTW/profile/"&gt;Profiling in Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/582336/how-can-you-profile-a-python-script"&gt;A question on Stackoverflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stefaanlippens.net/python_profiling_with_pstats_interactive_mode"&gt;A blog post about pstats&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>Making PyQt4, PySide and IPython work together</title><link href="https://cyrille.rossant.net/making-pyqt4-pyside-and-ipython-work-together/" rel="alternate"></link><published>2012-09-20T00:00:00+02:00</published><updated>2012-09-20T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-09-20:/making-pyqt4-pyside-and-ipython-work-together/</id><summary type="html">&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/PyQt"&gt;PyQt&lt;/a&gt; and
&lt;a href="http://en.wikipedia.org/wiki/PySide"&gt;PySide&lt;/a&gt;
are two independent Python libraries allowing access to the
&lt;a href="http://en.wikipedia.org/wiki/Qt_(framework)"&gt;Qt framework&lt;/a&gt;.
PyQt is maintained by the British firm
&lt;a href="http://www.riverbankcomputing.co.uk"&gt;Riverbank Computing&lt;/a&gt;,
whereas PySide is developed by Qt developers from
&lt;a href="http://en.wikipedia.org/wiki/Nokia"&gt;Nokia&lt;/a&gt;. PySide was created
by Nokia in 2009 after they &lt;em&gt;"failed to reach an agreement with PyQt developers
to …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/PyQt"&gt;PyQt&lt;/a&gt; and
&lt;a href="http://en.wikipedia.org/wiki/PySide"&gt;PySide&lt;/a&gt;
are two independent Python libraries allowing access to the
&lt;a href="http://en.wikipedia.org/wiki/Qt_(framework)"&gt;Qt framework&lt;/a&gt;.
PyQt is maintained by the British firm
&lt;a href="http://www.riverbankcomputing.co.uk"&gt;Riverbank Computing&lt;/a&gt;,
whereas PySide is developed by Qt developers from
&lt;a href="http://en.wikipedia.org/wiki/Nokia"&gt;Nokia&lt;/a&gt;. PySide was created
by Nokia in 2009 after they &lt;em&gt;"failed to reach an agreement with PyQt developers
to change its licensing terms to include LGPL as an alternative license"&lt;/em&gt;
(&lt;a href="http://en.wikipedia.org/wiki/PySide"&gt;quoting Wikipedia&lt;/a&gt;).
Fortunately, the two APIs are very similar (which is
not that surprising given that they are just bindings to the same Qt library).&lt;/p&gt;


&lt;p&gt;Developers willing to create a Python project based on Qt do not necessarily
need to choose between the two libraries: it is possible to support both
as soon as some deprecated features of PyQt are not used. Some details can
be found on the
&lt;a href="http://qt-project.org/wiki/Differences_Between_PySide_and_PyQt"&gt;Qt website&lt;/a&gt;
or on the
&lt;a href="http://www.riverbankcomputing.co.uk/static/Docs/PyQt4/html/incompatible_apis.html"&gt;PyQt website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here I give some tips about how to support both PySide and PyQt4 in a Python
project. In addition, I describe how IPython can be configured to work
properly with those libraries: it is indeed possible to
&lt;a href="http://ipython.org/ipython-doc/dev/interactive/qtconsole.html#qt-and-the-qtconsole"&gt;interact with Qt widgets from the IPython console&lt;/a&gt;.
This can be extremely helpful for debugging
or even in real-world applications. It is also very interesting when
&lt;a href="http://ipython.org/ipython-doc/stable/interactive/reference.html#gui-event-loop-support"&gt;using matplotlib from IPython&lt;/a&gt;
(the GUI backend then being Qt).&lt;/p&gt;
&lt;h2&gt;Importing Qt in Python&lt;/h2&gt;
&lt;p&gt;The
&lt;a href="https://github.com/ros-visualization/python_qt_binding/tree/master/src/python_qt_binding"&gt;python_qt_binding&lt;/a&gt;
package allows to use either PyQt4 or PySide, depending on which is installed.
Priority is given to PyQt4, but it can be changed in the code.
I prefer to use PyQt for now, since it seems more stable (especially when
used in conjunction with IPython), but that will probably change at some point.&lt;/p&gt;
&lt;p&gt;To use it, replace all your &lt;code&gt;PyQt4&lt;/code&gt; or &lt;code&gt;PySide&lt;/code&gt; imports with this package, like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# from PyQt4 import QtGui, QtCore  # old imports&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;python_qt_binding&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;QtCore&lt;/span&gt;  &lt;span class="c1"&gt;# new imports&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;python_qt_binding&lt;/code&gt; package must be importable: the folder should be
in the current directory, or put the path to this folder in the Python path
(e.g. by creating an ASCII &lt;code&gt;.pth&lt;/code&gt; file with the path to &lt;code&gt;python_qt_binding&lt;/code&gt;
inside).&lt;/p&gt;
&lt;h2&gt;PyQt4 API v1 and v2&lt;/h2&gt;
&lt;p&gt;Two APIs are available in PyQt4, v1 and v2. The first version is on the
deprecation road. Python 3 only supports v2, so does PySide. On Python 2.x,
the v1 is the default API. You can change the API with the following code
which comes from the &lt;code&gt;python_qt_binding&lt;/code&gt; package):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sip&lt;/span&gt;
&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;sip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setapi&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;QDate&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setapi&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;QDateTime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setapi&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;QString&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setapi&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;QtextStream&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setapi&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Qtime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setapi&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;QUrl&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setapi&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;QVariant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;RuntimeError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Could not set API version (&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;): did you import PyQt4 directly?&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This code must be called before any PyQt4 import. It can be a problem with
IPython, which automatically imports PyQt4 when Qt GUI event loop integration
is active. A possible solution is to paste the above code
in &lt;code&gt;~/.ipython/profile_default/ipython_config.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Also, you may want to set the
&lt;a href="http://ipython.org/ipython-doc/dev/interactive/reference.html#pyqt-and-pyside"&gt;&lt;code&gt;Qt_API&lt;/code&gt; environment variable&lt;/a&gt;
to either &lt;code&gt;pyqt&lt;/code&gt; or &lt;code&gt;pyside&lt;/code&gt; depending on which library you want to use.
&lt;a href="http://www.technoon.com/how-to-add-environment-variables-in-windows-8.html"&gt;See here for detailled instructions on Windows&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Configuring IPython&lt;/h2&gt;
&lt;p&gt;To enable the Qt GUI event loop integration in IPython, you need to uncomment
the following lines in &lt;code&gt;~/.ipython/profile_default/ipython_config.py&lt;/code&gt; (this file is
automatically created when you create an IPython profile):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TerminalIPythonApp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gui&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;qt&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TerminalIPythonApp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pylab&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;qt&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This allows you to open a Qt window in an interactive way, and to access the Qt
widget instance from IPython while the window is open. It solves also some
slow-down issues in the IPython console when windows have been opened.
It also works with matplotlib.&lt;/p&gt;
&lt;h2&gt;Create a Qt window with IPython&lt;/h2&gt;
&lt;p&gt;When Qt GUI event loop integration is active, a Qt application is
automatically created upon IPython launch, so that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MyQtWindow&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;just works. But this won't work by default in Python (e.g. with
&lt;code&gt;python script.py&lt;/code&gt;) since a Qt application won't have been opened in the first
place. By contrast, using the following code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QApplication&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MyQtWindow&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;
&lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exec_&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;will work with a standard Python console, but will disable interactive GUI
integration in IPython! So in order to
have the expected behavior in both cases (interactive IPython, or standard
Python interpreter), I use the following code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_window&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;window_class&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Create a Qt window in Python, or interactively in IPython with Qt GUI&lt;/span&gt;
&lt;span class="sd"&gt;    event loop integration.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;app_created&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;QtCore&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QCoreApplication&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instance&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QApplication&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;app_created&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;references&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;window_class&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;references&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;app_created&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exec_&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;window&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This function can be used like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MyQtWindow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QMainWindow&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# [...] your Qt window code&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="n"&gt;window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_window&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MyQtWindow&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="misc"></category><category term="python"></category></entry><entry><title>A tutorial on OpenGL/OpenCL interoperability in Python</title><link href="https://cyrille.rossant.net/a-tutorial-on-openglopencl-interoperability-in-python/" rel="alternate"></link><published>2012-09-18T00:00:00+02:00</published><updated>2012-09-18T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-09-18:/a-tutorial-on-openglopencl-interoperability-in-python/</id><summary type="html">&lt;p&gt;In the last two posts, I've shown
&lt;a href="https://cyrille.rossant.net/pyopencl-on-windows-without-a-gpu/"&gt;how to use OpenCL for GPGPU&lt;/a&gt;,
and
&lt;a href="https://cyrille.rossant.net/2d-graphics-rendering-tutorial-with-pyopengl/"&gt;OpenGL for graphics rendering&lt;/a&gt;,
with Python. Here I'll show how both OpenCL and OpenGL
can be used at the same time with Python. It's called OpenCL-OpenGL
interoperability. What is it about?&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;OpenGL gives low-level access to …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;In the last two posts, I've shown
&lt;a href="https://cyrille.rossant.net/pyopencl-on-windows-without-a-gpu/"&gt;how to use OpenCL for GPGPU&lt;/a&gt;,
and
&lt;a href="https://cyrille.rossant.net/2d-graphics-rendering-tutorial-with-pyopengl/"&gt;OpenGL for graphics rendering&lt;/a&gt;,
with Python. Here I'll show how both OpenCL and OpenGL
can be used at the same time with Python. It's called OpenCL-OpenGL
interoperability. What is it about?&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;OpenGL gives low-level access to the graphics card to do &lt;em&gt;real-time graphics
    rendering&lt;/em&gt; with hardware acceleration in an hardware-independent way.&lt;/li&gt;
&lt;li&gt;OpenCL gives low-level access to the graphics card to do &lt;em&gt;general-purpose
    intensive vectorized computations&lt;/em&gt; with hardware acceleration in an
    hardware-independent way.&lt;/li&gt;
&lt;li&gt;OpenCL/OpenGL interoperability allows to do intensive arbitrary computations
    for real-time graphics rendering.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Broadly speaking, the GPU is natively designed to perform highly-efficient
vectorized &lt;em&gt;linear&lt;/em&gt; computations (matrix transforms, rasterization...), for
up to four dimensions (3D + 1D for
&lt;a href="http://en.wikipedia.org/wiki/Homogeneous_coordinates"&gt;homogeneous coordinates&lt;/a&gt;).
2D and 3D graphics
rendering was indeed the only use for a GPU originally. GPGPU languages
such as OpenCL give the developer access to a C-like language for doing
hardware-accelerated high-dimensional or non-linear computations on the GPU,
generally for non-graphical purposes. However, such general computations may
actually be necessary for some specific graphical purposes: physical
simulations, mathematical rendering, etc. In those cases, the most efficient way
of using OpenCL for graphical data is to let the data on the GPU at all times.
Data transfers between the CPU and the GPU are known to be slow and form a
major bottleneck in those situations.&lt;/p&gt;
&lt;p&gt;With OpenCL-OpenGL interoperability, one can execute OpenCL code on the same
data buffers than those used by OpenGL for graphics rendering. The GPU is
responsible for both OpenCL computations and rendering, and the data stays
in GPU memory at all times.&lt;/p&gt;
&lt;p&gt;If one does not have an OpenCL-compatible graphics card, then the code
still works as expected. However, data transfers between the CPU and the GPU
are not avoidable since the OpenCL kernel actually executes on the CPU in this
case. This happens automatically and transparently. Hence, as for standard
OpenCL code, a program making use of OpenCL-OpenGL interoperability can still
work on a computer that does not include a compatible GPU. This is a very
interesting point regarding software portability.&lt;/p&gt;
&lt;p&gt;I will now describe a simple script illustrating OpenCL-OpenGL interoperability.
This script initializes an empty OpenGL VBO and an OpenCL buffer containing
points on an horizontal line. An OpenCL kernel then copies the points from the
OpenCL buffer to the OpenGL one and transform the &lt;span class="math"&gt;\(y\)&lt;/span&gt;-coordinate according
to a sine function. This function is then displayed on the screen.&lt;/p&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;This script requires Numpy, PyOpenGL, PyOpenCL, and an OpenCL SDK with
OpenGL interoperability support. Also, on some platforms (like Windows 8
apparently), the Python process needs to be run as an administrator so that
this script can work.&lt;/p&gt;
&lt;h2&gt;OpenCL initialization&lt;/h2&gt;
&lt;p&gt;OpenCL needs to be initialized with OpenGL interoperability. This code snippet
does just that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;clinit&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Initialize OpenCL with GL-CL interop.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;plats&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_platforms&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# handling OSX&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;platform&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;darwin&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;ctx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Context&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;properties&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;get_gl_sharing_context_properties&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
                             &lt;span class="n"&gt;devices&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[])&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;ctx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Context&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;properties&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
                            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;context_properties&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PLATFORM&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;plats&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
                            &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;get_gl_sharing_context_properties&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CommandQueue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;queue&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This code comes
&lt;a href="http://enja.org/2011/03/22/adventures-in-pyopencl-part-2-particles-with-pyopengl/"&gt;from this blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This function returns an OpenCL context object, and a command queue used for
compiling and executing kernels, and for initializing OpenCL buffers.&lt;/p&gt;
&lt;h2&gt;Buffers initialization&lt;/h2&gt;
&lt;p&gt;The trickiest part concerns the initialization of the buffers. First, such
initialization needs to occur after OpenGL initialization, but before
any OpenGL rendering. Placing the following code in the &lt;code&gt;initializeGL()&lt;/code&gt;
function does the trick.&lt;/p&gt;
&lt;p&gt;Next, we need here three buffer objects.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A standard OpenGL VBO: we tell OpenGL that we may write to this buffer
    several times (since the OpenCL kernel has access to it) with the
    &lt;code&gt;usage=GL_DYNAMIC_DRAW&lt;/code&gt; keyword argument. This buffer initially contains
    only zeros.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# empty OpenGL VBO&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glbuf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;glvbo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;VBO&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                       &lt;span class="n"&gt;usage&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_DYNAMIC_DRAW&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                       &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_ARRAY_BUFFER&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glbuf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A standard OpenCL buffer: in our example, this buffer contains the "source"
    data, a N*2 Numpy array containing points of coordinates &lt;span class="math"&gt;\((x,0)\)&lt;/span&gt; with
    &lt;span class="math"&gt;\(x \in [-1,1]\)&lt;/span&gt;. It is read-only since we just need access to this buffer to
    copy data from it to the OpenGL VBO.
    Also, we initialize OpenCL right after the OpenGL VBO
    creation, and just before the OpenCL buffer creation.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# initialize the CL context&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;clinit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# create a pure read-only OpenCL buffer&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clbuf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Buffer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mem_flags&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;READ_ONLY&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mem_flags&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;COPY_HOST_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;hostbuf&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An interop object to access an OpenGL VBO from OpenCL: this object
    is passed to the OpenCL kernel and allows direct access to the OpenGL VBO.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# create an interop object to access to GL VBO from OpenCL&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glclbuf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GLBuffer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mem_flags&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;READ_WRITE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glbuf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;buffers&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, once these buffers have been created, we can compile the OpenCL kernel.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# build the OpenCL program&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Program&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;clkernel&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# release the PyOpenCL queue&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finish&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Kernel code&lt;/h2&gt;
&lt;p&gt;The OpenCL kernel accepts two arguments: pointers to the OpenCL buffer (with
source data), and to the OpenGL VBO. We first get the array index in the
current thread, then we copy the data from the OpenCL buffer to the OpenGL VBO,
and transform the y-coordinate through a sine function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="cp"&gt;# OpenCL kernel that generates a sine function.&lt;/span&gt;
&lt;span class="n"&gt;clkernel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;__kernel&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;clkernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;__global&lt;/span&gt; &lt;span class="kt"&gt;float2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;clpos&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;__global&lt;/span&gt; &lt;span class="kt"&gt;float2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;glpos&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="c1"&gt;//get our index in the array&lt;/span&gt;
    &lt;span class="kt"&gt;unsigned&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_global_id&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

    &lt;span class="c1"&gt;// copy the x coordinate from the CL buffer to the GL buffer&lt;/span&gt;
    &lt;span class="n"&gt;glpos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;clpos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="c1"&gt;// calculate the y coordinate and copy it on the GL buffer&lt;/span&gt;
    &lt;span class="n"&gt;glpos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;10.0&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;clpos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="s"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Kernel execution&lt;/h2&gt;
&lt;p&gt;The second trickiest part is the kernel execution. Indeed, OpenCL needs to get
a secure access to the OpenGL VBO in order to avoid problems of concurrency
(since OpenGL also needs to access to this resource). Secure access is obtained
and released with the functions &lt;code&gt;enqueue_acquire_gl_objects()&lt;/code&gt; and
&lt;code&gt;enqueue_release_gl_objects()&lt;/code&gt;. The parameters are the queue returned by
our function &lt;code&gt;clinit()&lt;/code&gt;, and a list of interop objects to access (here, just
the &lt;code&gt;glclbuf&lt;/code&gt; object).&lt;/p&gt;
&lt;p&gt;Then, the actual kernel execution is in PyOpenCL similar to PyCUDA: the
&lt;code&gt;program&lt;/code&gt; object has a method with the same name as the kernel name. The
parameters include the OpenCL queue, the global and local worksizes, and
the arguments to the kernel.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Execute the OpenCL kernel.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="c1"&gt;# get secure access to GL-CL interop objects&lt;/span&gt;
    &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;enqueue_acquire_gl_objects&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glclbuf&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;# arguments to the OpenCL kernel&lt;/span&gt;
    &lt;span class="n"&gt;kernelargs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clbuf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glclbuf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# execute the kernel&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clkernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;kernelargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# release access to the GL-CL interop objects&lt;/span&gt;
    &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;enqueue_release_gl_objects&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glclbuf&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finish&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here, we call this function in &lt;code&gt;initializeGL()&lt;/code&gt;, after the buffers creation.
This way, we update the OpenGL VBO through the OpenCL kernel only at
initialization time.
But it would be more useful in a real application to execute the kernel
in the &lt;code&gt;paintGL()&lt;/code&gt; method.&lt;/p&gt;
&lt;h2&gt;OpenGL rendering&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;paintGL()&lt;/code&gt; function is very similar to the previous OpenGL tutorial, and
has nothing to do with OpenCL. We activate the VBO and tell OpenGL to draw
consecutive segments of lines (&lt;code&gt;GL_LINE_STRIP&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: apparently, in OpenGL, using
&lt;a href="http://en.wikipedia.org/wiki/Single-precision_floating-point_format"&gt;single precision floating point numbers&lt;/a&gt;
is better than using
&lt;a href="http://en.wikipedia.org/wiki/Double-precision_floating-point_format"&gt;double precision float point numbers&lt;/a&gt;.
The graphics card may not indeed support the latter format. I used doubles in
an early version of this post and I had some nasty memory access violation
crashes in particular cases. They disappeared when I switched to floats. If
this is helpful to anyone...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;paintGL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Paint the scene.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="c1"&gt;# clear the GL scene&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glClear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_COLOR_BUFFER_BIT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# set yellow color for subsequent drawing rendering calls&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glColor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# bind the VBO&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glbuf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# tell OpenGL that the VBO contains an array of vertices&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glEnableClientState&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_VERTEX_ARRAY&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# these vertices contain 2 simple precision coordinates&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glVertexPointer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_FLOAT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glbuf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# draw &amp;quot;count&amp;quot; points from the VBO&lt;/span&gt;
    &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glDrawArrays&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_LINE_STRIP&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Full script&lt;/h2&gt;
&lt;p&gt;Here is the full script.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# PyQt4 imports&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PyQt4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;QtCore&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;QtOpenGL&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PyQt4.QtOpenGL&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;QGLWidget&lt;/span&gt;
&lt;span class="c1"&gt;# PyOpenGL imports&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;OpenGL.GL&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;gl&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;OpenGL.arrays.vbo&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;glvbo&lt;/span&gt;
&lt;span class="c1"&gt;# PyOpenCL imports&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pyopencl&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;cl&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pyopencl.tools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;get_gl_sharing_context_properties&lt;/span&gt;

&lt;span class="c1"&gt;# OpenCL kernel that generates a sine function.&lt;/span&gt;
&lt;span class="n"&gt;clkernel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;__kernel void clkernel(__global float2* clpos, __global float2* glpos)&lt;/span&gt;
&lt;span class="s2"&gt;{&lt;/span&gt;
&lt;span class="s2"&gt;    //get our index in the array&lt;/span&gt;
&lt;span class="s2"&gt;    unsigned int i = get_global_id(0);&lt;/span&gt;

&lt;span class="s2"&gt;    // copy the x coordinate from the CL buffer to the GL buffer&lt;/span&gt;
&lt;span class="s2"&gt;    glpos[i].x = clpos[i].x;&lt;/span&gt;

&lt;span class="s2"&gt;    // calculate the y coordinate and copy it on the GL buffer&lt;/span&gt;
&lt;span class="s2"&gt;    glpos[i].y = 0.5 * sin(10.0 * clpos[i].x);&lt;/span&gt;
&lt;span class="s2"&gt;}&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;clinit&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Initialize OpenCL with GL-CL interop.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;plats&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_platforms&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# handling OSX&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;platform&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;darwin&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;ctx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Context&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;properties&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;get_gl_sharing_context_properties&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
                             &lt;span class="n"&gt;devices&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[])&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;ctx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Context&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;properties&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
                            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;context_properties&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PLATFORM&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;plats&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
                            &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;get_gl_sharing_context_properties&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CommandQueue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;queue&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GLPlotWidget&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;QGLWidget&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# default window size&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;600&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;600&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Load 2D data as a Nx2 Numpy array.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initialize_buffers&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Initialize OpenGL and OpenCL buffers and interop objects,&lt;/span&gt;
&lt;span class="sd"&gt;        and compile the OpenCL kernel.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# empty OpenGL VBO&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glbuf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;glvbo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;VBO&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                               &lt;span class="n"&gt;usage&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_DYNAMIC_DRAW&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_ARRAY_BUFFER&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glbuf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;# initialize the CL context&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;clinit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;# create a pure read-only OpenCL buffer&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clbuf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Buffer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                            &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mem_flags&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;READ_ONLY&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mem_flags&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;COPY_HOST_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                            &lt;span class="n"&gt;hostbuf&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# create an interop object to access to GL VBO from OpenCL&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glclbuf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GLBuffer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mem_flags&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;READ_WRITE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                            &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glbuf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;buffers&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
        &lt;span class="c1"&gt;# build the OpenCL program&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Program&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;clkernel&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;# release the PyOpenCL queue&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finish&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Execute the OpenCL kernel.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# get secure access to GL-CL interop objects&lt;/span&gt;
        &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;enqueue_acquire_gl_objects&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glclbuf&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="c1"&gt;# arguments to the OpenCL kernel&lt;/span&gt;
        &lt;span class="n"&gt;kernelargs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clbuf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glclbuf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# execute the kernel&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;program&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clkernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;kernelargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# release access to the GL-CL interop objects&lt;/span&gt;
        &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;enqueue_release_gl_objects&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glclbuf&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finish&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update_buffer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Update the GL buffer from the CL buffer&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# execute the kernel before rendering&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glFlush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initializeGL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Initialize OpenGL, VBOs, upload data on the GPU, etc.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# initialize OpenCL first&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;initialize_buffers&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;# set background color&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glClearColor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# update the GL buffer from the CL buffer&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update_buffer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;paintGL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Paint the scene.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# clear the GL scene&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glClear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_COLOR_BUFFER_BIT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# set yellow color for subsequent drawing rendering calls&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glColor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# bind the VBO&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glbuf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;# tell OpenGL that the VBO contains an array of vertices&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glEnableClientState&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_VERTEX_ARRAY&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# these vertices contain 2 simple precision coordinates&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glVertexPointer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_FLOAT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glbuf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# draw &amp;quot;count&amp;quot; points from the VBO&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glDrawArrays&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_LINE_STRIP&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;resizeGL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Called upon window resizing: reinitialize the viewport.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# update the window size&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;
        &lt;span class="c1"&gt;# paint within the whole window&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glViewport&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# set orthographic projection (2D only)&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glMatrixMode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_PROJECTION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glLoadIdentity&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;# the window corner OpenGL coordinates are (-+1, -+1)&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glOrtho&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

    &lt;span class="c1"&gt;# define a Qt window with an OpenGL widget inside it&lt;/span&gt;
    &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QMainWindow&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="c1"&gt;# generate random data points&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="c1"&gt;# initialize the GL widget&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GLPlotWidget&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="c1"&gt;# put the window at the screen position (100, 100)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setGeometry&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setCentralWidget&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# create the Qt App and window&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QApplication&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exec_&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="GL-CL interop" src="https://cyrille.rossant.net/images/glcl.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Final notes&lt;/h2&gt;
&lt;p&gt;Here are some interesting related links.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://enja.org/2011/03/22/adventures-in-pyopencl-part-2-particles-with-pyopengl/"&gt;Another tutorial in Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.codeproject.com/Articles/201263/Part-6-Primitive-Restart-and-OpenGL-Interoperabili"&gt;Another tutorial in C++&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cmsoft.com.br/index.php?option=com_content&amp;amp;view=category&amp;amp;id=99&amp;amp;layout=blog&amp;amp;Itemid=150"&gt;Tutorial in C#&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.youtube.com/watch?v=Tv1lrjA9UvA"&gt;A cool example of what one can do with OpenGL+OpenCL!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="misc"></category><category term="python"></category><category term="gpu"></category></entry><entry><title>2D graphics rendering tutorial with PyOpenGL</title><link href="https://cyrille.rossant.net/2d-graphics-rendering-tutorial-with-pyopengl/" rel="alternate"></link><published>2012-09-17T00:00:00+02:00</published><updated>2012-09-17T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-09-17:/2d-graphics-rendering-tutorial-with-pyopengl/</id><summary type="html">&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;: you may be interested in the &lt;a href="http://vispy.org/"&gt;Vispy&lt;/a&gt; library, which provides easier and more Pythonic access to OpenGL.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/OpenGL"&gt;OpenGL&lt;/a&gt; is a widely used open and cross-platform library for real-time 3D graphics, developed more than twenty years ago. It provides a low-level API that allows the developer to access the graphics …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;: you may be interested in the &lt;a href="http://vispy.org/"&gt;Vispy&lt;/a&gt; library, which provides easier and more Pythonic access to OpenGL.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/OpenGL"&gt;OpenGL&lt;/a&gt; is a widely used open and cross-platform library for real-time 3D graphics, developed more than twenty years ago. It provides a low-level API that allows the developer to access the graphics hardware in an uniform way. It is the platform of choice when developing complex 2D or 3D applications that require hardware acceleration and that need to work on different platforms. It can be used in a number of languages including C/C++, C#, Java, Objective-C (used in iPhone and iPad games), Python, etc. In this article, I'll show how OpenGL can be used with Python (thanks to the &lt;a href="http://pyopengl.sourceforge.net/documentation/index.html"&gt;PyOpenGL library&lt;/a&gt;) to efficiently render 2D graphics.&lt;/p&gt;


&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;One needs Python with the
&lt;a href="http://numpy.scipy.org/"&gt;Numpy&lt;/a&gt;,
&lt;a href="http://pyopengl.sourceforge.net/documentation/index.html"&gt;PyOpenGL&lt;/a&gt;, and
&lt;a href="http://www.riverbankcomputing.co.uk/software/pyqt/intro"&gt;PyQt4&lt;/a&gt; libraries. On
Windows, binary installers can be found
&lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/"&gt;on this webpage&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In addition, the most
recent drivers of the system graphics cards are needed, so that the latest
implementation of OpenGL is available. In particular, we'll make use of
&lt;a href="http://en.wikipedia.org/wiki/Vertex_Buffer_Object"&gt;vertex buffer objects (VBOs)&lt;/a&gt;,
that are available in the core implementation
starting from OpenGL version 1.5 (which appeared in 2003). Graphics cards that
were shipped after this date should have drivers that support VBOs. However,
it is possible that the drivers installed on the system do not support a
recent version of OpenGL.&lt;/p&gt;
&lt;p&gt;For instance, on Windows, I had some issues with the default drivers of a 2009
graphics cards: OpenGL 1.1 was the only supported version. The reason is that
Windows (starting from Vista) can use a sort of generic driver based on the
&lt;a href="http://en.wikipedia.org/wiki/Windows_Display_Driver_Model"&gt;Windows Display Driver Model (WDDM)&lt;/a&gt;
when the constructor drivers are not found
or not available. Now, the WDDM drivers tend to privilege
&lt;a href="http://en.wikipedia.org/wiki/DirectX"&gt;DirectX&lt;/a&gt; (Microsoft's
own graphics library, concurrent to OpenGL) rather than OpenGL, such that only
very old versions of OpenGL are supported on those drivers. In order to make
things work, one needs to find the constructor drivers and force their
installation. It can be a bit painful.&lt;/p&gt;
&lt;p&gt;In brief, if you have an error message mentioning OpenGL and buffer objects when
running the script below, ensure that the graphics card drivers are the right
ones. An extremely useful tool to check the OpenGL capabilities of the
graphics card is
&lt;a href="http://www.realtech-vr.com/glview/"&gt;OpenGL Extensions Viewer&lt;/a&gt;. It works on
Windows, Linux, and iOS.&lt;/p&gt;
&lt;h2&gt;QGLWidget&lt;/h2&gt;
&lt;p&gt;We'll define a
&lt;a href="http://en.wikipedia.org/wiki/Qt_(framework)"&gt;Qt&lt;/a&gt;
widget that displays points at random positions in the window.
This widget will derive from
&lt;a href="http://doc.qt.nokia.com/4.7-snapshot/qglwidget.html"&gt;&lt;code&gt;QGLWidget&lt;/code&gt;&lt;/a&gt;,
a Qt widget that offers access to
the OpenGL API for rendering. Three methods at least need to be overriden
in the derived class: &lt;code&gt;initializeGL()&lt;/code&gt;, &lt;code&gt;updateGL()&lt;/code&gt;, and &lt;code&gt;resizeGL(w, h)&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;initializeGL()&lt;/code&gt;: make here calls to OpenGL initialization commands. It is
    also the place for creating vertex buffer objects and populating them with
    some data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;paintGL()&lt;/code&gt;: make here calls to OpenGL rendering commands. It is called
    whenever the window needs to be redrawn.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;resizeGL(w, h)&lt;/code&gt;: make here calls related to camera and viewport. It is
    called whenever the size of the widget is changed (the new widget size are
    passed as parameters to this method).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Vertex Buffer Objects&lt;/h2&gt;
&lt;p&gt;The most efficient way of rendering data is to minimize the data
transfers from system memory to GPU memory, and to minimize the number of calls
to OpenGL rendering commands. A convenient way for doing this is to use
&lt;a href="http://en.wikipedia.org/wiki/Vertex_Buffer_Object"&gt;Vertex Buffer Objects&lt;/a&gt;.
They allow to allocate memory on the GPU, load data on the GPU
once (or several times if the data changes), and render it
efficiently since the data stays on the GPU between consecutives calls to
&lt;code&gt;paintGL()&lt;/code&gt;. PyOpenGL integrates a module to easily create and use VBOs:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;OpenGL.arrays.vbo&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;glvbo&lt;/span&gt;
&lt;span class="c1"&gt;# in initializeGL:&lt;/span&gt;
&lt;span class="c1"&gt;# create a VBO, data is a Nx2 Numpy array&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vbo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;glvbo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;VBO&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# in paintGL:&lt;/span&gt;
&lt;span class="c1"&gt;# bind a VBO, i.e. tell OpenGL we&amp;#39;re going to use it for subsequent&lt;/span&gt;
&lt;span class="c1"&gt;# rendering commands&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vbo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Painting with VBOs&lt;/h2&gt;
&lt;p&gt;OpenGL can render primitives like points, lines, and convex polygons.
The
&lt;a href="https://www.opengl.org/sdk/docs/man2/xhtml/glEnableClientState.xml"&gt;&lt;code&gt;glEnableClientState&lt;/code&gt;&lt;/a&gt;
and
&lt;a href="https://www.opengl.org/sdk/docs/man2/xhtml/glVertexPointer.xml"&gt;&lt;code&gt;glVertexPointer&lt;/code&gt;&lt;/a&gt;
functions configure the VBO
for rendering, and the
&lt;a href="https://www.opengl.org/sdk/docs/man2/xhtml/glDrawArrays.xml"&gt;&lt;code&gt;glDrawArrays&lt;/code&gt;&lt;/a&gt;
function draws primitives from the
buffer stored in GPU memory. Other drawing commands that can be used with
a VBO include
&lt;a href="https://www.opengl.org/sdk/docs/man2/xhtml/glMultiDrawArrays.xml"&gt;&lt;code&gt;glMultiDrawArrays&lt;/code&gt;&lt;/a&gt;
for plotting several independent primitives
from a single VBO (which is more efficient, but less flexible, than using
several VBOs). Indexed drawing is also possible and allows to use vertices
in arbitrary order, and to reuse vertices several times during rendering.
The relevant functions are
&lt;a href="https://www.opengl.org/sdk/docs/man2/xhtml/glDrawElements.xml"&gt;&lt;code&gt;glDrawElements&lt;/code&gt;&lt;/a&gt; and
&lt;a href="https://www.opengl.org/sdk/docs/man2/xhtml/glMultiDrawElements.xml"&gt;&lt;code&gt;glMultiDrawElements&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Color can be specified either before calling the rendering commands, with
the function
&lt;a href="https://www.opengl.org/sdk/docs/man2/xhtml/glColor.xml"&gt;&lt;code&gt;glColor&lt;/code&gt;&lt;/a&gt;,
or by creating a special VBO for colors, containing
the colors of every point. The relevant functions are
&lt;a href="https://www.opengl.org/sdk/docs/man2/xhtml/glColorPointer.xml"&gt;&lt;code&gt;glColorPointer&lt;/code&gt;&lt;/a&gt;
and &lt;code&gt;glEnableClientState(GL_COLOR_ARRAY)&lt;/code&gt;. A variant consists in packing the
colors with the vertices, i.e. having 5 numbers per point in a single VBO
(x, y coordinates and R, V, B color components).
&lt;a href="http://pyopengl.sourceforge.net/context/tutorials/shader_2.xhtml"&gt;See some details here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: apparently, in OpenGL, using
&lt;a href="http://en.wikipedia.org/wiki/Single-precision_floating-point_format"&gt;single precision floating point numbers&lt;/a&gt;
is better than using
&lt;a href="http://en.wikipedia.org/wiki/Double-precision_floating-point_format"&gt;double precision float point numbers&lt;/a&gt;.
The graphics card may not indeed support the latter format. I used doubles in
an early version of this post and I had some nasty memory access violation
crashes in particular cases. They disappeared when I switched to floats. If
this is helpful to anyone...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# in paintGL:&lt;/span&gt;
&lt;span class="c1"&gt;# set the color yellow&lt;/span&gt;
&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glColor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# enable the VBO&lt;/span&gt;
&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glEnableClientState&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_VERTEX_ARRAY&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# tell OpenGL that each vertex is made of 2 single precision floating&lt;/span&gt;
&lt;span class="c1"&gt;# numbers (x and y coordinates).&lt;/span&gt;
&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glVertexPointer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_FLOAT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vbo&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# draw all points from the VBO&lt;/span&gt;
&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glDrawArrays&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_POINTS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Setting orthographic projection for 2D rendering&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;resizeGL&lt;/code&gt; method sets the geometric projection used for
&lt;a href="http://en.wikipedia.org/wiki/Rasterisation"&gt;rasterization&lt;/a&gt;.
Since we're only interested in 2D rendering in this article, we're using
&lt;a href="http://en.wikipedia.org/wiki/Orthographic_projection"&gt;orthographic projection&lt;/a&gt;
with the
&lt;a href="https://www.opengl.org/sdk/docs/man2/xhtml/glOrtho.xml"&gt;&lt;code&gt;glOrtho&lt;/code&gt;&lt;/a&gt; function.
The
&lt;a href="https://www.opengl.org/sdk/docs/man2/xhtml/glViewport.xml"&gt;&lt;code&gt;glViewport&lt;/code&gt;&lt;/a&gt;
function
allows to specify the part of the screen used for the subsequent rendering
commands. Here we just tell OpenGL to draw within the entire window.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# paint within the whole window&lt;/span&gt;
&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glViewport&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# set orthographic projection (2D only)&lt;/span&gt;
&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glMatrixMode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_PROJECTION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glLoadIdentity&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# the window corner OpenGL coordinates are (-+1, -+1)&lt;/span&gt;
&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glOrtho&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Setting the PyQt widget&lt;/h2&gt;
&lt;p&gt;Here we use PyQt as a GUI window system. To show a window on the screen and
use our OpenGL widget, we first need to define a Qt main window, put the
OpenGL widget inside, and finally create a Qt application to host the main
window.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# define a Qt window with an OpenGL widget inside it&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QMainWindow&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;# initialize the GL widget&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GLPlotWidget&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;# [...] (set data for the OpenGL widget)&lt;/span&gt;
        &lt;span class="c1"&gt;# put the window at the screen position (100, 100)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setGeometry&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setCentralWidget&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# create the Qt App and window&lt;/span&gt;
&lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QApplication&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exec_&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Full script&lt;/h2&gt;
&lt;p&gt;Here is the full script.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# PyQt4 imports&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PyQt4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;QtCore&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;QtOpenGL&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PyQt4.QtOpenGL&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;QGLWidget&lt;/span&gt;
&lt;span class="c1"&gt;# PyOpenGL imports&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;OpenGL.GL&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;gl&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;OpenGL.arrays.vbo&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;glvbo&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GLPlotWidget&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;QGLWidget&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# default window size&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;600&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;600&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Load 2D data as a Nx2 Numpy array.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initializeGL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Initialize OpenGL, VBOs, upload data on the GPU, etc.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# background color&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glClearColor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# create a Vertex Buffer Object with the specified data&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vbo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;glvbo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;VBO&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;paintGL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Paint the scene.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# clear the buffer&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glClear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_COLOR_BUFFER_BIT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# set yellow color for subsequent drawing rendering calls&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glColor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# bind the VBO&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vbo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;# tell OpenGL that the VBO contains an array of vertices&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glEnableClientState&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_VERTEX_ARRAY&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# these vertices contain 2 single precision coordinates&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glVertexPointer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_FLOAT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vbo&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# draw &amp;quot;count&amp;quot; points from the VBO&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glDrawArrays&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_POINTS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;resizeGL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Called upon window resizing: reinitialize the viewport.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="c1"&gt;# update the window size&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;
        &lt;span class="c1"&gt;# paint within the whole window&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glViewport&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# set orthographic projection (2D only)&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glMatrixMode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GL_PROJECTION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glLoadIdentity&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;# the window corner OpenGL coordinates are (-+1, -+1)&lt;/span&gt;
        &lt;span class="n"&gt;gl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glOrtho&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# import numpy for generating random data points&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy.random&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;rdn&lt;/span&gt;

    &lt;span class="c1"&gt;# define a Qt window with an OpenGL widget inside it&lt;/span&gt;
    &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QMainWindow&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="c1"&gt;# generate random data points&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;rdn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="c1"&gt;# initialize the GL widget&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GLPlotWidget&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="c1"&gt;# put the window at the screen position (100, 100)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setGeometry&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setCentralWidget&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;widget&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# create the Qt App and window&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;QtGui&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QApplication&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TestWindow&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exec_&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="PyOpenGL tutorial" src="https://cyrille.rossant.net/images/gl.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Final notes&lt;/h2&gt;
&lt;p&gt;Here are some related interesting links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://pyopengl.sourceforge.net/documentation/index.html"&gt;Official PyOpenGL documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.opengl.org/sdk/docs/man2/"&gt;Official OpenGL documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pyopengl.sourceforge.net/context/tutorials/index.xhtml"&gt;A PyOpenGL tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://zetcode.com/tutorials/pyqt4/"&gt;A PyQt4 tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.siafoo.net/article/58"&gt;PyOpenGL tips and tricks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.songho.ca/opengl/gl_vbo.html"&gt;Introduction to VBOs (C++)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.opengl.org/wiki/Vertex_Specification_Best_Practices"&gt;Vertex Specification Best Practices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="misc"></category><category term="python"></category><category term="gpu"></category><category term="dataviz"></category></entry><entry><title>A PyOpenCL tutorial on Windows with or without a GPU</title><link href="https://cyrille.rossant.net/pyopencl-on-windows-without-a-gpu/" rel="alternate"></link><published>2012-09-16T00:00:00+02:00</published><updated>2012-09-16T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-09-16:/pyopencl-on-windows-without-a-gpu/</id><summary type="html">&lt;p&gt;I've been using &lt;a href="http://en.wikipedia.org/wiki/CUDA"&gt;CUDA&lt;/a&gt; and
&lt;a href="http://documen.tician.de/pycuda/"&gt;PyCUDA&lt;/a&gt; as
&lt;a href="http://en.wikipedia.org/wiki/GPGPU"&gt;GPGPU&lt;/a&gt; platforms for a few years now.
They enable access to the incredible computational power of graphics cards
through a simple C-like language. A recent
&lt;a href="http://en.wikipedia.org/wiki/Nvidia"&gt;Nvidia&lt;/a&gt; graphics card is nevertheless
required in order to execute CUDA code. Some computers may not include a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been using &lt;a href="http://en.wikipedia.org/wiki/CUDA"&gt;CUDA&lt;/a&gt; and
&lt;a href="http://documen.tician.de/pycuda/"&gt;PyCUDA&lt;/a&gt; as
&lt;a href="http://en.wikipedia.org/wiki/GPGPU"&gt;GPGPU&lt;/a&gt; platforms for a few years now.
They enable access to the incredible computational power of graphics cards
through a simple C-like language. A recent
&lt;a href="http://en.wikipedia.org/wiki/Nvidia"&gt;Nvidia&lt;/a&gt; graphics card is nevertheless
required in order to execute CUDA code. Some computers may not include a
Nvidia GPU, but rather an
&lt;a href="http://en.wikipedia.org/wiki/Advanced_Micro_Devices"&gt;AMD/ATI&lt;/a&gt; card or even
an integrated graphics processor. Those computers thus cannot execute a CUDA
program.&lt;/p&gt;


&lt;p&gt;Whereas changing the GPU on a desktop computer is straightforward (one still
needs to buy a new graphics card...), it is generally not possible to do so
on a laptop. It prevents a number of developers to run, compile or debug CUDA
code. It is also certainly a problem when distributing a software relying on
CUDA, since not having a CUDA-enabled Nvidia GPU prevents one to even launch
the program.&lt;/p&gt;
&lt;p&gt;For these reasons, I've recently been interested in
&lt;a href="http://en.wikipedia.org/wiki/OpenCL"&gt;OpenCL&lt;/a&gt;, a computing framework
equivalent to CUDA. The main difference is that OpenCL is an open standard
that has been adopted not only by Nvidia, but also by Intel and AMD. It means
that OpenCL programs may run on (recent) graphics card of either Nvidia or
AMD. In addition, a very interesting feature is that OpenCL programs may run
on a computer that does not even have a OpenCL-enabled GPU, but only a
recent-enough CPU. OpenCL code can be compiled for CPUs through the &lt;a href="http://software.intel.com/en-us/vcsource/tools/opencl-sdk"&gt;Intel
SDK for OpenCL&lt;/a&gt;
(Intel-only CPUs) or the &lt;a href="http://developer.amd.com/tools/hc/AMDAPPSDK/"&gt;AMD APP
SDK&lt;/a&gt;. OpenCL code is still
accelerated through vectorization instructions on CPUs (e.g.
&lt;a href="http://en.wikipedia.org/wiki/Streaming_SIMD_Extensions"&gt;SSE&lt;/a&gt; or
&lt;a href="http://en.wikipedia.org/wiki/Advanced_Vector_Extensions"&gt;AVX&lt;/a&gt;) and multicore
CPUs.&lt;/p&gt;
&lt;p&gt;This is really convenient since one can develop, debug and run an OpenCL
program on virtually any computer, even if it does not include an
OpenCL-enabled GPU. Moreover, distributing such a program is easier since the
end-user does not necessarily need to have a specific graphics card. Of
course, the performance of the program will be far less interesting than with
such a GPU, but the program will still run correctly.&lt;/p&gt;
&lt;p&gt;Here I detail my first experience with OpenCL on Python (using
&lt;a href="http://mathema.tician.de/software/pyopencl"&gt;PyOpenCL&lt;/a&gt;).
The installation part is actually the less trivial part (while still being
relatively easy) and may be of interest to some people.&lt;/p&gt;
&lt;h2&gt;Installation of an OpenCL SDK&lt;/h2&gt;
&lt;p&gt;I'll explain how I could install OpenCL and PyOpenCL on an "old" laptop with
an &lt;a href="http://www.amd.com/us/products/desktop/graphics/ati-radeon-hd-3000/hd-3600"&gt;ATI Radeon Mobility HD
3650&lt;/a&gt;
graphics card that does not support
OpenCL, an &lt;a href="http://en.wikipedia.org/wiki/Intel_Core_2"&gt;Intel Core 2 Duo CPU&lt;/a&gt;,
and a 32-bits &lt;a href="http://en.wikipedia.org/wiki/Windows_8"&gt;Windows 8&lt;/a&gt; operating
system.&lt;/p&gt;
&lt;p&gt;First, one needs to install an OpenCL SDK. AMD and Intel have their own SDKs
and I installed both. Later, we'll see that PyOpenCL allows us to choose, at
compilation-time, which SDK to use. The installation of the SDKs is
straightforward on Windows.&lt;/p&gt;
&lt;h2&gt;Installation of PyOpenCL&lt;/h2&gt;
&lt;p&gt;PyOpenCL is to OpenCL what PyCUDA is to CUDA: a Python wrapper to those GPGPU
platforms. It is developed and maintained by &lt;a href="http://mathema.tician.de/"&gt;Andreas
Klöckner&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Installing PyOpenCL on Windows is easy when using the binary package provided
by &lt;a href="http://www.lfd.uci.edu/~gohlke/"&gt;Christoph Gohlke&lt;/a&gt;. &lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/"&gt;His
webpage&lt;/a&gt; contains Windows binary
installers for the most recent versions of hundreds of Python packages. It is
of invaluable help for those Python users that use Windows. It is also
possible yet much more complicated to build &lt;a href="http://wiki.tiker.net/PyOpenCL/Installation"&gt;PyOpenCL from source on
Windows&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;PyOpenCL has a few uncommon dependencies (beyond
&lt;a href="http://numpy.scipy.org/"&gt;Numpy&lt;/a&gt;), like
&lt;a href="http://pypi.python.org/pypi/decorator"&gt;decorator&lt;/a&gt; and
&lt;a href="http://pypi.python.org/pypi/pytools"&gt;PyTools&lt;/a&gt; (actually the latter includes
&lt;em&gt;decorator&lt;/em&gt;, so I'm not even sure one needs to install decorator separately).
These libraries can be easily installed with the &lt;code&gt;easy_install&lt;/code&gt; command-line
tool provided by the &lt;a href="http://packages.python.org/distribute/"&gt;Distribute&lt;/a&gt;
library.&lt;/p&gt;
&lt;p&gt;Some environment variables may need to be specified, like &lt;code&gt;PYOPENCL_CTX&lt;/code&gt; or
&lt;code&gt;PYOPENCL_COMPILER_OUTPUT&lt;/code&gt; (see below). In order to do this, one needs to go
to the advanced system parameters and add new variables in the &lt;em&gt;User
variables&lt;/em&gt; section (&lt;a href="http://www.technoon.com/how-to-add-environment-variables-in-windows-8.html"&gt;see
here&lt;/a&gt;
for details).&lt;/p&gt;
&lt;p&gt;In order to quickly test the installation of PyOpenCL, try the following
commands in a Python console:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;import pyopencl
import pyopencl.array
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We now turn to the execution of a very simple OpenCL program.&lt;/p&gt;
&lt;h2&gt;PyOpenCL Hello World script&lt;/h2&gt;
&lt;p&gt;Save the following code in a .py file and execute it. The OpenCL code should be
compiled and executed correctly, and the squares of integers should be
displayed. Some warnings may be displayed even if everything worked corectly.
In addition, PyOpenCL may require the user to decide which SDK to use if several
are installed. In order not to be asked everytime, one can set the
&lt;code&gt;PYOPENCL_CTX&lt;/code&gt; environment variable to the corresponding index (see above).&lt;/p&gt;
&lt;p&gt;I could use both Intel and AMD SDKs. Ensure that you run Python in a command
line as an administrator (otherwise it may cause issues with
compilation, at least that's what I could note on my Windows 8 setup).&lt;/p&gt;
&lt;p&gt;The actual code is self-explanatory, especially for someone who already knows
CUDA. This program generates a Numpy array with all integers between 0 and 9,
passes it to an OpenCL kernel that computes the square of an array of integers,
dynamically compiles and executes this kernel, and copies back the output from
the context memory to Python.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# import PyOpenCL and Numpy. An OpenCL-enabled GPU is not required,&lt;/span&gt;
&lt;span class="c1"&gt;# OpenCL kernels can be compiled on most CPUs thanks to the Intel SDK for OpenCL&lt;/span&gt;
&lt;span class="c1"&gt;# or the AMD APP SDK.&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pyopencl&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;cl&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# create an OpenCL context&lt;/span&gt;
&lt;span class="n"&gt;ctx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_some_context&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CommandQueue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# create the kernel input&lt;/span&gt;
&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# kernel output placeholder&lt;/span&gt;
&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# create context buffers for a and b arrays&lt;/span&gt;
&lt;span class="c1"&gt;# for a (input), we need to specify that this buffer should be populated from a&lt;/span&gt;
&lt;span class="n"&gt;a_dev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Buffer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mem_flags&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;READ_ONLY&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mem_flags&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;COPY_HOST_PTR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;hostbuf&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# for b (output), we just allocate an empty buffer&lt;/span&gt;
&lt;span class="n"&gt;b_dev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Buffer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mem_flags&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;WRITE_ONLY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nbytes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# OpenCL kernel code&lt;/span&gt;
&lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;__kernel void test1(__global int* a, __global int* b) {&lt;/span&gt;
&lt;span class="s2"&gt;    int i = get_global_id(0);&lt;/span&gt;
&lt;span class="s2"&gt;    b[i] = a[i]*a[i];&lt;/span&gt;
&lt;span class="s2"&gt;}&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# compile the kernel&lt;/span&gt;
&lt;span class="n"&gt;prg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Program&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# launch the kernel&lt;/span&gt;
&lt;span class="n"&gt;event&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;prg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;a_dev&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_dev&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# copy the output from the context to the Python process&lt;/span&gt;
&lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;enqueue_copy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_dev&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# if everything went fine, b should contain squares of integers&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is the output I get on my installation.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;C:\Python27\lib\site-packages\pyopencl\__init__.py:32: CompilerWarning: Built kernel retrieved from cache. Original from-source build had warnings:
Build on &amp;lt;pyopencl.Device &amp;#39;Intel(R) Core(TM)2 Duo CPU     T6400  @ 2.00GHz&amp;#39; on &amp;#39;Intel(R) OpenCL&amp;#39; at 0x2251b58&amp;gt; succeeded, but said:

Build started
Kernel &amp;lt;test1&amp;gt; was successfully vectorized
Done.
  warn(text, CompilerWarning)
C:\Python27\lib\site-packages\pyopencl\__init__.py:32: CompilerWarning: From-binary build succeeded, but resulted in non-empty logs:
Build on &amp;lt;pyopencl.Device &amp;#39;Intel(R) Core(TM)2 Duo CPU     T6400  @ 2.00GHz&amp;#39; on &amp;#39;Intel(R) OpenCL&amp;#39; at 0x2251b58&amp;gt; succeeded, but said:

Build started
Kernel &amp;lt;test1&amp;gt; was successfully vectorized
Done.
  warn(text, CompilerWarning)
[ 0  1  4  9 16 25 36 49 64 81]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Final notes&lt;/h2&gt;
&lt;p&gt;There is of course far more to tell about OpenCL that what I've shown here.
The point was to show how one could use GPGPU on a standard computer that
does not have a GPGPU-enabled graphics card, by using OpenCL and Python.
Even if I don't have much experience in OpenCL yet, I think it has a promising
future as an open and portable concurrent to CUDA.&lt;/p&gt;
&lt;p&gt;Here are some interesting related links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.khronos.org/opencl/"&gt;The official OpenCL website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://enja.org/2011/02/22/adventures-in-pyopencl-part-1-getting-started-with-python/"&gt;PyOpenCL tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.planquart.com/tutoriel-n%C2%B01-pyopencl-premier-calcul-sur-gpu"&gt;Another one (in French)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="misc"></category><category term="python"></category><category term="gpu"></category></entry><entry><title>A mathematical proof that our world is in three dimensions</title><link href="https://cyrille.rossant.net/a-mathematical-proof-that-our-world-is-in-three-dimensions/" rel="alternate"></link><published>2012-08-19T00:00:00+02:00</published><updated>2012-08-19T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-08-19:/a-mathematical-proof-that-our-world-is-in-three-dimensions/</id><summary type="html">&lt;p&gt;Everyone knows that our world is three-dimensional. It seems indeed obvious that there are three independent spatial directions, no less, no more. But can we really be sure? After all, everything we know about our world comes from our senses and from what our brains interprete. Does the fact that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Everyone knows that our world is three-dimensional. It seems indeed obvious that there are three independent spatial directions, no less, no more. But can we really be sure? After all, everything we know about our world comes from our senses and from what our brains interprete. Does the fact that we &lt;em&gt;see&lt;/em&gt; in 3D really proves that the world &lt;em&gt;is&lt;/em&gt; in 3D? Can we have a mathematical proof, based on experimental observations, that the world is three-dimensional? This question is totally relevant, and several scientists and philosophers, like &lt;a href="http://en.wikipedia.org/wiki/Immanuel_Kant"&gt;Immanuel Kant&lt;/a&gt;, have been interested in it (see for example &lt;a href="http://webinet.cafe-sciences.org/articles/dans-combien-de-dimensions-vivons-nous/"&gt;this blog post&lt;/a&gt; in French for a nice review).&lt;/p&gt;


&lt;p&gt;Here, I detail Kant's idea of a rigourous proof that we live in a 3D world. There are three steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We model the world as an N-dimensional Euclidean space and we study a mathematical object called a &lt;strong&gt;vector field&lt;/strong&gt; that verifies some natural properties.&lt;/li&gt;
&lt;li&gt;We find experimental observations that allows us to infer properties about this object.&lt;/li&gt;
&lt;li&gt;We link these properties to the number of spatial dimensions and we conclude that &lt;span class="math"&gt;\(N=3\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The physical notions behind this proof are about &lt;a href="http://en.wikipedia.org/wiki/Conservative_force"&gt;conservative forces&lt;/a&gt; and &lt;a href="http://en.wikipedia.org/wiki/Potential_theory"&gt;potential theory&lt;/a&gt;. The mathematical notions concern the &lt;a href="http://en.wikipedia.org/wiki/Laplace_operator"&gt;Laplace operator&lt;/a&gt; and &lt;a href="http://en.wikipedia.org/wiki/Harmonic_function"&gt;harmonic functions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First, here is an intuitive explanation of this proof (&lt;a href="http://en.wikipedia.org/wiki/Inverse-square_law#Justification"&gt;quoting Wikipedia&lt;/a&gt;):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The inverse-square law generally applies when some force, energy, or other conserved quantity is radiated outward radially in three-dimensional space from a point source. Since the surface area of a sphere (which is &lt;span class="math"&gt;\(4\pi r^2\)&lt;/span&gt;) is proportional to the square of the radius, as the emitted radiation gets farther from the source, it is spread out over an area that is increasing in proportion to the square of the distance from the source. Hence, the intensity of radiation passing through any unit area (directly facing the point source) is inversely proportional to the square of the distance from the point source.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;1. Mathematical model&lt;/h2&gt;
&lt;p&gt;We model the world as an open set &lt;span class="math"&gt;\(U\)&lt;/span&gt; of &lt;span class="math"&gt;\(\mathbb R^N\)&lt;/span&gt;, where &lt;span class="math"&gt;\(N\)&lt;/span&gt; is the number of dimensions. We consider a &lt;a href="http://en.wikipedia.org/wiki/Vector_field"&gt;&lt;strong&gt;vector field&lt;/strong&gt;&lt;/a&gt; &lt;span class="math"&gt;\(F\)&lt;/span&gt;, that is, a function &lt;span class="math"&gt;\(F: U \longrightarrow \mathbb R^N\)&lt;/span&gt; that maps any point &lt;span class="math"&gt;\(p\)&lt;/span&gt; in &lt;span class="math"&gt;\(U\)&lt;/span&gt; to a &lt;span class="math"&gt;\(N\)&lt;/span&gt;-dimensional vector attached to that point. This vector field can represent a &lt;a href="http://en.wikipedia.org/wiki/Force_field_(physics)"&gt;force field&lt;/a&gt;, like a &lt;a href="http://en.wikipedia.org/wiki/Gravitational_field"&gt;gravitational field&lt;/a&gt; generated by a massive object, or an &lt;a href="http://en.wikipedia.org/wiki/Electric_field"&gt;electrostatic field&lt;/a&gt; generated by a charged body. It can also represent a &lt;a href="http://en.wikipedia.org/wiki/Flux"&gt;&lt;strong&gt;flux&lt;/strong&gt;&lt;/a&gt;, like in &lt;a href="http://en.wikipedia.org/wiki/Transport_phenomena"&gt;transport phenomena&lt;/a&gt;: &lt;a href="http://en.wikipedia.org/wiki/Heat_transfer"&gt;heat transfer&lt;/a&gt;, &lt;a href="http://en.wikipedia.org/wiki/Mass_transfer"&gt;mass transfer&lt;/a&gt; or &lt;a href="http://en.wikipedia.org/wiki/Fluid_dynamics"&gt;fluid dynamics&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We will assume three natural hypotheses: that this vector field is &lt;a href="http://en.wikipedia.org/wiki/Solenoidal_vector_field"&gt;&lt;strong&gt;incompressible&lt;/strong&gt;&lt;/a&gt; (or solenoidal), &lt;a href="http://en.wikipedia.org/wiki/Conservative_vector_field"&gt;&lt;strong&gt;conservative&lt;/strong&gt;&lt;/a&gt; (or irrotational), and &lt;a href="http://en.wikipedia.org/wiki/Isotropy"&gt;&lt;strong&gt;isotropic&lt;/strong&gt;&lt;/a&gt;. One also uses the terminology of &lt;a href="http://en.wikipedia.org/wiki/Laplacian_field"&gt;&lt;strong&gt;Laplacian vector field&lt;/strong&gt;&lt;/a&gt; when the first two hypotheses are satisfied. These hypotheses correspond to a conserved quantity that is radiated outward radially and isotropically from a point source.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Incompressibility&lt;/strong&gt; occurs when the &lt;a href="http://en.wikipedia.org/wiki/Divergence"&gt;&lt;strong&gt;divergence&lt;/strong&gt;&lt;/a&gt; of the vector field is zero: &lt;span class="math"&gt;\(\nabla \cdot F=0\)&lt;/span&gt;. It means that there is no local source or sink, no local creation or annihilation. If the vector field represents a mass transfer, incompressibility means that there is conservation of mass: mass cannot be created or annihilated at any point in space. For a gravitational field, the divergence is zero outside mass sources. Similarly, for an electrostatic field, the divergence is zero outside charge sources.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Irrotationality&lt;/strong&gt; occurs when the &lt;a href="http://en.wikipedia.org/wiki/Curl_(mathematics)"&gt;&lt;strong&gt;curl&lt;/strong&gt;&lt;/a&gt; of the vector field is zero: &lt;span class="math"&gt;\(\nabla \times F=0\)&lt;/span&gt;. It means that the field does not &lt;em&gt;spin&lt;/em&gt; locally (in fluid dynamics terms, there is no &lt;a href="http://en.wikipedia.org/wiki/Vorticity"&gt;vorticity&lt;/a&gt;). An equivalent property is that the field is &lt;strong&gt;conservative&lt;/strong&gt;, so that the line integral from one point to another is independent of the choice of path connecting the two points (in fact, one has to assume the &lt;em&gt;simple connectedness&lt;/em&gt; of &lt;span class="math"&gt;\(U\)&lt;/span&gt; for the equivalence). A conservative field is the &lt;strong&gt;&lt;a href="http://en.wikipedia.org/wiki/Gradient"&gt;gradient&lt;/a&gt; of a scalar field&lt;/strong&gt;: there exists a scalar field &lt;span class="math"&gt;\(u : U \longrightarrow \mathbb R\)&lt;/span&gt; such that &lt;span class="math"&gt;\(F = \nabla u\)&lt;/span&gt;. The gravitational force and the electrostatic force are examples of &lt;a href="http://en.wikipedia.org/wiki/Conservative_force"&gt;conservative forces&lt;/a&gt;. The gravitational &lt;em&gt;vector field&lt;/em&gt; is the gradient of the gravitational &lt;em&gt;potential field&lt;/em&gt;, and similarly for the electrostatic field.&lt;/p&gt;
&lt;p&gt;Finally, &lt;strong&gt;isotropy&lt;/strong&gt; means uniformity in spatial directions, that is, we assume that the vector field &lt;span class="math"&gt;\(F\)&lt;/span&gt; is &lt;a href="http://en.wikipedia.org/wiki/Rotational_invariance"&gt;rotational invariant&lt;/a&gt;. For example, the gravitational or electrostatic field generated by a perfectly spherical source is rotational invariant.&lt;/p&gt;
&lt;p&gt;Under the two last hypotheses, we can write &lt;span class="math"&gt;\(F=\nabla u(r)\)&lt;/span&gt; where &lt;span class="math"&gt;\(r\)&lt;/span&gt; is the distance to the origin: &lt;span class="math"&gt;\(r^2 = \sum x_i^2\)&lt;/span&gt;. The vector field &lt;span class="math"&gt;\(F\)&lt;/span&gt; is the gradient of a scalar field &lt;span class="math"&gt;\(u\)&lt;/span&gt; that depends only on &lt;span class="math"&gt;\(r\)&lt;/span&gt; since it is isotropic. The first hypothesis, &lt;span class="math"&gt;\(\nabla \cdot F=0\)&lt;/span&gt; (outside field sources), implies that &lt;span class="math"&gt;\(\nabla \cdot \nabla u=0\)&lt;/span&gt;, that is, &lt;span class="math"&gt;\(\Delta u=0\)&lt;/span&gt; where &lt;span class="math"&gt;\(\Delta=\sum \frac{\partial^2}{\partial x_i^2}\)&lt;/span&gt; is the &lt;a href="http://en.wikipedia.org/wiki/Laplace_operator"&gt;Laplacian&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The equation &lt;span class="math"&gt;\(\Delta u=0\)&lt;/span&gt; is a &lt;a href="http://en.wikipedia.org/wiki/Partial_differential_equation"&gt;&lt;strong&gt;partial differential equation&lt;/strong&gt;&lt;/a&gt; (PDE) called the &lt;a href="http://en.wikipedia.org/wiki/Laplace%27s_equation"&gt;&lt;strong&gt;Laplace equation&lt;/strong&gt;&lt;/a&gt;. A function with a null Laplacian is called an &lt;a href="http://en.wikipedia.org/wiki/Harmonic_function"&gt;&lt;strong&gt;harmonic function&lt;/strong&gt;&lt;/a&gt;, so we're looking for an harmonic function &lt;span class="math"&gt;\(u(r)\)&lt;/span&gt;. &lt;/p&gt;
&lt;h2&gt;2. Experimental observations&lt;/h2&gt;
&lt;p&gt;It is known since &lt;a href="http://en.wikipedia.org/wiki/Newton's_law_of_universal_gravitation"&gt;Newton&lt;/a&gt; and &lt;a href="http://en.wikipedia.org/wiki/Coulomb's_law"&gt;Coulomb&lt;/a&gt; that the laws of gravitation and electrostatics follow &lt;a href="http://en.wikipedia.org/wiki/Inverse-square_law"&gt;inverse-square laws&lt;/a&gt;, where the strength of interaction forces is proportional to the inverse square of the distance. This observation has been validated by a number of experiments during the last centuries. The same inverse-square law is observed for light, sound and radiation phenomena.&lt;/p&gt;
&lt;p&gt;We will now show that if a vector field satisfying the three preceding properties (like the gravitation law) verifies the inverse-square law, then it implies necessarily that &lt;span class="math"&gt;\(N=3\)&lt;/span&gt;, i.e. the world has three dimensions.&lt;/p&gt;
&lt;h2&gt;3. Proof&lt;/h2&gt;
&lt;p&gt;The proof is straightforward once one knows the following &lt;a href="http://en.wikipedia.org/wiki/Laplace_operator#N_dimensions"&gt;expression for the Laplacian in N dimensions and in spherical coordinates&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$\Delta u(r) = \frac{1}{r^{N-1}} \times \frac{\partial}{\partial r} \left( r^{n-1} \frac{\partial u}{\partial r} \right) + \frac{1}{r^2} \times \Delta_{S^{N-1}} u$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\Delta_{S^{N-1}}\)&lt;/span&gt; is the &lt;a href="http://en.wikipedia.org/wiki/Laplace%E2%80%93Beltrami_operator"&gt;Laplace-Beltrami operator&lt;/a&gt; on the &lt;a href="http://en.wikipedia.org/wiki/N_sphere"&gt;(N-1)-hypersphere&lt;/a&gt; (an (N-1)-dimensional &lt;a href="http://en.wikipedia.org/wiki/Riemannian_manifold"&gt;Riemannian manifold&lt;/a&gt;), also called &lt;a href="http://en.wikipedia.org/wiki/Laplace%E2%80%93Beltrami_operator#Examples"&gt;spherical Laplacian&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Since &lt;span class="math"&gt;\(u\)&lt;/span&gt; is isotropic and depends only on &lt;span class="math"&gt;\(r\)&lt;/span&gt;, it is constant on hyperspheres (defined by &lt;span class="math"&gt;\(r=\textrm{constant}\)&lt;/span&gt;), so that the restriction of &lt;span class="math"&gt;\(u\)&lt;/span&gt; on &lt;span class="math"&gt;\(S^{N-1}\)&lt;/span&gt; is constant, its gradient is null, and &lt;span class="math"&gt;\(\Delta_{S^{N-1}} u=0\)&lt;/span&gt;. Therefore:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$\frac{1}{r^{N-1}} \times \frac{\partial}{\partial r} \left( r^{n-1} \frac{\partial u}{\partial r} \right) = 0$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;hence:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$\left( r^{n-1} \frac{\partial u}{\partial r} \right) = \textrm{constant}$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;and finally we find that:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$u(r) = \frac{C}{r^{N-2}}.$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;We omit the integration constant since a potential field is defined up to an additive constant. Hence, the intensity of the vector field &lt;span class="math"&gt;\(\nabla u\)&lt;/span&gt; is proportional to &lt;span class="math"&gt;\(1/r^{N-1}\)&lt;/span&gt;. For an inverse-square law, it means that &lt;span class="math"&gt;\(N-1=2\)&lt;/span&gt; so that &lt;span class="math"&gt;\(N=3\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Finally, we should add that some modern theories, like &lt;a href="http://en.wikipedia.org/wiki/String_theory"&gt;string theory&lt;/a&gt;, assume a higher number of spatial dimensions, where the extra dimensions are of a much smaller scale, such that, at common scales, the three dimensions of space are still a reasonable approximation.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="misc"></category><category term="maths"></category></entry><entry><title>Fréquence des prénoms des candidats au bac 2012</title><link href="https://cyrille.rossant.net/frequence-des-prenoms-des-candidats-au-bac-2012/" rel="alternate"></link><published>2012-07-14T00:00:00+02:00</published><updated>2012-07-14T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-07-14:/frequence-des-prenoms-des-candidats-au-bac-2012/</id><summary type="html">&lt;p&gt;Je poursuis mon analyse des prénoms des candidats au bac cette année (voir
&lt;a href="https://cyrille.rossant.net/prenoms-et-reussite-au-bac/"&gt;billet précédent&lt;/a&gt;) en
m'intéressant cette fois à la fréquence des différents prénoms portés
par les candidats, indépendamment de leurs résultats. Les 346 581
candidats portent 18 473 prénoms différents. &lt;strong&gt;Le prénom le plus porté
est Camille&lt;/strong&gt; avec …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Je poursuis mon analyse des prénoms des candidats au bac cette année (voir
&lt;a href="https://cyrille.rossant.net/prenoms-et-reussite-au-bac/"&gt;billet précédent&lt;/a&gt;) en
m'intéressant cette fois à la fréquence des différents prénoms portés
par les candidats, indépendamment de leurs résultats. Les 346 581
candidats portent 18 473 prénoms différents. &lt;strong&gt;Le prénom le plus porté
est Camille&lt;/strong&gt; avec 4 848 candidats. Voici les quelques prénoms les plus
utilisés, représentatifs des prénoms à la mode aux alentours de l'année
1994 (nuage réalisé sur &lt;a href="http://www.wordle.net"&gt;Wordle&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img alt="Prénoms" src="/images/prenoms-cloud.png" /&gt;&lt;/p&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Camille     4848
Marie       4354
Thomas      4134
Manon       4131
Nicolas     3851
Alexandre   3831
Maxime      3720
Laura       3702
Marine      3639
Pauline     3630
Marion      3433
Antoine     3370
Julie       3157
Mathilde    3045
Quentin     3036
Guillaume   2913
Pierre      2872
Julien      2854
Kevin       2835
Lea         2780
Anais       2775
Romain      2621
Clement     2615
Melanie     2576
Justine     2564
Sarah       2398
Florian     2298
Chloe       2256
Charlotte   2172
Valentin    2150
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Une observation intéressante est que les prénoms rares sont,
paradoxalement, très nombreux. Ainsi, 12 129 prénoms soit &lt;strong&gt;65% de tous
les prénoms ne sont portés que par un seul candidat&lt;/strong&gt;! Mais ces
candidats ne représentent que 3.5% du total des candidats. Un nombre
important de parents souhaite ainsi donner un prénom unique à leur
enfant, souvent d'ailleurs en trouvant des variantes orthographiques
originales de prénoms plus classiques. Par exemple, le prénom Zinedine
admet comme variantes, entre
autres: Zin-Eddine, Zine-Din, Zine-Dine, Zine-Eddine, Zineddine
ou Zinnedine. D'ailleurs, &lt;strong&gt;les prénoms composés représentent 15% de
tous les prénoms&lt;/strong&gt; (et 2% de tous les candidats).&lt;/p&gt;
&lt;p&gt;Poursuivant le raisonnement, on peut s'intéresser au nombre de prénoms
portés par 2, 3, 4 candidats ou plus. Cela revient à étudier la
distribution des fréquences des prénoms. On obtient alors la courbe
suivante.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Loi de Zipf" src="https://cyrille.rossant.net/images/prenoms-zipf.png" /&gt;&lt;/p&gt;
&lt;p&gt;A gauche est représenté la fraction de prénoms qui sont portés par 1, 2,
... jusqu'à 20 candidats (points bleus). Si 65% des prénoms sont portés
par un seul candidat, 10% le sont par 2 candidats, 5% le sont par 3,
etc. Cette courbe démarre à une valeur importante mais diminue ensuite
extrêmement rapidement. Il s'agit d'une propriété caractéristique de
nombreux phénomènes et qui porte le nom de &lt;a href="http://fr.wikipedia.org/wiki/Longue_tra%C3%AEne"&gt;&lt;strong&gt;"longue
traîne"&lt;/strong&gt;&lt;/a&gt;.
L'utilisation des mots dans une langue donnée, la répartition des
richesses, la population dans les villes constituent quelques exemples.
Il y a ainsi très peu de villes extrêmement peuplées, et énormément de
villes très peu peuplées, de telle sorte qu'environ 20% de toutes les
villes représentent 80% de la population. Ou encore, 20% d'une
population concentre 80% des richesses. C'est &lt;a href="http://fr.wikipedia.org/wiki/Principe_de_Pareto"&gt;&lt;strong&gt;la loi des 80-20, ou
principe de Pareto&lt;/strong&gt;&lt;/a&gt;,
qui quantifie en quelque sorte certaines inégalités.&lt;/p&gt;
&lt;p&gt;Ici, &lt;strong&gt;ce principe est approximativement vérifié qualitativement mais
non quantitativemen&lt;/strong&gt;t: il est en fait plus marqué que la règle des
80-20! Ainsi 80% des candidats sont représentés non pas par 20% des
prénoms, mais par 2.5%! &lt;strong&gt;Au delà de l'observation d'un grand nombre de
prénoms rares, on peut faire celle d'un petit nombre de prénoms très
répandus&lt;/strong&gt;. Ainsi, seuls 0.5% des prénoms servent à nommer la moitié des
candidats. De plus, &lt;strong&gt;10% des prénoms représentent 90% des candidats&lt;/strong&gt;,
formant ainsi plutôt une règle des 90-10.&lt;/p&gt;
&lt;p&gt;Mathématiquement, on peut constater que &lt;strong&gt;la distribution des fréquences
des prénoms semble suivre de manière assez approximative une &lt;a href="http://fr.wikipedia.org/wiki/Loi_de_Zipf"&gt;loi de
Zipf&lt;/a&gt;&lt;/strong&gt;, typique d'une
distribution à longue traîne et satisfaisant à une règle de type 80-20.
Cette loi signifie que le nombre de prénoms donné à &lt;span class="math"&gt;\(n\)&lt;/span&gt;
candidats est proportionnel à &lt;span class="math"&gt;\(1/n^s\)&lt;/span&gt;, avec
&lt;span class="math"&gt;\(s&amp;gt;1\)&lt;/span&gt; un paramètre réel (loi de puissance). On constate en
effet que la distribution des fréquences des prénoms dans un &lt;a href="http://en.wikipedia.org/wiki/Log-log_plot"&gt;graphique
log-log&lt;/a&gt; est
approximativement linéaire, suggérant une loi de puissance
(voir panneau de droite dans la figure précédente). On peut tenter de
faire correspondre une loi de Zipf à ces données, à l'aide d'une méthode
d'estimation statistique. En utilisant la &lt;a href="http://fr.wikipedia.org/wiki/Maximum_de_vraisemblance"&gt;méthode du maximum de
vraisemblance&lt;/a&gt;,
on trouve une valeur &lt;span class="math"&gt;\(s \simeq 1.9\)&lt;/span&gt; pour le paramètre.
Cette distribution adaptée aux données est représentée en rouge dans la
figure précédente.&lt;/p&gt;
&lt;p&gt;Une autre manière de représenter cette distribution est d'afficher le
pourcentage de candidats couverts par 1, 2, 3... prénoms, en triant les
prénoms par ordre décroissant de fréquence. On obtient le graphique
suivant (à droite, échelle log-log) :&lt;/p&gt;
&lt;p&gt;&lt;img alt="Fréquence" src="https://cyrille.rossant.net/images/prenoms-frequency.png" /&gt;&lt;/p&gt;
&lt;p&gt;Le "coude" observé à gauche est typique d'une loi de Zipf. De gauche à
droite, les prénoms sont classés par fréquence décroissante (le prénom
le plus donné d'abord, Camille, puis le second, Marie, etc.). Au fur et
à mesure que l'on ajoute ces prénoms, la fraction de candidats
représentés augmente très rapidement (partie gauche du coude). Puis
viennent les prénoms beaucoup plus rares, portés par un nombre très
faible de candidats (partie droite). La courbe croît alors très
lentement, le nombre de candidats couverts n'augmentant que d'une
fraction infinitésimale à chaque prénom.&lt;/p&gt;
&lt;p&gt;La répartition des prénoms est ainsi particulièrement hétérogène, avec
d'un côté des prénoms très répandus, et de l'autre côté des prénoms
totalement originaux, nouveaux, ou uniques. Y aurait-il deux grandes
tendances chez les parents, entre les "traditionalistes" qui
souhaiteraient utiliser des prénoms classiques (ou des prénoms
d'ascendants familiaux), et les "modernistes" qui souhaiteraient rompre
avec le passé et marquer leur originalité? Notons qu'il est possible de
concilier les deux tendances, en quelque sorte, en &lt;a href="http://coulmont.com/blog/2011/07/20/le-vieux-qui-hante/"&gt;utilisant un prénom
du passé en second prénom, comme pour manifester un lien avec les
générations
précédentes&lt;/a&gt;.
Par ailleurs, cette tendance observée dans une population très
spécifique (une partie des candidats au bac 2012) est-elle la même que
celle observée plus généralement dans toute la population? Je laisse le
soin aux &lt;a href="http://coulmont.com/"&gt;sociologues&lt;/a&gt; d'y répondre.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="misc"></category><category term="opendata"></category></entry><entry><title>Prénoms et réussite au bac</title><link href="https://cyrille.rossant.net/prenoms-et-reussite-au-bac/" rel="alternate"></link><published>2012-07-12T00:00:00+02:00</published><updated>2012-07-12T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-07-12:/prenoms-et-reussite-au-bac/</id><summary type="html">&lt;p&gt;Le sociologue Baptiste Coulmont, auteur de 
&lt;em&gt;&lt;a href="http://coulmont.com/livres/prenoms/"&gt;Sociologie des prénoms&lt;/a&gt;&lt;/em&gt;, s'est
intéressé aux corrélations entre le prénom des candidats au baccalauréat
2012 et leur réussite à cet examen (&lt;a href="http://coulmont.com/blog/2012/07/08/prenoms-mentions-bac-2012/"&gt;voir ici pour l'étude originale sur
le blog de
l'auteur&lt;/a&gt;).
Ce travail a été &lt;a href="http://www.lepoint.fr/societe/les-prenoms-qui-reussissent-au-bac-10-07-2012-1483876_23.php"&gt;largement relayé par les
médias&lt;/a&gt;,
car les résultats sont …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Le sociologue Baptiste Coulmont, auteur de 
&lt;em&gt;&lt;a href="http://coulmont.com/livres/prenoms/"&gt;Sociologie des prénoms&lt;/a&gt;&lt;/em&gt;, s'est
intéressé aux corrélations entre le prénom des candidats au baccalauréat
2012 et leur réussite à cet examen (&lt;a href="http://coulmont.com/blog/2012/07/08/prenoms-mentions-bac-2012/"&gt;voir ici pour l'étude originale sur
le blog de
l'auteur&lt;/a&gt;).
Ce travail a été &lt;a href="http://www.lepoint.fr/societe/les-prenoms-qui-reussissent-au-bac-10-07-2012-1483876_23.php"&gt;largement relayé par les
médias&lt;/a&gt;,
car les résultats sont particulièrement intéressants. Il s'avère que
certains prénoms réussissent mieux que d'autres: les Madeleine et autres
Côme réussissent bien mieux (plus de 25% de mentions TB chez ces
candidats) que les Youssef ou Nabil (aucune mention TB cette année). Ce
n'est probablement pas le prénom en lui-même qui influe sur le résultat,
mais plutôt le fait que le prénom est souvent le reflet de certains
critères sociologiques (classe sociale, origine géographique, profession
des parents...). Ce sont ces derniers critères qui ont une influence
certaine sur les résultats scolaires, démontrant des inégalités
profondes dans le système éducatif actuel.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt;: &lt;a href="http://coulmont.com/bac/"&gt;maintenant, vous pouvez connaître les résultats des candidats
portant votre prénom!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;J'ai voulu effectuer quelques analyses complémentaires sur ces mêmes
données, en m'intéressant plus aux aspects mathématiques que
sociologiques. Il peut s'agir d'un exemple intéressant dans
l'enseignement d'un cours de probabilité et statistiques, illustrant
notamment les notions de
&lt;a href="http://fr.wikipedia.org/wiki/Probabilit%C3%A9_conditionnelle"&gt;conditionnement&lt;/a&gt;,
d'&lt;a href="http://fr.wikipedia.org/wiki/Esp%C3%A9rance_conditionnelle"&gt;espérance
conditionnelle&lt;/a&gt;,
de &lt;a href="http://fr.wikipedia.org/wiki/Inf%C3%A9rence_bay%C3%A9sienne"&gt;raisonnement
bayésien&lt;/a&gt;,
ou de &lt;a href="http://fr.wikipedia.org/wiki/Divergence_de_Kullback-Leibler"&gt;divergence de
Kullback-Leibler&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Résultat moyen en fonction du prénom&lt;/h2&gt;
&lt;p&gt;Nous nous intéressons au &lt;strong&gt;profil de résultats&lt;/strong&gt;: il s'agit d'une courbe
donnant la proportion de candidats pour chaque résultat possible: oral
(O), passable (P), mention assez bien (AB), mention bien (B), mention
très bien (TB). Cela s'appelle aussi une distribution de probabilité sur
l'ensemble des résultats possibles. Voici le profil moyen, pour tous les
candidats et indépendamment du prénom. &lt;strong&gt;Il y a environ 17% de candidats
devant passer l'oral, 35% de P, 27% de AB, 14% de B, 7% de TB&lt;/strong&gt;.
Rappelons que ces chiffres comportent deux biais: il ne s'agit que des
candidats ayant obtenu l'examen après le premier écrit, ou ayant obtenu
la possibilité de passer l'oral. Les candidats ayant échoué après le
premier écrit ne sont pas inclus dans les données. Le deuxième biais
concerne le fait que seuls les candidats ayant accepté de diffuser
publiquement leurs résultats sont inclus.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Prénoms" src="https://cyrille.rossant.net/images/prenoms-all.png" /&gt;&lt;/p&gt;
&lt;p&gt;Maintenant, nous nous intéressants à l'influence du prénom sur le
résultat au bac. Nous allons utiliser deux approches mathématiques: la
première utilise l'&lt;strong&gt;espérance conditionnelle&lt;/strong&gt;, la seconde utilise la
&lt;strong&gt;divergence de Kullback-Leibler&lt;/strong&gt;. Dans les deux cas, l'idée est de
comparer le profil moyen avec le profil pour chaque prénom. Cela revient
à étudier la distribution de probabilité conditionnelle à la donnée du
prénom. En d'autres termes, si un candidat pris au hasard a 7% d'avoir
eu mention TB, le fait de savoir qu'il s'appelle Côme, Nicolas, ou
Youssef change-t-il cette probabilité? Cette question correspond au
principe mathématique de &lt;strong&gt;conditionnement&lt;/strong&gt;. Du point de vue de
l'espérance conditionnelle, on peut se demander, si la moyenne générale
au bac est de 12 chez tous les candidats, combien de points en plus on
peut attendre chez un candidat en connaissant son prénom? D'un point de
vue bayésien, on peut aussi voir la question ainsi: connaissant le
profil de résultat moyen (prior), le fait de connaître le prénom
change-t-il le profil de résultat (posterior)?&lt;/p&gt;
&lt;h2&gt;Moyenne au bac&lt;/h2&gt;
&lt;p&gt;Dans cette première approche, nous nous intéressons à la moyenne des
candidats, sachant ou non leurs prénoms. Mathématiquement, il s'agit
respectivement de l'espérance de la distribution moyenne du résultat, et
de l'&lt;em&gt;espérance conditionnelle&lt;/em&gt; de cette distribution &lt;em&gt;sachant&lt;/em&gt; le
prénom du candidat. Pour cela, nous assignons d'abord une note moyenne à
chaque mention: 9 pour O, 11 pour P, 13 pour AB, 15 pour B, 17 pour TB.
Il ne s'agit bien sûr que d'une approximation, puisque nous n'avons
accès qu'à la mention et pas à la note moyenne de chaque candidat. Chez
tous les candidats (ayant réussi ou devant passer l'oral, donc), la
moyenne globale est de 12.2.&lt;/p&gt;
&lt;p&gt;Nous pouvons ensuite, pour chaque prénom, calculer l'écart, par rapport
à cette moyenne, de la moyenne des candidats portant ce prénom (ou
espérance conditionnelle). Nous trouvons que cet écart varie entre -2.1
(Nahida) et +2.1 (Gaëtane), soit une bonne mention d'écart. &lt;strong&gt;Autrement
dit, une Nahida a en moyenne &lt;em&gt;une mention en-dessous&lt;/em&gt; de la mention
moyenne des candidats, comparé à &lt;em&gt;une mention au-dessus&lt;/em&gt; pour une
Gaëtane&lt;/strong&gt;. Voici le profil de résultat des six prénoms les plus
en-dessous de la moyenne:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Moyenne" src="https://cyrille.rossant.net/images/prenoms-mean.png" /&gt;&lt;/p&gt;
&lt;p&gt;Voici les résultats complets pour les 30 prénoms les plus en-dessous,
avec l'écart à la moyenne.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Nahida       -2,07
Alyson       -1,97
Imad         -1,91
Nadir        -1,80
Mariama      -1,75
Bilel        -1,65
Fatma        -1,63
Abdelkader   -1,60
Manuella     -1,59
Aziza        -1,57
Yassin       -1,57
Mounir       -1,57
Moussa       -1,56
Siham        -1,55
Patrice      -1,53
Kamel        -1,53
Giovanni     -1,53
Dalila       -1,47
Abdel        -1,45
Erwin        -1,42
Nordine      -1,41
Khalid       -1,40
Latifa       -1,40
Youssef      -1,38
Sofian       -1,38
Souad        -1,37
Soumia       -1,37
Bilal        -1,36
Alysson      -1,36
Lamia        -1,35
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Du côté des prénoms avec l'écart le plus au-dessus de la moyenne, voici
les profils de résultats.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Moyenne" src="https://cyrille.rossant.net/images/prenoms-mean2.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Gaetane        2,13
Madeleine      1,94
Ariane         1,82
Come           1,76
Marguerite     1,73
Isaure         1,71
Mahaut         1,61
Marie-Anne     1,58
Hannah         1,51
Melisande      1,46
Viviane        1,45
Quitterie      1,43
Marie-Astrid   1,43
Guillemette    1,38
Anouk          1,35
Irene          1,34
Blaise         1,33
Arielle        1,33
Solange        1,33
Leon           1,31
Domitille      1,29
Celeste        1,23
Noemi          1,23
Cleo           1,23
Hortense       1,22
Baudouin       1,19
Jack           1,19
Iris           1,17
Jolan          1,17
Gaspard        1,16
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Destin des prénoms&lt;/h2&gt;
&lt;p&gt;Avec la seconde méthode, nous nous intéressons à la quantité
d'information obtenue avec la connaissance du prénom. Autrement dit,
posons-nous d'abord la question suivante:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Quel résultat attendre d'un candidat pris au hasard?&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Réponse&lt;/em&gt;: voir le profil de résultat moyen au début de cet article,
    supposé connu a priori (7% de mention TB, 14% de mentions B, etc.).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ensuite:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Quel résultat attendre d'un candidat pris au hasard, &lt;em&gt;si l'on nous
    donne son prénom&lt;/em&gt;? Plus précisément, &lt;strong&gt;à quel point notre attente du
    résultat est-elle modifiée par la connaissance de son prénom&lt;/strong&gt;?&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Réponse&lt;/em&gt;: la &lt;strong&gt;divergence de Kullback-Leibler&lt;/strong&gt; entre la
    distribution moyenne, et la distribution conditionnée au prénom,
    donne une réponse quantitative à cette question.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cette divergence constitue une sorte de métrique entre deux
distributions. Une divergence quasi-nulle signifie que les distributions
sont quasi-identiques, donc que notre attente du résultat n'est pas
modifiée par la connaissance du prénom. A l'inverse, une divergence plus
élevée signifie que la connaissance du prénom change de manière
importante le résultat que l'on peut attendre du candidat (&lt;a href="http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#KL_divergence_and_Bayesian_updating"&gt;voir ici
pour des
détails&lt;/a&gt;).
Les graphiques ci-dessous illustrent cela.&lt;/p&gt;
&lt;p&gt;Voici d'abord les six prénoms associés à la divergence la plus élevée.
Nous reconnaissons les prénoms obtenus plus haut, sauf que les prénoms
réussissant le mieux sont mélangés avec ceux réussissant le moins. En
effet, cette mesure signifie à quel point les profils de résultats sont
différents de la moyenne, mais pas la direction de cette différence, qui
peut être meilleure (plus de bonnes mentions) ou moins bonne (plus de
mauvais résultats).&lt;/p&gt;
&lt;p&gt;&lt;img alt="Divergence" src="https://cyrille.rossant.net/images/prenoms-kl2.png" /&gt;&lt;/p&gt;
&lt;p&gt;Voici les 30 prénoms associés à la divergence la plus élevée.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Nahida
Alyson
Imad
Nadir
Alysson
Gaetane
Tina
Mariama
Patrice
Madeleine
Aziza
Come
Fatih
Bilel
Manuella
Moussa
Fatma
Giovanni
Abdelkader
Cleo
Elia
Erwin
Isaure
Abdel
Siham
Zelie
Yassin
Mounir
Juliane
Leon
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Maintenant, nous pouvons aussi nous intéresser aux &lt;strong&gt;prénoms avec la
divergence la plus faible&lt;/strong&gt;, autrement dit les prénoms les plus
représentatifs de l'ensemble des candidats. Ces prénoms sont
probablement répartis de manière uniforme parmi tous les candidats, sans
être associés, par exemple, à une classe sociale particulière qui aurait
des résultats très différents de la moyenne. Ainsi, un Valentin ou une
Emilie a un profil de résultat tout à fait comparable à la moyenne
globale.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Divergence" src="https://cyrille.rossant.net/images/prenoms-kl1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Valentin
Emilie
Nicolas
Alexandra
Clement
Laura
Thomas
Arnaud
Remy
Alexandre
Helene
Hugo
Mario
Bastien
Sebastien
Estelle
Xavier
Romain
Quentin
Eva
Guillaume
Rayan
Vincent
Adrien
Sabine
Ines
Lucas
Sarah
Floriane
Virgile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;En conclusion, nous avons donné des méthodes pour trouver les prénoms
qui influent le plus (positivement ou négativement) sur le résultat au
bac, et à l'inverse pour trouver ceux qui ont le moins d'impact sur le
résultat et qui sont le plus proches possible des résultats globaux. Il
y a probablement beaucoup d'autres choses à analyser dans ces données.&lt;/p&gt;
&lt;h2&gt;Méthodes&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Données.&lt;/em&gt; Les données concernent les résultats de 346851 candidats,
toutes séries confondues (générales et technologiques), qui ont au moins
eu l'oral et qui ont accepté de rendre disponible publiquement leur
résultat. Tous ces candidats portent 18473 prénoms différents. Pour les
analyses, nous n'avons considéré que les prénoms portés par au moins 20
candidats, soit 1211 prénoms différents représentant 310145 candidats.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Modélisation&lt;/em&gt;. L'ensemble des candidats est noté
&lt;span class="math"&gt;\(\Omega\)&lt;/span&gt;, l'ensemble des 1211 prénoms est noté
&lt;span class="math"&gt;\(E\)&lt;/span&gt;, l'ensemble des résultats possibles est noté
&lt;span class="math"&gt;\(F\)&lt;/span&gt;. L'ensemble &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; est muni de la tribu
discrète et de la mesure de probabilité uniforme. Les variables
aléatoires &lt;span class="math"&gt;\(X(\omega)\)&lt;/span&gt; et &lt;span class="math"&gt;\(Y(\omega)\)&lt;/span&gt; sont
des variables aléatoires à valeurs dans &lt;span class="math"&gt;\(E\)&lt;/span&gt; et
&lt;span class="math"&gt;\(F\)&lt;/span&gt;, respectivement, et donnant le prénom et le résultat de
chaque candidat. Voici les formules utilisées.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;La probabilité de &lt;span class="math"&gt;\(y\)&lt;/span&gt; est:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
p[y]=\frac{\textrm{card}\left\{\omega \in
\Omega \mid Y(\omega)=y\right\}}{\textrm{card}(\Omega)}  
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;La probabilité conditionnelle de &lt;span class="math"&gt;\(y\)&lt;/span&gt; sachant
    &lt;span class="math"&gt;\(x\)&lt;/span&gt; est:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ 
p[y\mid x] = \frac{\textrm{card}\left\{\omega
\in \Omega \mid X(\omega)=x,
Y(\omega)=y\right\}}{\textrm{card}\left\{\omega \in \Omega
\mid X(\omega)=x\right\}}  
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;L'espérance de &lt;span class="math"&gt;\(y\)&lt;/span&gt; est:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
E[y]=\sum_{y \in F} y \times p[y]  
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;L'espérance conditionnelle de &lt;span class="math"&gt;\(y\)&lt;/span&gt; sachant
    &lt;span class="math"&gt;\(x\)&lt;/span&gt; est:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
E[y \mid x]=\sum_{y \in F} y \times p[y \mid
x]  
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;La divergence de Kullback-Leibler entre la distribution
    &lt;span class="math"&gt;\(p[y]\)&lt;/span&gt; et la distribution conditionnelle
    &lt;span class="math"&gt;\(p[y\mid x]\)&lt;/span&gt; est:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ 
D(x)=\sum_{y \in F} p[y \mid x] \times
\log\left(\frac{p[y \mid x]}{p[y]}\right)  
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="misc"></category><category term="opendata"></category></entry><entry><title>Introduction to Bayesian thinking</title><link href="https://cyrille.rossant.net/introduction-to-bayesian-thinking/" rel="alternate"></link><published>2012-07-04T00:00:00+02:00</published><updated>2012-07-04T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-07-04:/introduction-to-bayesian-thinking/</id><content type="html">&lt;p&gt;An updated version of this post can be found in the &lt;a href="https://ipython-books.github.io/"&gt;IPython Cookbook&lt;/a&gt;.&lt;/p&gt;</content><category term="misc"></category><category term="maths"></category></entry><entry><title>Build a Python IDE for Windows with Notepad++ and IPython</title><link href="https://cyrille.rossant.net/python-ide-windows/" rel="alternate"></link><published>2012-07-02T00:00:00+02:00</published><updated>2012-07-02T00:00:00+02:00</updated><author><name>Cyrille Rossant</name></author><id>tag:cyrille.rossant.net,2012-07-02:/python-ide-windows/</id><summary type="html">&lt;p&gt;I've been looking for a good and free Python IDE for Windows for a long time. I first used
&lt;a href="http://www.eclipse.org/"&gt;Eclipse&lt;/a&gt; and &lt;a href="http://pydev.org/"&gt;Pydev&lt;/a&gt;, but
Eclipse is a bit of a &lt;em&gt;"usine à gaz"&lt;/em&gt;. I tried
&lt;a href="http://code.google.com/p/spyderlib/"&gt;Spyder&lt;/a&gt; but it crashed too often
and it was not flexible enough. I ended up using …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been looking for a good and free Python IDE for Windows for a long time. I first used
&lt;a href="http://www.eclipse.org/"&gt;Eclipse&lt;/a&gt; and &lt;a href="http://pydev.org/"&gt;Pydev&lt;/a&gt;, but
Eclipse is a bit of a &lt;em&gt;"usine à gaz"&lt;/em&gt;. I tried
&lt;a href="http://code.google.com/p/spyderlib/"&gt;Spyder&lt;/a&gt; but it crashed too often
and it was not flexible enough. I ended up using
&lt;a href="http://notepad-plus-plus.org/"&gt;Notepad++&lt;/a&gt;, a really fast and powerful
text editor, with the great command-line interpreter
&lt;a href="http://ipython.org/"&gt;IPython&lt;/a&gt;. Notepad++ is extremely light to use,
opens within a second, and contains most important features a Python
developer wants (syntax highlighting, automatic indentation, code
folding...). However, it does not include a native way for running
Python scripts. On the other hand, IPython is a widely used and
extremely powerful Python interpreter that is well adapted for
scientific computing. It allows to run scripts in a command-line
interface, and offers the possibility to continue an interactive session
afterwards. It also includes a debugger and many more features.&lt;/p&gt;


&lt;p&gt;Unfortunately, using both Notepad++ and IPython in a convenient way
during an interactive session, where one edits a script and runs it many
times, is not straightforward. One can simply open both programs, with
IPython opened in the script directory, and call the magic &lt;em&gt;%run
script.py&lt;/em&gt; command repeatedly. However, when calling &lt;em&gt;%run&lt;/em&gt; several
times, the Python script is correctly reloaded every time, but not the
imported modules that could also have been edited in Notepad++. In other
words, if one runs a script which depends on different modules, and
edits one such module, those modifications won't be effective at the
next &lt;em&gt;%run&lt;/em&gt; command. One has to import and reload that specific module,
which can be tiresome when editing a lot of different modules. There
appears to be no way of resetting the whole IPython environment and
reloading all modules. So typically one has to close and open again
IPython in the right working directory. This is cumbersome since every
edition-evaluation loop requires to close the IPython interpreter, open
it again, put the window at a convenient place on the screen, go in the
right directory, and run the script. Over and over again, even when
changing just one line of code in an imported script.&lt;/p&gt;
&lt;p&gt;Those little issues might seem unimportant, but they can really hurt
productivity and prevent the user from focusing on its core work.
Therefore I've been looking for a way of automating this interactive
edition-evaluation loop with Notepad++ and IPython. The goal is to let
the user press a single keyboard button (e.g. F6) in a Python script
opened in Notepad++ in order to execute it in IPython. One should have
also a simple way of reloading all modules if needed. Here is what I
came up with. This method may certainly be improved, and it could even
be adapted to other OS than Windows.&lt;/p&gt;
&lt;p&gt;This method works with Python 2.7, IPython 0.13 and Notepad++ 6.1.3 (it
will probably work with other versions, but it may require small
modifications).&lt;/p&gt;
&lt;p&gt;First, create a custom IPython script that will define two new magic
commands in IPython called &lt;em&gt;%cdrun&lt;/em&gt; and &lt;em&gt;%cdrunkill&lt;/em&gt;. Both open a new
IPython interpreter, set a specific working directory, and run a Python
script. The second command also kills any existing IPython interpreter
(corresponding to a hard restart of IPython). This script will be loaded
at every IPython launch, so it should be placed here:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;C:\Users\&amp;lt;USERNAME&amp;gt;\.ipython\profile_default\startup\cdrun.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This file contains the following code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;subprocess&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Popen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;PIPE&lt;/span&gt;

&lt;span class="n"&gt;ip&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_ipython&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;kill_python&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c1"&gt;# kill all other python processes&lt;/span&gt;
    &lt;span class="n"&gt;pid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getpid&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;cmd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tasklist&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;/FO&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;LIST&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;/FI&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;IMAGENAME eq python.exe&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Popen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PIPE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;communicate&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;PID&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;ps&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;pid&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;ps&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ps&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;
    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/pid &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ps&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;cmd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;taskkill /F &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cdrun&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arg&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;magic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;cd &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;magic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;run &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cdrunkill&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arg&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;kill_python&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;magic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;cd &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;magic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;run &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;ip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;define_magic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;cdrun&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cdrun&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;define_magic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;cdrunkill&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cdrunkill&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;em&gt;kill_python&lt;/em&gt; function kills all Python processes except the
current one. Hence this script allows to automatically close a previous
IPython interpreter and open a new one, resolving the module reloading
issue. If you want to open a new IPython interpreter without killing all
Python processes (for example, with a multicore computer, launching
several scripts in different IPython interpreters can make them run in
parallel on several CPUs), you can use the first command &lt;em&gt;cdrun&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Next, you can specify the screen location and the size of the Ipython
window. It is very convenient because it allows you to put the
Notepad++, say, on the left of the screen, and the IPython interpreter
on the right, so that you don't have to manually move the IPython window
every time you launch a new interpreter (otherwise Windows tends to put
it at random locations). To do this, &lt;a href="http://commandwindows.com/configure.htm"&gt;edit the window properties of the
IPython prompt&lt;/a&gt; (see method on
this website).&lt;/p&gt;
&lt;p&gt;Third, define a new macro in Notepad++, by editing or creating the
following file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# in C:\Users\&amp;lt;USERNAME&amp;gt;\AppData\Roaming\Notepad++\shortcuts.xml&lt;/span&gt;
ipython -i -c &lt;span class="s2"&gt;&amp;quot;%cdrun &lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;FULL_CURRENT_PATH&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;  
ipython -i -c &lt;span class="s2"&gt;&amp;quot;%cdrunkill &lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;FULL_CURRENT_PATH&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The buttons #117 and #118 correspond to F6 and F7 here. If other
commands exist, just add the &lt;em&gt;\&amp;lt;Command&gt;&lt;/em&gt; lines in the
&lt;em&gt;\&amp;lt;UserDefinedCommands&gt;&lt;/em&gt; section. If those shortcuts don't work, it may
be because they are already assigned to other commands: go in Settings,
then Shortcuts, and remove them.&lt;/p&gt;
&lt;p&gt;Also, do not edit this XML file with Notepad++, because your
modifications may be discarded when you close Notepad++. Instead, ensure
that Notepad++ is closed, edit the file with Notepad, and reopen
Notepad++.&lt;/p&gt;
&lt;p&gt;Now, when you open a Python script in Notepad++, you can press F6. It
will launch an IPython window and execute the script. At the end of the
execution, you can interact in the IPython interpreter. If you need to
execute the script again, just use the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt; &lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This will reload &lt;em&gt;script.py&lt;/em&gt;, but not other modules. If you need to
reload everything, press F7 in Notepad++: it will close the IPython
window and open a new one, at the same location on the screen. This
gives you the illusion of a very light and basic Python IDE, and allows
you to benefit from both the great editing features of Notepad++ and the
powerful IPython interpreter at the same time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: you can automate the process of re-evaluating the script in
IPython. Here, you need to: save the script in Notepad++, set the focus
to IPython (with the mouse or with ALT+TAB), and type again the &lt;em&gt;%run&lt;/em&gt;
command (or selecting it in the command history). With the very powerful
tool &lt;a href="http://www.autohotkey.com/"&gt;AutoHotkey&lt;/a&gt;, you can create a simple
script for automating these keystrokes. Create a text file named
"ipython_update.ahk" somewhere and put the following code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;SetTitleMatchMode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="nb"&gt;IfWinExist&lt;/span&gt; &lt;span class="n"&gt;Notepad&lt;/span&gt;&lt;span class="se"&gt;`+`+&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;WinActivate&lt;/span&gt;
    &lt;span class="nb"&gt;Send&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
    &lt;span class="nb"&gt;SetTitleMatchMode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="nb"&gt;IfWinExist&lt;/span&gt; &lt;span class="n"&gt;ipython&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nb"&gt;WinActivate&lt;/span&gt;
        &lt;span class="nb"&gt;Send&lt;/span&gt; &lt;span class="se"&gt;`%&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="se"&gt;`r&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, in Notepad++, create a new command for launching this script with
the current file as parameter:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;autohotkey &lt;span class="o"&gt;[&lt;/span&gt;YOURPATH&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="se"&gt;\i&lt;/span&gt;python_update.ahk &lt;span class="k"&gt;$(&lt;/span&gt;FILE_NAME&lt;span class="k"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Ensure that the autohotkey.exe binary is in the Windows Path. Now,
pressing F8 in Notepad++ will automatically set the focus to IPython and
run your script.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note for Linux users&lt;/strong&gt;: Here is a Python function for killing all
Python processes except the current one on Linux that might be useful.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;kill_python&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Linux version (not very well tested, might need some tweaking)&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;pid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getpid&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;cmd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ps -ef | grep python | awk &amp;#39;{print $2}&amp;#39;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;commands&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getoutput&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;pid&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;cmd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;kill &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="misc"></category><category term="python"></category></entry></feed>